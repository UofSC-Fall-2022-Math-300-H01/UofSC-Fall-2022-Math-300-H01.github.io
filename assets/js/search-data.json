{"0": {
    "doc": "Homework 0",
    "title": "Homework 0 - Orientation",
    "content": "Due 2022-08-22. You can find the assignment on GitHub. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/00/#homework-0---orientation",
    "relUrl": "/homework/00/#homework-0---orientation"
  },"1": {
    "doc": "Homework 0",
    "title": "Homework 0",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/00/",
    "relUrl": "/homework/00/"
  },"2": {
    "doc": "Homework 1",
    "title": "Homework 1 - Propositions, logic, and deduction",
    "content": "Due 2022-08-26. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/01/#homework-1---propositions-logic-and-deduction",
    "relUrl": "/homework/01/#homework-1---propositions-logic-and-deduction"
  },"3": {
    "doc": "Homework 1",
    "title": "Homework 1",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/01/",
    "relUrl": "/homework/01/"
  },"4": {
    "doc": "Homework 2",
    "title": "Homework 2 - Negation, proof by contradiction, and truth",
    "content": "Due 2022-09-06. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/02/#homework-2---negation-proof-by-contradiction-and-truth",
    "relUrl": "/homework/02/#homework-2---negation-proof-by-contradiction-and-truth"
  },"5": {
    "doc": "Homework 2",
    "title": "Homework 2",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/02/",
    "relUrl": "/homework/02/"
  },"6": {
    "doc": "Homework 3",
    "title": "Homework 3 - Proof vs truth and some useful formula",
    "content": "Due 2022-09-06. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/03/#homework-3---proof-vs-truth-and-some-useful-formula",
    "relUrl": "/homework/03/#homework-3---proof-vs-truth-and-some-useful-formula"
  },"7": {
    "doc": "Homework 3",
    "title": "Homework 3",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/03/",
    "relUrl": "/homework/03/"
  },"8": {
    "doc": "Homework 4",
    "title": "Homework 4 - Propositional logic in Lean",
    "content": "Due 2022-09-19. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/04/#homework-4---propositional-logic-in-lean",
    "relUrl": "/homework/04/#homework-4---propositional-logic-in-lean"
  },"9": {
    "doc": "Homework 4",
    "title": "Homework 4",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/04/",
    "relUrl": "/homework/04/"
  },"10": {
    "doc": "Homework 5",
    "title": "Homework 5 - More propositional logic in Lean",
    "content": "Due 2022-09-26. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/05/#homework-5---more-propositional-logic-in-lean",
    "relUrl": "/homework/05/#homework-5---more-propositional-logic-in-lean"
  },"11": {
    "doc": "Homework 5",
    "title": "Homework 5",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/05/",
    "relUrl": "/homework/05/"
  },"12": {
    "doc": "Homework 6",
    "title": "Homework 6 - Predicate logic",
    "content": "Due 2022-10-03. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/06/#homework-6---predicate-logic",
    "relUrl": "/homework/06/#homework-6---predicate-logic"
  },"13": {
    "doc": "Homework 6",
    "title": "Homework 6",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/06/",
    "relUrl": "/homework/06/"
  },"14": {
    "doc": "Homework 7",
    "title": "Homework 7 - Predicate logic in Lean",
    "content": "Due 2022-10-10. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/07/#homework-7---predicate-logic-in-lean",
    "relUrl": "/homework/07/#homework-7---predicate-logic-in-lean"
  },"15": {
    "doc": "Homework 7",
    "title": "Homework 7",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/07/",
    "relUrl": "/homework/07/"
  },"16": {
    "doc": "Homework 8",
    "title": "Homework 8 - Sets",
    "content": "Due 2022-10-17. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/08/#homework-8---sets",
    "relUrl": "/homework/08/#homework-8---sets"
  },"17": {
    "doc": "Homework 8",
    "title": "Homework 8",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/08/",
    "relUrl": "/homework/08/"
  },"18": {
    "doc": "Homework 9",
    "title": "Homework 9 - Sets in Lean",
    "content": "Due 2022-10-24. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/09/#homework-9---sets-in-lean",
    "relUrl": "/homework/09/#homework-9---sets-in-lean"
  },"19": {
    "doc": "Homework 9",
    "title": "Homework 9",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/09/",
    "relUrl": "/homework/09/"
  },"20": {
    "doc": "Homework 10",
    "title": "Homework 10 - Functions",
    "content": "Due 2022-10-31. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/10/#homework-10---functions",
    "relUrl": "/homework/10/#homework-10---functions"
  },"21": {
    "doc": "Homework 10",
    "title": "Homework 10",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/10/",
    "relUrl": "/homework/10/"
  },"22": {
    "doc": "Homework 11",
    "title": "Homework 11 - Relations",
    "content": "Due 2022-11-07. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/11/#homework-11---relations",
    "relUrl": "/homework/11/#homework-11---relations"
  },"23": {
    "doc": "Homework 11",
    "title": "Homework 11",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/homework/11/",
    "relUrl": "/homework/11/"
  },"24": {
    "doc": "Homework 12",
    "title": "Homework 12 - Induction and the natural numbers",
    "content": "Due 2022-11-14. You can find and submit the assignment on our Github Classroom. ",
    "url": "https://300.f22.matthewrobertballard.com/homework/12/#homework-12---induction-and-the-natural-numbers",
    "relUrl": "/homework/12/#homework-12---induction-and-the-natural-numbers"
  },"25": {
    "doc": "Homework 12",
    "title": "Homework 12",
    "content": "WORK IN PROGRESS . ",
    "url": "https://300.f22.matthewrobertballard.com/homework/12/",
    "relUrl": "/homework/12/"
  },"26": {
    "doc": "This Website",
    "title": "About this website",
    "content": "This website is hosted on GitHub and relies on Jekyll to generate the content. It uses the Just the Class theme which built off the Just the Docs theme. At material appearing here is copyright © 2021 Matthew Ballard and is distributed with an MIT license. ",
    "url": "https://300.f22.matthewrobertballard.com/about_this_webpage/#about-this-website",
    "relUrl": "/about_this_webpage/#about-this-website"
  },"27": {
    "doc": "This Website",
    "title": "This Website",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/about_this_webpage/",
    "relUrl": "/about_this_webpage/"
  },"28": {
    "doc": "Announcements",
    "title": "Announcements",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"29": {
    "doc": "Announcements",
    "title": "Week 15 Announcement",
    "content": "Dec 2 &middot; 0 min read For the last week of classes, make sure . | to present at least once (this is a quarter of your grade completely in your control) and | to turn in any revisions by the end of Friday December 2 (all course materials can be found at our GitHub org) | . Each presentation after the first will convert your lowest homework or quiz to a 100%. I’ve sent out an assignment in Teams that just serves to report your current grade. ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"30": {
    "doc": "Announcements",
    "title": "Week 8 Announcement",
    "content": "Oct 7 &middot; 0 min read Remember this is a short week due to Fall Break. Take a look at . | the schedule for this week | and the homework for this week. | . ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"31": {
    "doc": "Announcements",
    "title": "Week 6 Announcement",
    "content": "Sep 23 &middot; 0 min read Take a look at . | the schedule for this week | and the homework for this week. | . ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"32": {
    "doc": "Announcements",
    "title": "Week 5 Announcement",
    "content": "Sep 16 &middot; 0 min read For Monday and Wednesday, be sure to bring a laptop to class this week if you have one. Take a look at . | the schedule for this week | and the homework for this week. | . ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"33": {
    "doc": "Announcements",
    "title": "Week 4 Announcement",
    "content": "Sep 9 &middot; 0 min read Be sure to bring a laptop to class this week if you have one. Take a look at . | the schedule for this week | and the homework for this week. | . ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"34": {
    "doc": "Announcements",
    "title": "Week 3 Announcement",
    "content": "Sep 2 &middot; 0 min read We will return to in-person instruction on Wednesday Sept 7 in LC Room 348 . Take a look at . | the schedule for this week | and the homework for this week. | . ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"35": {
    "doc": "Announcements",
    "title": "Week 2 Announcement",
    "content": "Aug 26 &middot; 0 min read We are still virtual through Microsoft Teams this week. Take a look at . | the schedule for this week | and the homework for this week. | . The due date for homework 2 has been pushed back to Tuesday September 6 due to Labor Day. Note: your files in GitHub classroom will not update to reflect this. ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"36": {
    "doc": "Announcements",
    "title": "Week 1 Announcement",
    "content": "Aug 19 &middot; 0 min read Welcome to Transition to Advanced Mathematics! . To be prepared for the first class, make sure you . | read the syllabus | check homework 0 | reach out with any questions. | . Due to delays in the renovation of LeConte College, class meetings will be virtual through Microsoft Teams until (at least) 2022.09.07. ",
    "url": "https://300.f22.matthewrobertballard.com/announcements/",
    "relUrl": "/announcements/"
  },"37": {
    "doc": "Basic ideas",
    "title": "Basics of functions",
    "content": "As we have seen Lean has built in types function f : A → B. We encountered these when dealing with implication in propositional/predicate logic. Given propositions P Q : Prop, a term h : P → Q is a function that inputs proofs of P and outputs proofs of Q. Similarly, we modeled predicates as functions P : U → Prop which take terms of a general type U and output propositions. And a proof h : ∀ x, P x is function whose inputs are terms x : U and whose output at a given x is a proof of P x. The last incarnation is particularly instructive of the power of the existence of a function. For a general predicate P, there will be not be a proof of ∀ x, P x. In other words, we will not be able to make a well-defined function. The Lean notation and the mathematical notation for a function coincide: f : A → B. Here A is called the domain of f and B is called the codomain of f. In other words, the domain of a function is the type of its inputs and the codomain is the type of outputs. Mathematically, it is useful to approach to construction of a function with more an artistic mentality. Often we will make a function that where the output seemingly depends on more data than the given inputs and then provide a proof that the extra data, while not extraneous, does not change the output when it changes. Checking this is usually called checking that a function is well-defined. Example. Suppose $x \\in \\mathbb{R}$ is a real number. Consider the function \\(x \\mapsto \\sqrt{x}\\) Where $\\sqrt{x}$ satisfies $(\\sqrt{x})^2 = x$. Is this a well-defined function? For any input from $\\mathbb{R}$, we need to be able to evaluate this function into a single output. Problem #1: if $x &lt; 0$, then there are no (real number) solutions to $y^2 = x$. Thus, this proposed function cannot be evaluated for $x &lt; 0$. We would say that this is not well-defined for $x &lt; 0$. Problem #2: Let’s assume that $x \\geq 0$. We now have another problem. If $x &gt; 0$, then there are two choices for $\\sqrt{x}$, a positive one and a negative one. Thus this is also not a well-defined function for $x&gt;0$. To fix this, we impose some additional conditions. First, the domain of $\\sqrt{x}$ is not all of $\\mathbb{R}$. It is all real numbers satisfying $x \\geq 0$. The square root function, as it appeared in your calculus class, is then the positive solution to the equation $y^2 = x$ for a given input $x &gt; 0$ and is, of course, $0$ if $x=0$. In Lean, we cannot write a non-well-defined function - the type checker will yell at us. Suppose you are handed a type U and are asked for some function f : U → U. What can you do? You can hand back the input as the output. Definition. The identity function is the function whose output is equal to input, i.e. $x \\mapsto x$. The identity function depends on the type of x. Let’s see it in Lean. variable (α : Type) #check @id α -- id : α → α . With more information about the input type we can generally make more functions. variable (α β : Type) -- if we take a product term we can project onto each component def proj (z : α × β) := z.1 #check proj α β -- proj α β : α × β → α . As we can see projection for product types is also built in already using z.1,z.2 or z.fst,z.snd. Let’s get even more specific. Lean knows about natural numbers and all the usual arithmetic operations we can apply to them. The name for $\\mathbb{N}$ in Lean is Nat. def f : Nat → Nat := fun n =&gt; 2*n^3 + 4*n + 3 #eval f 5 -- 273 . The command #eval calls a more efficient (but less type-safe) evaluation program to compute the application of f. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/basic/#basics-of-functions",
    "relUrl": "/notes/functions/basic/#basics-of-functions"
  },"38": {
    "doc": "Basic ideas",
    "title": "Chaining functions",
    "content": "One of the most powerful aspects of functions is the ability to chain them together, one after another after another… . If we have f : A → B, g: B → C, then we can take an input a, feed it into f as f a, and then feed that into g as g (f a). The result is the composition of f and g. Definition. Given functions $f : A \\to B$ and $g : B \\to C$, the composition of $g$ and $f$ is the function \\(a \\mapsto g(f(a))\\) The composition is denoted as $g \\circ f$ and is typed in Lean as Function.comp and is abbreviated as \\circ. Note that composing is only possible if the codomain of $f$ equals the domain of $g$. Let’s see some examples in Lean. def f : Nat → Nat := fun n =&gt; 2*n^3 + 4*n + 3 def g (n : Nat) : Nat := n^2 + 1 #check g ∘ f -- g ∘ f : Nat → Nat #eval f 1 -- 9 #eval g (f 1) -- 82 #eval (g ∘ f) 1 -- 82 -- note that the order of composition is essential #eval f (g 1) -- 27 . In general $g \\circ f \\neq f \\circ g$ even if both compositions are well-defined so functional composition is non-commutative. It is associative however. Theorem. Composition of functions is an associative operation. In other words, if $f: A \\to B$, $g : B \\to C$, and $h : C \\to D$ are three functions, then \\((h \\circ g) \\circ f = h \\circ (g \\circ f)\\) . Proof. (Expand to view) Two functions $f_1,f_2$ are equal if they have the same domains and codomains and if for any element $x$ of the domain we have $f_1(x) = f_2(x)$. More plainly, two functions are equal if - they take in the same types of inputs - they give back the same type of outputs and - for any input, they evaluate to the same output So to prove this we assume we have some $a$ from $A$ and evaluate both sides. The left-hand side is by definition $$ ((h \\circ g) \\circ f)(a) = (h \\circ g)(f(a)) = h(g(f(a))) $$ The right-hand side is $$ (h \\circ (g \\circ f))(a) = h((g \\circ f)(x)) = h(g(f(a))) $$ These are equal so the functions are equal. &#9632; . What does the proof of associativity look like in Lean? . variable (α β γ δ : Type) variable (f : α → β) (g : β → γ) (h : γ → δ) theorem Assoc : (h ∘ g) ∘ f = h ∘ (g ∘ f) := by apply funext -- the goal is now -- ⊢ ∀ (x : α), Function.comp (h ∘ g) f x = Function.comp h (g ∘ f) x intro a rfl . Here funext is a (more robust) version of the proposition \\(\\forall f_1,f_2 : A \\to B, f_1 = f_2 \\leftrightarrow (\\forall a, f_1(a) = f_2(a))\\) and stands for functional extensionality (similar to set extensionality). Notice also that rfl closed the goal Function.comp (h ∘ g) f x = Function.comp h (g ∘ f) x even though it is not immediately of the form t = t, i.e. something is equal to itself. This is due to the fact that rfl can also reduce terms to their more basic form, just like we did in our own pen-and-paper proof of associativity of functional composition. The identity function plays a special rule in composition - composing with it does nothing. Or stated at more high-level: composition with an identity function is also an identity function but now for functions: $f \\mapsto f$. variable (α β : Type) variable (f : α → β) theorem comp_id : f ∘ (@id α) = f := by apply funext intro x rfl theorem id_comp : (@id β) ∘ f = f := by apply funext intro x rfl . Another useful consequence of functional extensionality is that if $f = g$ then $f(x) = g(x)$ for any $x$. We could extract this result from funext each time we want to use it but that is not very ergonomic. Instead, the result is already built into Lean as congrFun. variable (α β : Type) variable (f₁ f₂ : α → β) example (h : f₁ = f₂) (a : α) : f₁ a = f₂ a := by exact congrFun h a . The contrapositive of this statement is useful. variable (α β : Type) variable (f₁ f₂ : α → β) example (h : ∃ a, f₁ a ≠ f₂ a) : f₁ ≠ f₂ := by intro n have ⟨a,h₁⟩ := h have : f₁ a = f₂ a := congrFun n a exact h₁ this . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/basic/#chaining-functions",
    "relUrl": "/notes/functions/basic/#chaining-functions"
  },"39": {
    "doc": "Basic ideas",
    "title": "Basic ideas",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/basic/",
    "relUrl": "/notes/functions/basic/"
  },"40": {
    "doc": "Basic ideas",
    "title": "Basics of relations",
    "content": "We already know what relations are. We saw then as part of predicate logic. Definition. A relation is a binary predicate. So in Lean we would write . variable (U : Type) variable (R : U → U → Prop) . In sets, one usually defines a relation on elements of a set $X$ as a subset \\(R \\subseteq X \\times X\\) The corresponding predicate is then \\((x,x^\\prime) \\in R\\) . We write $x R y$ to abbreviate that staement that $x$ is related by $R$ to $y$, the predicate is satisfied for the values $x$ and $y$. Often from the context, we will just write $x \\sim y$. The simple definition allows for a variety of examples. Examples . | We could simply take | . def R (x y : U) := fun x y =&gt; False . Since there is no proof of false, no pairs are even related. The corresponding subset of $U \\times U$ is $\\varnothing$. | At the other end of the extreme, we have | . def R (x y : U) := fun x y =&gt; True . Here every pair $(x,y)$ is related. The corresponding subset of $U \\times U$ is $U \\times U$ itself. | Equality is perhaps the most familiar example of a relation. | . def R (x y : U) := fun x y =&gt; x = y . The corresponding subset of $U \\times U$ is called the diagonal \\(\\Delta_U := \\lbrace (x,x) \\in U \\times U \\mid x \\in U \\rbrace\\) . | Lets take the natural numbers. Thanks to their rich structure there are many possible relations. We have the familiar relation based on size of integers: $n &lt; m$ denotes that $n$ is less than $m$. Lean already knows about this | . variable (n m : Nat) #check n &lt; m -- n &lt; m : Prop . The subset of the $\\mathbb{N} \\times \\mathbb{N}$ is just \\(R_{&lt;,\\mathbb{N}} := \\lbrace (n,m) \\mid n &lt; m \\rbrace\\) If we identity $\\mathbb{N} \\times \\mathbb{N}$ with the lattice points in the first quadrant of $\\mathbb{R}^2$, then we can visualize $R_{&lt;,\\mathbb{N}$ as all the points above the line $y = x$. | We have the close cousin of $ &lt; $ on $\\mathbb{N}$ : $\\leq$, less than or equal. We simply combined two relations we have seen above using an $\\lor$ \\(n \\leq m \\leftrightarrow (n &lt; m) \\lor (n=m)\\) Since have combined two relations using an or statement we get the union of their corresponding subsets \\(R_{\\leq, \\mathbb{N}} = \\Delta_{\\mathbb{N}} \\cup R_{&lt;,\\mathbb{N}}\\) | The previous example built a new relation from an old one using a particular logical connective. One can, of course, use the other connectives, $\\to, \\land, \\neg$. For example, we have \\(x &gt; y := \\neg (x \\leq y)\\) where the corresponding subset is $R_{\\leq, \\mathbb{N}}^c$, the complement. | We can also use arithmetic to build relations on natural numbers. For example, we have divisibility $a \\mid b$ if there exists some $c$ with $b = ac$. | Similarly, we can use functions to build new relations from old ones. For example, let’s take $ &lt; $ on the real numbers $\\mathbb{R}$ and the absolute value function $| \\cdot | : \\mathbb{R} \\to \\mathbb{R}$. Let’s say that $x$ is related to $y$ if $|x| \\leq |y|$. This gives a new relation which is equal to $x \\in [-y,y]$. | . Looking at our examples, we say a variety of behaviors. For some, we have $x \\sim x$ for all $x$, like $=$, but for others we don’t, like $&lt;$. For some we can always compare $x$ to $y$ or vice-versa; for others we can’t. There are a handful of natural properties we can impose on relations which we will discuss next. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/basic/#basics-of-relations",
    "relUrl": "/notes/relations/basic/#basics-of-relations"
  },"41": {
    "doc": "Basic ideas",
    "title": "Basic ideas",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/basic/",
    "relUrl": "/notes/relations/basic/"
  },"42": {
    "doc": "Basics",
    "title": "Sets and membership",
    "content": "We want to talk sensibly and precisely about collecitons of mathematical objects. The notion of a set accomplishes this. Like when working with predicate logic, we first fix an universal repoository $\\mathcal U$. Members of $\\mathcal U$ are called elements. Definition. A set $X$ is a (sub)collection of elements from $\\mathcal U$. The basic operation we can perform given an element $x$ and a set $X$ is to ask whether $x$ is in $X$ or not, ie to check membership. We use the notation $x \\in X$ for the predicate: $x$ is an element of $X$. And we use $x \\not \\in X$ for $\\neg (x \\in X)$. Example. Suppose we are talking about all the dogs that live in neighborhood at home. Then our universal set $\\mathcal D$ is a giant list of every dog, perhaps identified by name. We can make new sets in a few ways. For example, \\(\\text{Fritz}, \\text{Herman}, \\text{Sam}\\) would form a set. We use special notation to indicate we are forming a set: curly braces $\\lbrace ~ \\rbrace$. So we would write the previous set of dogs \\(W := \\lbrace \\text{Fritz}, \\text{Herman}, \\text{Sam} \\rbrace\\) to indicate we are talking about a set of dogs. In building the set $W$, we explicitly listed out the members of the set. Depending on the time and page length, this might not be feasible in general. Suppose that all the stars of the Air Bud franchise lived in the neighborhood. Then, without confusion, we can label each lead golden retriever with corresponding movie. If I wanted a set consisting of all the stars of Air Bud. Often, we are bit lazier in writing down a set. For example \\(AB := \\lbrace \\text{Air Bud}, \\text{Air Bud: Golden Retriever}, \\ldots, \\text{Santa Paws 2: The Santa Pups} \\rbrace\\) We wrote out the first few elements of the set and the last one and we expect people to infer the rest from context. People would know for instance that \\(\\text{Air Buddy} \\in AB\\) and \\(\\text{Lassie} \\not \\in AB\\) (Admittedly, this works better when talking about more rigid things like numbers. Most people could guess that \\(\\lbrace 1, 2, 3, \\ldots, 9, 10 \\rbrace\\) is the set of natural numbers between 1 and 10.) . The final common way to make a set is by specifying a condition that must hold as the condition for membership in that set. \\(D := \\lbrace d \\mid d \\text{ is a weiner dog} \\rbrace\\) denotes the set consisting of dogs in our universal set (in the neighborhood) that are dachshunds. So $d \\in D$ if and only if $d$ is a weiner dog. Perhaps $D$ is too large and we are only concerned with weiner dogs owned by my grandmother. \\(GD := \\lbrace d \\in D \\mid d \\text{ is owned by my grandma} \\rbrace\\) So $GD$ consists of the weiner dogs that are also owned by my grandmother. So to check the $d \\in GD$ we would have to verify that both . | $d$ is a weiner dog and | $d$ is my grandma’s dog | . It turns out that \\(\\text{Fritz} \\in GD \\\\ \\text{Herman} \\in GD \\\\ \\text{Sam} \\in GD\\) and there are no other weiner dogs that my grandmother owns. Both $W$ and $GD$ consist of exactly the same collection of elements so they are equal sets \\(W = GD\\) . The equality is an incarnation of a general principle called set extensionality. Set Extensionality. Two sets $X$ and $Y$ are equal if and only if $X$ and $Y$ have the same elements. We can express this using a logical formula \\(X = Y \\leftrightarrow \\forall z~ (z \\in X \\leftrightarrow z \\in Y)\\) . Extensionality of sets provides the fundamental way of checking two sets are equal. Example. Consider the two sets \\(X = \\{2,3,5,7\\}\\) and \\(Y = \\{n \\in \\mathbb{N} \\mid n \\text{ is prime and } n &lt; 10 \\}\\) . The two sets are in fact equal. To show this, we prove that \\(\\forall n~ (n \\in X \\leftrightarrow n \\in Y)\\) Remember to introduce a universal quantifier, we need to prove $n \\in X \\leftrightarrow n \\in Y$ where $n$ is now free. To introduce a bi-implication, we need two proofs. One of $n \\in X \\to n \\in Y$ and one of $n \\in Y \\to n \\in X$. We first prove that $n \\in X \\to n \\in Y$. To introduce an implication, we assume that $n \\in X$ is true and check that $n \\in Y$. So assume that \\(n \\in X = \\lbrace 2,3,5,7 \\rbrace\\) We want to prove that $n \\in Y$. The claim of membership $n \\in Y$ is equivalent to $n$ satisfying the predicate \\(n \\text{ is prime and } &lt; 10\\) So to show that $n \\in Y$ we check truth of the predicate. We can do this case by case. If $n = 2$, then $n$ is prime because the only natural number that divides it is $1$ and $n &lt; 10$. If $n = 3$, then $n$ is prime and $n &lt; 10$. If $n = 5$, then $n$ is prime and $n &lt; 10$. If $n = 7$, then $n$ is prime and $n &lt; 10$. Thus, if $n \\in X$, then $n \\in Y$. Next we assume that $n \\in Y$ and our goal is to show that $n \\in X$. Assume that $n \\in Y$. This is the same as saying that $n$ is prime and $n &lt; 10$. We know the list of natural numbers less that than $10$ is \\(0,1,2,3,4,5,6,7,8,9\\) So far this is larger than $X$; it has $X$ but it also has more elements. We check which of these are prime to see which are elements are actually in $Y$. We go case by case. If $n = 0$, then $0 = 2 \\cdot 0$, so $2 \\mid 0$ and $0$ is not prime. If $n = 4$, then $4 = 2 \\cdot 2$ so $4$ is not prime. If $n=6$, then $6 = 2 \\cdot 3$ so $6$ is not prime. $8 = 2 \\cdot 4$ so $8$ is not prime. $9 = 3 \\cdot 3$ so $9$ is not prime. Thus, the only elements that could be in $Y$ are $2,3,5,7$, ie $n \\in Y \\to n \\in X$. Definition. We say $X$ is a subset of $X$ if $\\forall x~ (x \\in X \\to x \\in Y)$. In other words, every element of $X$ is also an element of $Y$. We write $X \\subseteq Y$ is $X$ is a subset of $Y$. If $X \\subseteq Y$ and $ X \\not = Y$, then we write $X \\subset Y$. Note that this means we can express extensionality as $X = Y$ if and only if $X \\subseteq Y$ and $Y \\subseteq X$. Recall that $\\mathbb{R}$ is the set of real numbers. These numbers are represented by points on an infinite line and should be familiar from calculus. (This is not a precise definition.) . Example. Consider the sets \\([0,1] := \\lbrace x \\in \\mathbb{R} \\mid 0 \\leq x \\leq 1 \\rbrace \\\\ (0,1] := \\lbrace x \\in \\mathbb{R} \\mid 0 &lt; x \\leq 1 \\rbrace \\\\ \\lbrack 0,1) := \\lbrace x \\in \\mathbb{R} \\mid 0 \\leq x &lt; 1 \\rbrace \\\\ (0,1) := \\lbrace x \\in \\mathbb{R} \\mid 0 &lt; x &lt; 1 \\rbrace\\) . Then \\([0,1] \\supseteq (0,1] \\supseteq (0,1) \\\\ \\lbrack 0,1] \\supseteq [0,1) \\supseteq (0,1) \\\\ (0,1] \\nsubseteq [0,1) \\\\ \\lbrack 0,1) \\nsubseteq (0,1]\\) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/basic/#sets-and-membership",
    "relUrl": "/notes/sets/basic/#sets-and-membership"
  },"43": {
    "doc": "Basics",
    "title": "Basics",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/basic/",
    "relUrl": "/notes/sets/basic/"
  },"44": {
    "doc": "Schedule",
    "title": "Schedule",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/",
    "relUrl": "/calendar/"
  },"45": {
    "doc": "Schedule",
    "title": "The integers and integers mod m",
    "content": "Nov 21 Construction of the integers Pre-reading Nov 28 Lean’s Int Pre-reading Project draft due Nov 30 Modular arithmetic Pre-reading Dec 2 A glimpse of groups Pre-reading Dec 9 Final project due ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#the-integers-and-integers-mod-m",
    "relUrl": "/calendar/#the-integers-and-integers-mod-m"
  },"46": {
    "doc": "Schedule",
    "title": "Past topics",
    "content": ". ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#past-topics",
    "relUrl": "/calendar/#past-topics"
  },"47": {
    "doc": "Schedule",
    "title": "Induction",
    "content": "Nov 9 Peano’s natural numbers Pre-reading Nov 11 Recursion Pre-reading Nov 14 Induction Pre-reading Nov 16 Strong induction Pre-reading Nov 18 Other inductive types Pre-reading HW 12 due ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#induction",
    "relUrl": "/calendar/#induction"
  },"48": {
    "doc": "Schedule",
    "title": "Relations",
    "content": "Oct 31 Examples of relations Pre-reading HW 10 due Project &amp; Group Choice due Nov 2 Properties of relations Pre-reading Nov 4 Partial and total orders Pre-reading Nov 7 Equivalence relations Pre-reading HW 11 due ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#relations",
    "relUrl": "/calendar/#relations"
  },"49": {
    "doc": "Schedule",
    "title": "Functions",
    "content": "Oct 21 Basic ideas around functions Pre-reading Oct 24 Injective, surjective, bijective functions Pre-reading HW 9 due Oct 26 Inverses Pre-reading Oct 28 Functions and sets Pre-reading ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#functions",
    "relUrl": "/calendar/#functions"
  },"50": {
    "doc": "Schedule",
    "title": "Sets",
    "content": "Oct 10 Introducing sets Pre-reading HW 7 due Oct 12 Operations on sets Pre-reading Oct 17 Sets in Lean Pre-reading HW 8 due Oct 19 More set theoretic proofs in Lean Pre-reading ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#sets",
    "relUrl": "/calendar/#sets"
  },"51": {
    "doc": "Schedule",
    "title": "Predicate logic",
    "content": "Sep 23 Predicates, quantifiers, and equality Pre-reading Sep 26 New rules of inference Pre-reading HW 5 due Sep 28 Models in predicate logic Pre-reading Oct 3 Examples derivations Pre-reading Oct 5 Predicate logic in Lean Pre-reading HW 6 due Oct 7 Examples in Lean Pre-reading ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#predicate-logic",
    "relUrl": "/calendar/#predicate-logic"
  },"52": {
    "doc": "Schedule",
    "title": "Lean",
    "content": "Sep 12 Propositions and connectives Pre-reading HW 3 due Sep 14 Proofs and first rules of inference Pre-reading Sep 16 More proofs and rules of inference Pre-reading Sep 19 Negation and proof by contradiction Pre-reading HW 4 due Sep 21 Interactive mode for proving Pre-reading ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#lean",
    "relUrl": "/calendar/#lean"
  },"53": {
    "doc": "Schedule",
    "title": "Propositional logic",
    "content": "Aug 22 Some puzzles No pre-reading HW 0 due Aug 24 Propositions and proof Pre-reading Aug 26 And, or, implies Pre-reading Aug 29 Not Pre-reading HW 1 due Aug 31 Reductio ad absurdum Pre-reading Sep 2 Intepretations and truth tables Pre-reading Sep 7 Proof vs truth Pre-reading HW 2 due Sep 9 Useful formula in propositional logic Pre-reading ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#propositional-logic",
    "relUrl": "/calendar/#propositional-logic"
  },"54": {
    "doc": "Schedule",
    "title": "Welcome and Orientation",
    "content": "Aug 19 Introducing the course and ourselves ",
    "url": "https://300.f22.matthewrobertballard.com/calendar/#welcome-and-orientation",
    "relUrl": "/calendar/#welcome-and-orientation"
  },"55": {
    "doc": "And, or, implies",
    "title": "Conjunction",
    "content": "One basic rhetorical device is a take a bunch of statements and group them together with an and. The murderer was cousin Mr. Plum and the weapon was the candlestick and the murder occured in the foyer. The corresponding connective in logic has the fancy name of conjunction is denoted by $\\land$. So if we have expressions $C$ and $D$, then $C \\land D$ is another valid expression. Now let’s think about what we can deduce assuming we know $C$ and $D$. It may seem silly but if we know $C \\land D$ then we know $C$. So we have the following elimination rule for deduction . The notation we use for this move is $\\land_{E_L}$. Similarly, we have the right-sided analog. Then we have a introduction rule that mirrors: if we know that $C$ is true and $D$ is true, then we know that $C$ and $D$ is true. Note that at this level we know very little. For example, $A \\land B \\land C$ is ambigious. It is either \\((A \\land B) \\land C\\) or \\(A \\land (B \\land C)\\) But these are logically equivalent, meaning we can prove one from the other and vice-versa. Below we have \\((A \\land B) \\land C \\vdash A \\land (B \\land C)\\) . Can you give a proof for \\(A \\land (B \\land C) \\vdash (A \\land B) \\land C ~?\\) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/connectives/#conjunction",
    "relUrl": "/notes/propositional_logic/connectives/#conjunction"
  },"56": {
    "doc": "And, or, implies",
    "title": "Disjunction",
    "content": "Another common rhetorical pattern is an argument by cases. Often the cases are exhaustive, like “it is sunny or it is not sunny”. Our introduction rules are pretty straightforward. The elimination rule is a bit more subtle. If we want to reach our goal $C$ and we know that $A$ or $B$ is true, then we need to justify $C$ in two separate cases. One case for when $A$ is true and one case for when $B$ is true. This means that elimination needs to take in a proof $A \\vdash C$ and $B \\vdash C$. Note the lines above $A$ and $B$. This an example of hypothetical reasoning. We have assumed that $A$ is true and provided some argument to derive $C$. Similarly, we have assumed that $B$ is true and argued to $C$. Given both, then know that $A \\lor B \\vdash C$. The superscipts ${}^1$ indicate where we introduce additional assumptions and where we cancel. The numbering helps up keep track of any hypotheses introduced. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/connectives/#disjunction",
    "relUrl": "/notes/propositional_logic/connectives/#disjunction"
  },"57": {
    "doc": "And, or, implies",
    "title": "Implication",
    "content": "Implication is basic step in a (natural language) logical argument. If we know that whenever $X$ is true, then so is $Y$. Then once we know that $X$ is true we get that $Y$ is also. We have a connective symbol $\\to$ for implication. Via our interpretation of proofs, one would likely also think of $X \\vdash Y$ as type of implication. The introduction and elimination rules make this connection clearer. First for elimination, we need to know $X \\to Y$ and $X$ to conclude $Y$. The introduction rule is . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/connectives/#implication",
    "relUrl": "/notes/propositional_logic/connectives/#implication"
  },"58": {
    "doc": "And, or, implies",
    "title": "Bi-implication",
    "content": "Another connective is bi-implication, or commonly called iff for if and only if. It is denoted $\\leftrightarrow$. It has two elimination rules depending on whether we know $X$ or $Y$. If we have a proofs $X \\vdash Y$ and $Y \\vdash X$ then we can conclude $X \\leftrightarrow Y$. Let’s do an example proof to see how these rules interact. Example. Let’s show that \\((A \\to B) \\land (B \\to C) \\vdash A \\to C\\) So if $A$ implies and $B$ implies $C$, then $A$ implies $C$ if we intrepret it using words. Proof. (Expand to view) To prove $A \\to C$, we want introduce a $\\to$. This introduce says we can conclude $A \\to C$ if we can establish $A \\vdash C$. Thus, we can reduce to proving $$ (A \\to B) \\land (B \\to C), A \\vdash C $$ With $A$ and $A \\to B$, we can eliminate to $B$. Then with $B$ and $B \\to C$, we can eliminate to $C$. Below is a full proof. &#9632; . Here is another example. Example. Let’s establish \\(((A \\lor B) \\to C) \\to ((A \\to C) \\land (B \\to C))\\) . Proof. (Expand to view) Recall that $$ ((A \\lor B) \\to C) \\to ((A \\to C) \\land (B \\to C)) $$ is shorthand for $$ \\vdash ((A \\lor B) \\to C) \\to ((A \\to C) \\land (B \\to C)) $$ In other words, we want to proof the formula without assumptions. We \"backwards\" similarly to the last example. To establish a goal of the form $X \\to Y$, we need $X \\vdash Y$. So it suffices to show $$ ((A \\lor B) \\to C) \\vdash ((A \\to C) \\land (B \\to C)) $$ Now to establish a goal with $\\land$ we want to prove both sides of the $\\land$. So we need two proofs $$ (A \\lor B) \\to C \\vdash A \\to C \\\\ (A \\lor B) \\to C \\vdash B \\to C $$ Again we can reverse the introduction rule for $\\to$ to reduce to $$ (A \\lor B) \\to C, A \\vdash C \\\\ (A \\lor B) \\to C, B \\vdash C $$ We can use the introduction rules for $\\lor$ to produce $A \\lor B$ from either $A$ or $B$. Putting it all together we have &#9632; . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/connectives/#bi-implication",
    "relUrl": "/notes/propositional_logic/connectives/#bi-implication"
  },"59": {
    "doc": "And, or, implies",
    "title": "Some conventions",
    "content": "Writing out lots of $( \\ )$ is tedious after awhile. We therefore establish some conventions on how to read a formula without paretheses. First, all of $\\to, \\land,$ and $\\lor$ associate right to left. This means that \\(A \\lor B \\lor C := A \\lor (B \\lor C)\\) . Then $\\to$ binds more weakly that both $\\lor$ and $\\land$. For example \\(A \\lor B \\to C \\land D := (A \\lor B) \\to (C \\land D)\\) . It is important to remember that, in general, the placement of parentheses makes a difference! . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/connectives/#some-conventions",
    "relUrl": "/notes/propositional_logic/connectives/#some-conventions"
  },"60": {
    "doc": "And, or, implies",
    "title": "And, or, implies",
    "content": "Last time, we saw the beginnings of a formal system to represent logical reasoning. Here we introduce some operations on a collection of propositions to build expressions. You can think of the propositions as the atoms of our system and the connectives we introduce as the bonds. In addition, for each connective, we give a introductiona and elimination rule in deduction. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/connectives/",
    "relUrl": "/notes/propositional_logic/connectives/"
  },"61": {
    "doc": "Propositions and proofs",
    "title": "Propositions",
    "content": "We start with the basic building blocks of first-order logic: propositions. The collection of propositions is simply a collection of symbols. Common ones are based on the Roman or Greek alphabets, e.g. \\(A, B, C ,\\ldots \\\\ \\alpha, \\beta, \\gamma, \\ldots\\) But we could just as easily using emoji for our symbols . 😉, 🤯, 🌭, . Right now, they have no meaning attached. Given a set of propositions, we next need rules to combine them into expressions. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/deduction/#propositions",
    "relUrl": "/notes/propositional_logic/deduction/#propositions"
  },"62": {
    "doc": "Propositions and proofs",
    "title": "Deduction",
    "content": "The operations we use to combine expressions will reflect oft-occuring structures in human reason. But, we also need to model the common steps in deduction. Here there are two separate roles: assumptions we are given and goals we want to establish (if we can). In the written (or natural) language, you might see. Example. If $n$ and $m$ are even integers, then so is $n-m$. Recall here that the integers are \\(\\mathbb{Z} = \\lbrace \\ldots, -2,-1,0,1,2, \\ldots \\rbrace\\) . This could also be written as . Example. Let $n$ and $m$ be even integers. The integer $n-m$ is also an even integer. While the latter example is not written an explicit if-then the content is the same. Our set of assumptions is $n$ and $m$ are even integers while our goal is $n-m$ is an even integer. Let’s write down a proof of these statements. We can represent as a table. | Assumptions | Goal | . | $n, m$ even | $n-m$ is even | . Mathematics is well-known for compact (and difficult) notation. In a proof, it is often valuable to unfold the definitions into the statement they represent. We perform this operation on the assumptions. | Assumptions | Goal | . | $n = 2c$ for some integer $c$ | $n-m$ is even | . | $m = 2d$ for some integer $d$ |   | . We also rewrite the goal in the same way. | Assumptions | Goal | . | $n = 2c$ for some integer $c$ | $n-m = 2e$ for some integer $e$ | . | $m = 2d$ for some integer $d$ |   | . To achieve our goal, we want to exhibit the desired $e$ using the assumptions at hand. To make progress, we import another “known fact” into the assumptions context: distribution of multiplication over subtraction. | Assumptions | Goal | . | $n = 2c$ for some integer $c$ | $n-m = 2e$ for some integer $e$ | . | $m = 2d$ for some integer $d$ |   | . | $u(v-w) = uv-uw$ for all integers $u,v,w$ |   | . Now we can an apply distribution with $u = 2, v = c, w = d$ to gain another statement and finish. | Assumptions | Goal | . | $n = 2c$ for some integer $c$ | $n-m = 2e$ for some integer $e$ | . | $m = 2d$ for some integer $d$ |   | . | $u(v-w) = uv-uw$ for all integers $u,v,w$ |   | . | $n - m = 2c - 2d = 2(c-d)$ |   | . | set $e = c-d$ |   | . | $n -m = 2e$ |   | . While we modeled this proof as a table, it is notationally simpler to represent deduction from assumption $A$ to goal $B$ (with some intermediate steps) vertically. And we write $A \\vdash B$ to indicate that we can prove the goal(s) $B$ given the assumption(s) $A$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/deduction/#deduction",
    "relUrl": "/notes/propositional_logic/deduction/#deduction"
  },"63": {
    "doc": "Propositions and proofs",
    "title": "Propositions and proofs",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/deduction/",
    "relUrl": "/notes/propositional_logic/deduction/"
  },"64": {
    "doc": "The definition",
    "title": "Building the $~\\mathbb{Z}~$ from $~\\mathbb{N}$",
    "content": "Intuitively, to go from $\\mathbb{N}$, we just add in $-n$ for each $n \\in \\mathbb{N}$ with $n &gt; 0$. We will see two different ways of handling this. Grothendieck construction. We start with $\\mathbb{N}$ and consider the set $\\mathbb{N} \\times \\mathbb{N}$ of ordered pairs of natural numbers. On this, we impose a relation. We write $(n_1,m_1) \\sim (n_2,m_2)$ if \\(n_1 + m_2 = n_2 + m_1\\) . Theorem. This is an equivalence relation on $\\mathbb{N} \\times \\mathbb{N}$. Proof. (Expand to view) We check that $\\sim$ is reflexive. For any $(n,m)$, we have $(n,m) \\sim (n,m)$ since $n + m = n + m$. Next we check symmetry. Assume that $(n_1,m_1) \\sim (n_2,m_2)$. Then, by definition, we have $$ n_1 + m_2 = n_2 + m_1 $$ Flipping the equality we get $$ n_2 + m_1 = n_1 + m_2 $$ so $(n_2,m_2) \\sim (n_1,m_1)$. Now we check transitivity. Assume that $(n_1,m_1) \\sim (n_2,m_2)$ and $(n_2,m_2) \\sim (n_3,m_3)$. Then, we have $$ n_1 + m_2 = n_2 + m_1 \\\\ n_2 + m_3 = n_3 + m_2 $$ So $$ n_1 + m_3 + n_2 = n_1 + n_3 + m_2 = n_1 + m_2 + n_3 = n_2 + m_1 + n_3 = n_3 + m_1 + n_2 $$ We know that we cancel addition in $\\mathbb{N}$ so we can conclude that $$ n_1 + m_3 = n_3 + m_1 $$ &#9632; . Since we have an equivalence relation, we can form the quotient by that equivalence relation. Definition. The integers, denoted $\\mathbb{Z}$, are the set of equivalence classes of $\\mathbb{Z} := \\mathbb{N} \\times \\mathbb{N}/\\sim$. Ok, maybe this does not look like our familiar integers. Where is $-1$? Where are the $\\mathbb{N}$’s even? . Definition. We will let \\(\\begin{aligned} i : \\mathbb{N} &amp; \\to \\mathbb{Z} \\\\ n &amp; \\mapsto [(n,0)] \\end{aligned}\\) and let \\(\\begin{aligned} j : \\mathbb{N} &amp; \\to \\mathbb{Z} \\\\ n &amp; \\mapsto [(0,n)] \\end{aligned}\\) . Lemma. | Both $i$ and $j$ are injective. | Every element of $\\mathbb{Z}$ is in the image of $i$ or of $j$. | If $i(n) = j(m)$, then $n=m=0$. | . Proof. (Expand to view) Assume that $[(n,0)] = [(m,0)]$. Then we have seen that this is equivalent to $(n,0) \\sim (m,0)$. So $n + 0 = m + 0$ or $n = m$. A similar argument shows that $j$ is injective. Let $[(n,m)]$ be an equivalence class. Assume that $n \\geq m$. Then $$ n + 0 = (n-m) + m $$ So $(n,m) \\sim (n-m,0)$ and $[(n,m)] = [(n-m,0)] = i(n-m)$. Now assume that $n \\leq m$. Then $$ n + m-n = 0 + m $$ so $(n,m) \\sim (0,m-n)$ and $[(n,m)] = [(0,m-n)] = j(m-n)$. Assume that $i(n) = j(m)$. Then $[(n,0)] = [(0,m)]$. So $(n,0) \\sim (0,m)$. Thus, $$ n + m = 0 + 0 = 0 $$ Since $n,m \\in \\mathbb{N}$, we have $n = m = 0$. &#9632; . Despite the unfamiliar definition, we see that $\\mathbb{Z}$ is exactly two copies of $\\mathbb{N}$ with their two $0$’s identified. Furthermore, we can add elements of $\\mathbb{Z}$! First, we start with componentwise addition on $\\mathbb{N} \\times \\mathbb{N}$. \\((n_1,m_1) + (n_2,m_2) := (n_1+n_2,m_1+m_2)\\) . Theorem. The following is a well-defined function. \\(\\begin{aligned} \\mathbb{Z} \\times \\mathbb{Z} &amp; \\to \\mathbb{Z} \\\\ ([(n_1,m_1)],[(n_2,m_2)]) &amp; \\mapsto [(n_1+n_2,m_1+m_2)] \\end{aligned}\\) . Proof. (Expand to view) The possible problem with this as a function is that the output might depend on the representatives of the equivalence. Certainly the function $$ ([(n_1,m_1)],[(n_2,m_2)]) \\mapsto (n_1+n_2,m_1+m_2) $$ is not well-defined. For example, $[(0,0)] = [(1,1)]$ but we get different outputs for $([(0,0)],[(0,0)])$ and $([(1,1)],[(1,1)])$. Assume that $[(n_1,m_1)] = [(n_1^\\prime,m_1^\\prime)]$ and that $[(n_2,m_2)] = [(n_2^\\prime,m_2^\\prime)]$. Then $$ n_1 + m_1^\\prime = n_1^\\prime + m_1 \\\\ n_2 + m_2^\\prime = n_2^\\prime + m_2 $$ The two outputs we get are $(n_1+n_2,m_1+m_2)$ and $(n_1^\\prime + n_2^\\prime, m_1^\\prime + m_2^\\prime)$. We need to check these give the same equivalence class. It is equivalent to checking that $(n_1+n_2,m_1+m_2) \\sim (n_1^\\prime+n_2^\\prime,m_1^\\prime+m_2^\\prime)$. We have $$ n_1+n_2+m_1^\\prime + m_2^\\prime = n_1^\\prime+n_2^\\prime +m_1+m_2 $$ using the equalities above. &#9632; . The function $i$ now satisfies \\(i(n+m) = [(n+m,0)] = [(n,0)] + [(m,0)] = i(n) + i(m)\\) so it intertwines addition in $\\mathbb{N}$ and addition in $\\mathbb{Z}$. Similarly $j(n+m) = j(n) + j(m)$. Example. | We have \\([(n,m)] + [(0,0)] = [(0,0)] + [(n,m)] = [(n,m)]\\) for any $(n,m)$. | We have \\([(n,0)] + [(0,m)] = \\begin{cases} [(n-m,0)] &amp; \\text{ if }n \\geq m \\\\ [(0,m-n)] &amp; \\text{ if } n \\leq m \\end{cases}\\) In particular, $[(n,0)] + [(0,n)] = [(0,0)]$. | . So $[(n,0)]$ is really $n$ while $[(0,n)]$ is $-n$ (though we could reverse the roles here). Theorem. The function \\(\\begin{aligned} \\mathbb{Z} \\times \\mathbb{Z} &amp; \\to \\mathbb{Z} \\\\ ([(n_1,m_1)],[(n_2,m_2)]) &amp; \\mapsto [(n_1n_2 + m_1m_2,n_1m_2+n_2m_1)] \\end{aligned}\\) is well-defined. We omit the proof of this theorem. Let’s look at the outputs of this function on simple entries. | What if we input $i(n)$ and $i(m)$? Then, $i(nm) = [(nm,0)]$ comes out. | What if we inpute $j(n)$ and $j(m)$? Then we get $[(nm,0)] = i(nm)$. | How about $i(n)$ and $j(m)$? Then we get $[(0,nm)] = j(nm)$. | . If you think about this for a little bit, you will recognize it as multiplication on $\\mathbb{Z}$. Next we will compare this to Lean’s Int. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/def/#building-the-mathbbz-from-mathbbn",
    "relUrl": "/notes/integers/def/#building-the-mathbbz-from-mathbbn"
  },"65": {
    "doc": "The definition",
    "title": "The definition",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/def/",
    "relUrl": "/notes/integers/def/"
  },"66": {
    "doc": "Equivalence relations",
    "title": "Like equality but not equal to it",
    "content": "Another common type of relation is the following. Definition. An equivalence relation is a relation $\\cong$ that is . | reflexive | symmetric and | transitive | . Equivalence relations are already built in to Lean’s core code . structure Equivalence {α : Sort u} (r : α → α → Prop) : Prop where refl : ∀ x, r x x symm : ∀ {x y}, r x y → r y x trans : ∀ {x y z}, r x y → r y z → r x z . The prototypical example of an equivalence relation is equality $=$. Here is another example prominent example. Example. Let $m \\in \\mathbb{Z}$. Given two integers $a,b$, we say $a$ is equivelant to $b$ modulo $m$ if $m \\mid b-a$. We write $a \\equiv b \\mod m$ to denote this relation. Let’s check this is reflexive. To say that $a \\equiv a \\mod m$, we need, by definition, $m \\mid a - a = 0$. But all integers divide $0$: $0 = 0 \\cdot m$. So indeed this is reflexive. For symmetry, assume that $a \\equiv b \\mod m$. Then there is some $c$ with $b - a = cm$. We also have \\(a - b = -(b-a) = -(cm) = (-c)m\\) so we have $b \\equiv a \\mod m$. Now let’s check transitivity. Assume that $a \\equiv b \\mod m$ and that $b \\equiv c \\mod m$. Unfolding the definitions, we have $d_1$ and $d_2$ with \\(b - a = d_1 m,~ c - b = d_2 m\\) Then \\(c - a = c - b + b - a = d_1 m + d_2 m = (d_1+d_2)m\\) so $m \\mid c -a$. Another example we have already seen. Example. Bijection of sets is an equivalence relation. For reflexivity, we use that the identity function $\\operatorname{id}_X : X \\to X$ is a bijection. Assume that $f : X \\to Y$ is a bijection. Then we seen that we have an inverse $f^{-1} : Y \\to X$ which is also a bijection. Thus, being in bijection is symmetric. Finally, given bijections $f: X \\to Y$ and $g: Y \\to Z$, the composition $g \\circ f : X \\to Z$ is a bijection giving transitivity. One last example from the beginning of class. Example. Bi-implication of proposition is an equivalence relation. We need to check . | For all propositional formula $X$, we have $X \\leftrightarrow X$. | If $X \\leftrightarrow Y$, then $Y \\leftrightarrow X$ for any pair of propositional formula. | Given $X, Y, Z$ with $X \\leftrightarrow Y$ and $Y \\leftrightarrow Z$, we have $X \\leftrightarrow Z$. | . Here are the proofs in Lean . variable (X Y Z : Prop) theorem biimp_refl : X ↔ X := ⟨fun h =&gt; h,fun h =&gt; h⟩ theorem biimp_symm (h : X ↔ Y) : Y ↔ X := ⟨h.mpr, h.mp⟩ theorem biimp_trans (h₁ : X ↔ Y) (h₂ : Y ↔ Z) : X ↔ Z := ⟨h₂.mp ∘ h₁.mp, h₁.mpr ∘ h₂.mpr⟩ . Very often, properties of interest are preserved by an equivalence relation. Mentally, we start to treat equivalent elements as equal even through they are not. But there is a construction by which equivalence becomes equality. Definition. Let $X$ be a set with an equivalence relation $\\cong$. For $x$ in $X$, the equivalence class of $x$ is \\([x] := \\lbrace x^\\prime \\mid x \\cong x^\\prime \\rbrace\\) In other words, $[x]$ is the set of elements that are equivalent to $x$. Example. Let’s take $m = 2$ and consider the equivalence class of $0$ modulo $2$. Say $0 \\equiv d \\mod 2$ is just saying that $2 \\mid d - 0 = d$. Thus, $d \\in [0]$ if and only if $d$ is even. Similarly, $d \\in [1]$ if and only if $d$ is odd. Lemma. $[x^\\prime] = [x]$ if and only if $x \\cong x^\\prime$. Proof. (Expand to view) Assume that $[x^\\prime] = [x]$ then $x^\\prime \\in [x^\\prime]$ since $x^\\prime \\cong x^\\prime$ from reflexivity of $\\cong$. Then $x^\\prime \\in [x]$ so by definition $x \\cong x^\\prime$. Now assume that $x \\cong x^\\prime$. We have to show that $[x] = [x^\\prime]$ as sets. Assume that $y \\in [x]$. By definition, we have $x \\cong y$. From reflexivity, we have $x^\\prime \\cong x$. Then transitivity tells us that $x^\\prime \\cong y$. So by definition $y \\in [x^\\prime]$. Now assume that $y \\in [x^\\prime]$. Then $x^\\prime \\cong y$ be definition. Using transitivity, we get $x \\cong y$ and $y \\in [x]$. Thus, $[x] = [x^\\prime]$ as sets. &#9632; . Using the previous lemma, we learn that $[0]$ and $[1]$ are the only equivalence classes mod $2$. If $d$ is odd, then $[d] = [1]$. If $d$ is even, $[d] = [0]$. Definition. The quotient by an equivalence relation $\\cong$ is the set of equivalence classes of $\\cong$: \\(X/\\cong := \\lbrace [x] \\mid x \\in X \\rbrace\\) . The quotient comes with a quotient function \\(\\pi : X \\to X/ \\cong \\\\ x \\mapsto [x]\\) . Example. Thus, $\\mathbb{Z}/\\equiv_2 = \\lbrace [0],[1] \\rbrace$. More generally, \\(\\mathbb{Z}/\\equiv_m = \\lbrace [0], [1], [2], \\ldots, [m-1] \\rbrace\\) Since any integers $a$ can be written as $a = r + qm$ for $0 \\leq r &lt; m$. Here $r$ is the remainder under division by $m$. Example. The quotient of Prop by ↔ is in bijection with the set of truth tables. This follows from completeness and soundness of propositional logic. The set $X/\\cong$ satisfies a universal property with respect to functions $f : X/\\cong \\to Y$. More precisely, we have the following theorem. Theorem. Let $(X,\\cong)$ be a set with an equivalence relation. Then, for any function $f : X \\to Y$ which satisfies the condition $x \\cong x^\\prime \\to f(x) = f(x^\\prime)$, we have a unique function $\\overline{f} : X / \\cong \\to Y$ with $\\overline{f} \\circ \\pi = f$. Proof. (Expand to view) First, we tackle uniqueness. Since $\\pi$ is surjective, it has a right inverse. Thus, if $\\overline{f} \\circ \\pi = \\overline{f}^\\prime \\circ \\pi$, we can compose with the right inverse to get $\\overline{f} = \\overline{f}^\\prime$. Thus, the condition that $\\overline{f} \\circ \\pi = f$ uniquely determines $\\overline{f}$ _if_ it exists. To show existence, we \"try\" to define $\\overline{f}([x]) = f(x)$. The essential problem here is that, as we have seen, we can have $[x] = [x^\\prime]$, with $x \\neq x^\\prime$. So from this definition if $x \\cong x^\\prime$, we also have $\\overline{f}([x]) = f(x^\\prime)$. So we need to check that if $[x] = [x^\\prime]$ that $\\overline{f}([x]) = \\overline{f}([x^\\prime])$. If $[x] = [x^\\prime]$, we know that $x \\cong x^\\prime$. By assumption we have $f(x) = f(x^\\prime)$, but this says that $$ \\overline{f}([x]) = f(x) = f(x^\\prime) = \\overline{f}([x^\\prime]) $$ and our attempt at a function is actually a well-defined function. &#9632; . The previous theorem says that composing with $\\pi$ gives a bijection between the following two sets of functions \\(\\lbrace g : X/\\cong \\to Y \\rbrace \\overset{- \\circ \\pi}{\\to} \\lbrace f : X \\to Y \\mid f(x) = f(x^\\prime) \\text{ whenever } x \\cong x^\\prime \\rbrace\\) Thus, we can understand functions out of $X/\\cong$ in terms of data that does not explicitly reference $X/\\cong$ itself. This is what is meant by a universal property: the set of functions out of $X/\\cong$ to $Y$ are all functions $X \\to Y$ satisfies some condition. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/equiv/#like-equality-but-not-equal-to-it",
    "relUrl": "/notes/relations/equiv/#like-equality-but-not-equal-to-it"
  },"67": {
    "doc": "Equivalence relations",
    "title": "Equivalence relations",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/equiv/",
    "relUrl": "/notes/relations/equiv/"
  },"68": {
    "doc": "Examples",
    "title": "Example proofs and non-proofs",
    "content": "With quantifiers, functions, and equality, we have a greater richness of expression. Since each of the symbols mimics standard rhetorical techniques, we still recognize some common patterns as encapsulated via provable formula. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/examples/#example-proofs-and-non-proofs",
    "relUrl": "/notes/predicate/examples/#example-proofs-and-non-proofs"
  },"69": {
    "doc": "Examples",
    "title": "Order of quantifiers",
    "content": "Can we prove \\(\\forall y~ \\exists x~ A(x,y) \\to \\exists x~ \\forall y~ A(x,y)\\) in general? . To approach this, it makes sense to try to find a simple model and figure if the statement is true. Let’s take $\\mathbb{N}$ and interpret $A(x,y)$ as $x=y$. Then, in natural language, the head of the implication says that for any number $y$ there is some other number $x$ such that $x=y$. This of course is always true! We can take our desired $y$ to be $x$. The tail of the implication says that there is a single number $x$ such that for every number $y$ we have $x=y$. This is clearly false as not all numbers are equal. Thus, this formula cannot be proven. We cannot exchange quantifiers thoughtlessly. Is the other direction provable? Our initution from the particular in encouraging and in fact it is. We use new variable labels to make things clear. The intuition of the proof here says that we can the witness of the first existential quantifier as the witness of the second. We can freely exchange the same quantifiers. Below is a proof of $ \\forall x~ \\forall y~ A(x,y) \\vdash \\forall y~ \\forall x~ A(x,y)$. Similiarly, we can exchange existential quantifiers. Given this we often write $\\forall x~ y$ in place of $\\forall x~ \\forall y~$ and $\\exists x~ y$ for $\\exists x~ \\exists y$ to shorten notation. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/examples/#order-of-quantifiers",
    "relUrl": "/notes/predicate/examples/#order-of-quantifiers"
  },"70": {
    "doc": "Examples",
    "title": "Negation and quantifiers",
    "content": "We have seen how to exchange $\\neg$ and other connectives like $\\land$ and $\\lor$. Let’s try to understand $\\neg (\\exists x~ A(x))$. This is saying no matter what the value of $x$ is $A(x)$ should not be true. That looks much like $\\forall x~ \\neg A(x)$. This also comports with our analogy between $\\forall$ and $\\land$ and $\\exists$ and $\\lor$. Let’s try to give a proof. Similarly, $\\neg \\forall x~ A(x) \\leftrightarrow \\exists x~ \\neg A(x)$ is a valid formula. In fact, we have already been using this logical pattern in our arguments. It is usually called finding a counter-example. The counter-example being the witness to $\\exists x~ \\neg A(x)$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/examples/#negation-and-quantifiers",
    "relUrl": "/notes/predicate/examples/#negation-and-quantifiers"
  },"71": {
    "doc": "Examples",
    "title": "Quantifiers and con/disjunction",
    "content": "From our analogy between $\\forall$ and $\\land$ and $\\exists$ and $\\lor$, we can guess at the behavior when quantifiers and con/disjunction interact. Indeed, the following are valid formula. \\(\\forall x~ (A(x) \\land B(x)) \\leftrightarrow \\forall x~ A(x) \\land \\forall x~ B(x) \\\\ \\exists x~ (A(x) \\lor B(x)) \\leftrightarrow \\exists x~ A(x) \\lor \\exists x~ B(x)\\) . Let’s think about $\\forall x~ (A(x) \\lor B(x))$ vs $\\forall x~ A(x) \\lor \\forall x~ B(x)$. Inituitively, whether $A(x)$ or $B(x)$ is true might depend on $x$. For example, in the model $\\mathbb{N}$ where we interpret $A(x)$ as $x$ is even and $B(x)$ as $x$ is odd. Then, we know that everyone number is either even or odd. But not every number is even. Neither is every number odd. There is a still an implication. Similarly, one direction of distrubition of $\\exists$ over $\\land$ is valid. But if we use the model $\\mathbb{N}$ with $A(x)$ being $x &gt; 2$ and $B(x)$ being $x &lt; 1$. Then $\\exists x~ A(x) \\land \\exists x~ B(x)$ is true as there are numbers greater than $2$ and there are also numbers less than $1$ (namely $0$). However, $\\exists x~ (A(x) \\land B(x))$ is not true since no number is both less than $1$ and greater than $2$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/examples/#quantifiers-and-condisjunction",
    "relUrl": "/notes/predicate/examples/#quantifiers-and-condisjunction"
  },"72": {
    "doc": "Examples",
    "title": "Unique existence \\(~\\exists !\\)",
    "content": "Often, in mathematics, we are concerned with whether a list of conditions can completely specify something, be it a number, a formula, or something else. This pattern of logic is common enough that we introduce some shorthand notation. The formula \\(\\exists x~ (A(x) \\land \\forall y~ (A(y) \\to (x=y)))\\) says that there is some $x$ that makes $A(x)$ true and if there is any other value that makes $A(x)$ true then in fact it had to be the original value. This formula get its own compact notation: $\\exists ! x~ A(x)$. This is read as there exists a unique $x$ satisifying $A(x)$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/examples/#unique-existence-exists-",
    "relUrl": "/notes/predicate/examples/#unique-existence-exists-"
  },"73": {
    "doc": "Examples",
    "title": "Examples",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/examples/",
    "relUrl": "/notes/predicate/examples/"
  },"74": {
    "doc": "Logical formulas",
    "title": "Propositions in Lean",
    "content": "The engine that makes Lean interactive theorem verifier and prover is the idea that every piece of data has a type. This include mathematical data. So the natural numbers have (are) a type Nat as are the real numbers. Individual natural numbers are called terms of type Nat. To express this relationship, we write 5: Nat. If you know a little set theory, it will be harmless to imagine replacing the semi-colon with an element symbol $\\in$. Lean has type for propositions called Prop. We can think of this as the whole universe of possible propositions. A term of Prop is a individual proposition. Suppose I have propositional variables $A,B,C$ in my logic. How do I tell Lean about them? We declare them as variables. variable (A B C : Prop) . A useful tool built into the system is the ability to check what Lean believes an expression means. variable (D : Prop) #check D . The window pane on the right hand side of the editor reports D: Prop which Lean reporting back that indeed it thinks D is a proposition. Next we can combine propositional variables into formulas. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/formulas/#propositions-in-lean",
    "relUrl": "/notes/lean/formulas/#propositions-in-lean"
  },"75": {
    "doc": "Logical formulas",
    "title": "Connectives",
    "content": "Let’s see how each of our connectives, $\\neg, \\to, \\lor, \\land,$ and $\\leftrightarrow$ are encoded in Lean. Here is negation . variable (A : Prop) #check ¬ A . Lean tells that indeed ¬ A : Prop. Note that ¬ is a Unicode symbol (like emoji). In general, we do not have those on our keyboard but the editor nows how to fill it in if we type \\neg and hit the spacebar. Unicode is pretty but we can also use standard (ASCII) characters to access negation. variable (A : Prop) #check Not A . will also report ¬ A : Prop. We mentioned that everything in Lean has a type. What about Not? Checking it returns Not : Prop → Prop. If we interpret this (Unicode) arrow as an assignment, this makes sense. Given a formula X, ¬ X is another one. Next, we turn to implication, $\\to$. It has the same Unicode arrow ( typeset as \\to) . variable (A B : Prop) #check A → B . gives that A → B : Prop. For conjunction, $\\land$, we have (at least) three notations that all work: . variable (A B : Prop) #check A ∧ B #check And A B #check A /\\ B . Here ∧ is typed using \\and. Next we have disjunction. variable (A B : Prop) #check A ∨ B /- typed as \\or -/ #check Or A B #check A \\/ B . Note the text between /- -/. This tells Lean that to ignore the what is written. They are only comments and not commands. Finally, bi-implication. variable (A B : Prop) #check A ↔ B /- typed as \\iff -/ #check Iff A B . Aside from negation, all of the other connectives take in two formulas and yield a single one. So if you #check Iff you will get Iff : Prop → Prop → Prop. What happens if you #check ↔? . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/formulas/#connectives",
    "relUrl": "/notes/lean/formulas/#connectives"
  },"76": {
    "doc": "Logical formulas",
    "title": "Logical formulas",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/formulas/",
    "relUrl": "/notes/lean/formulas/"
  },"77": {
    "doc": "Groups",
    "title": "What are $~\\mathbb{Z}~$ and $~\\mathbb{Z}/m\\mathbb{Z}~$ really?",
    "content": "We make $\\mathbb{Z}$ from $\\mathbb{N}$ to have the benefit of undoing addition. Usually we think of subtraction as undoing addition but subtraction is just addition of negative numbers. To get to $\\mathbb{Z}$, we take each $n \\in \\mathbb{N}$ and we “create” a new element $-n$ that is characterized by the property \\(n + (-n) = 0 = (-n) + n\\) We’ve seen how to do this via a quotient of $\\mathbb{N} \\times \\mathbb{N}$ by an equivalence relation and via inductive types in Lean. The structure of $(\\mathbb{Z},+)$ is a particular instance of a general notion of a group. Definition. A group is a triple of data $(G,\\cdot,e)$ consisting of . | a set $G$, | a binary operation $\\cdot : G \\times G \\to G$, and | an element $e \\in G$ | . which together satisfy the following conditions: . | $\\cdot$ is associative: $a \\cdot (b \\cdot c) = (a \\cdot b) \\cdot c$ | evaluating $\\cdot$ on $e$ is the identity function (on either side): $a \\cdot e = e \\cdot a = a$ | and there exists inverses: for each $a \\in G$ there is some $b \\in G$ with $a \\cdot b = b \\cdot a = e$. | . Often when $\\cdot$ and $e$ are clear from the context we just use the underlying set $G$ to refer to a group. The element $e \\in G$ is called the identity element of $G$. Example. $\\mathbb{Z}$ is a group under addition where $\\mathbb{N}$ is not a group under addition. The defect with $\\mathbb{N}$ is the lack of additive inverses which is rectified by passage to $\\mathbb{Z}$. Example. $\\mathbb{Z}/m\\mathbb{Z}$ is group for all $m$ under modular addition. For associativity, we can use that for $\\mathbb{Z}$: \\([n] + ([m] + [k]) = [n] + [m+k] = [n+(m+k)] \\\\ = [(n+m)+k] = [n+m] + [k] = ([n] + [m]) + [k]\\) The identity element of $\\mathbb{Z}/m\\mathbb{Z}$ is the equivalence class of $0$. We can see that $[-n]$ is the inverse to $[n]$ since \\([n] + [-n] = [n+(-n)] = [0] = [(-n)+n] = [-n] + [n]\\) But in $\\mathbb{Z}/m\\mathbb{Z}$ there are more efficient choices for representative of the equivalence class of the inverse. For example, assume we start with $0 \\leq n &lt; m$. Then \\([n] + [m-n] = [m] = [0] = [m] = [m-n] + [n]\\) so $m-n$ is another representative for $[-n]$ and it satisfies $0 &lt; m - n \\leq m$. Example. The integers are not a group under multiplication because for a general $n \\in \\mathbb{Z}$, there is no $m$ with $nm = 1$. Theorem. Let $X$ be a set. Then the set of all self-bijections of $X$ is a group under composition. Proof. (Expand to view) We have seen that function composition is associative. The identity element is the identity function $\\operatorname{id}_X$. Composition with the identity function returns the original function. We have already seen that $f: X \\to X$ is a bijection if and only if it has a inverse $g: X \\to X$, ie a function $g$ such that $g \\circ f = f \\circ g = \\operatorname{id}$. So we have inverses. &#9632; . Definition. Let $X$ be a set. The symmetric group on $X$, denoted $S_X$, is set of all self-bijections of $X$ under composition. Example. Let’s take the symmetric group of the set $\\lbrace 0,1,2,3\\rbrace$. We can represent an element $f: \\lbrace 0,1,2,3 \\rbrace \\to \\lbrace 0,1,2,3 \\rbrace$ as a list \\(f \\mapsto f(0) f(1) f(2) f(3)\\) without losing any information. Thus, $1032$ would be the function that swaps $0$ and $1$ and swaps $2$ and $3$. The symmetric group behaves a way that might be unexpected from the examples above. Let’s compose $0321$ and $1023$ in the two orders: \\(0321 \\circ 1023 = 3021 \\\\ 1023 \\circ 0321 = 1320\\) Note that $3021 \\neq 1320$. In the symmetric group, the order of applying the group operation matters whereas in $\\mathbb{Z}$ or $\\mathbb{Z}/m\\mathbb{Z}$ it doesn’t. Definition. We say a group $G$ is a commutative or abelian if $a \\cdot b = b \\cdot a$ for all $a,b \\in G$. If $X$ has more than two elements, then $S_X$ is never abelian. The symmetric group is, as the name suggests, the group of symmetries of the underlying set. More generally, given a set with extra mathematical structure, it is very natural to consider the set of self-bijections that perserve the structure. These also form groups. Example. Let’s consider functions $f : \\mathbb{Z} \\to \\mathbb{Z}$ which preserve addition and satisfy $f(0) = 0$. Then, for positive $n$, since $n = 1 + \\cdots + 1$, we have \\(f(n) = f(1 + \\cdots + 1) = f(1) + \\cdots + f(1) = nf(1)\\) For $-n$, we have \\(f(n) + f(-n) = f(n + (-n)) = f(0) = 0\\) so $f(-n) = -f(n)$ and $f$ is completely determined by the value $f(1)$. What can $f(1)$ be for $f$ to be a bijection? If $f(1) = 0$, then $f(n) = 0$ for all $n$. Not so good. For $f$ to be surjective, we need to be able to write every integer as a multiple of $f(1)$. In other words, $f(1)$ has to divide $n$ for all $n \\in \\mathbb{Z}$. This forces $f(1) = \\pm 1$. So the set of symmetries $\\mathbb{Z}$ under addition is a two element set given by the identity function and the negative function $n \\mapsto -n$. This is rather small compared to the symmetric group of $\\mathbb{Z}$ the set which is infinite. There are the same number of symmetries of $(\\mathbb{Z},+)$ as there are elements of the group $\\mathbb{Z}/2\\mathbb{Z}$: two. Are they the same group? . On its face, the answer is no but there is a natural way to loosen equality. Definition. Let $G$ and $H$ be groups. An homomorphism of groups is a function $\\phi : G \\to H$ such . | $\\phi(e_G) = e_H$ and | $\\phi(a\\cdot b) = \\phi(a) \\cdot \\phi(b)$ | . An isomorphism is a bijective homomomorphism. If $G = H$, we call an isomorphism an automorphism. Above we computed the automorphism group of $(\\mathbb{Z},+)$. It is in fact isomorphic to $\\mathbb{Z}/2\\mathbb{Z}$ using the function \\([0] \\mapsto \\operatorname{id}_{\\mathbb{Z}} ~,~ [1] \\mapsto (n \\mapsto -n)\\) You should use the definitions above to check that this indeed is a homomorphism. Understanding the structure of groups is a fundamental pursuit throughout all of math. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/group/#what-are-mathbbz-and-mathbbzmmathbbz-really",
    "relUrl": "/notes/integers/group/#what-are-mathbbz-and-mathbbzmmathbbz-really"
  },"78": {
    "doc": "Groups",
    "title": "Groups",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/group/",
    "relUrl": "/notes/integers/group/"
  },"79": {
    "doc": "Functions and sets",
    "title": "Interactions between functions and sets",
    "content": "If we already know about sets, then we can actually construct functions directly. At first the definition looks a little strange. Definition. Let $X$ and $Y$ be sets. A function $f : X \\to Y$ is a subset \\(\\Gamma \\subseteq X \\times Y\\) satisfying the condition \\(\\forall~ x, \\exists !~ (x',y) \\in \\Gamma, x = x'\\) In other words, in our subset of pairs, $\\Gamma$, given an element $x \\in X$, there is one and exactly one ordered pair of the form $(x,y)$. Given a function, $\\Gamma_f$, we can define application of the function to an element $x \\in X$ as \\(x \\mapsto y\\) where $y$ is the unique element of $Y$ making $(x,y) \\in \\Gamma_f$ hold. Given a function of the familiar type $f : X \\to Y$, we can make subset of $X \\times Y$ as \\(\\Gamma_f := \\lbrace (x,f(x)) \\mid x \\in X \\rbrace\\) This is commonly called the graph of $f$. Given a $f : A \\to B$ and a subset $X \\subseteq A$, we define a new subset of $B$. Definition. The image of $X$ under the function $f$ is the set \\(f(X) := \\lbrace b \\mid \\exists~ x \\in X, f x = b \\rbrace\\) . Example. If \\(f : \\mathbb{N} \\to \\mathbb{N} \\\\ n \\mapsto n^2\\) is our function, then $f(\\mathbb{N})$ is the set of natural numbers which are squares. If we instead start with a subset $Y \\subseteq B$, then we can create a subset of $A$. Definition. The pre-image (or inverse image) of $Y$ is the set \\(f^{-1}(Y) := \\{ a \\mid f(a) \\in Y \\}\\) . Coming back to our example of the squaring map, we would have \\(f^{-1}(\\lbrace 0,1,2,3,4,5,6,7,8 \\rbrace) = \\{0,1,2\\}\\) . Lemma. $f$ is surjective if and only if $f(X) = Y$. Proof. (Expand to view) Assume that $f$ is surjective. From the definition, we know that $f(X) \\subseteq Y$. For the other direction, assume we have $y \\in Y$. Since $f$ is surjective, there exists a $x \\in X$ with $f(x) = y$. But, by definition of the image $X$ under $f$, this says $y \\in f(X)$. Assume that $f(X) = Y$. To show that $f$ is surjective, we choose some $y \\in Y$ and look for an $x$ with $f(x) = y$. But, by definition of the image, we know there is such an $x$. &#9632; . More generally, we get two statements describing what happens when we take images of pre-images and pre-images of images. Lemma. For any $Y$, we have \\(f(f^{-1} Y) \\subseteq Y\\) . Proof. (Expand to view) Let $b \\in f(f^{-1} Y)$. We unfold the definitions to check this. Since $b \\in f(f^{-1} Y)$, we have, by definition, there exists some $a \\in f^{-1} Y$ such that $f(a) = b$. Since $a \\in f^{-1} Y$, by definition, we have $f(a) \\in Y$. Thus, $b = f(a) \\in Y$. &#9632; . Note that this is not an equality in general. If we have an equality, then every element of $Y$ is in the image of $f$ applied to $f^{-1} Y$. In particular, it forces $f$ to surject onto $Y$. Lemma. For any $X$, we have \\(X \\subseteq f^{-1}(f(X))\\) . Proof. (Expand to view) Again, this comes from chaining together the definitions. Assume that $a \\in X$. Then $f(a) \\in f(X)$. Thus, by definition, $a \\in f^{-1} (f(X))$. &#9632; . Again this is not always an equality. For example, lets taking our squaring map but now view it a function $\\mathbb{Z} \\to \\mathbb{Z}$. If $X = \\mathbb{N}$, then $f^{-1}(f(\\mathbb{N})) = \\mathbb{Z}$. Both images and pre-images behave well with respect to unions and intersections. We have . -- The union of inverse images is the inverse image of the union theorem union_preimage (f : α → β) (Y Y' : Set β) : f⁻¹ (Y ∪ Y') = f⁻¹ Y ∪ f⁻¹ Y' := by rfl -- The intersection of inverse images is the inverse image of -- the intersection theorem inter_preimage (f : α → β) (Y Y' : Set β) : f⁻¹ (Y ∩ Y') = f⁻¹ Y ∩ f⁻¹ Y' := by rfl -- The union of images is the image of the union theorem union_image (f : α → β) (X X' : Set α) : Image f (X ∪ X') = Image f X ∪ Image f X' := by set_extensionality b · intro h have ⟨a,h'⟩ := h cases h'.left with | inl hl =&gt; exact Or.inl ⟨a,hl,h'.right⟩ | inr hr =&gt; exact Or.inr ⟨a,hr,h'.right⟩ · intro h cases h with | inl hl =&gt; have ⟨a,h'⟩ := hl exact ⟨a,⟨Or.inl h'.left,h'.right⟩⟩ | inr hr =&gt; have ⟨a,h'⟩ := hr exact ⟨a,⟨Or.inr h'.left,h'.right⟩⟩ -- The image of the intersection is a subset of the -- intersection of the image theorem inter_image (f : α → β) (X X' : Set α) : Image f (X ∩ X') ⊆ Image f X ∩ Image f X' := by intro b h have ⟨a,h'⟩ := h exact ⟨⟨a,⟨h'.left.left,h'.right⟩⟩,⟨a,⟨h'.left.right,h'.right⟩⟩⟩ . In general, $f (X \\cap X’) \\neq f(X) \\cap f(X’)$. For example, take the unique function $f : \\mathbb{Z} \\to \\lbrace 0 \\rbrace$, $X$ the odd integers, and $X’$ the even integers. Then $X \\cap X’ = \\varnothing $ but $f(X) \\cap f(X’) = \\lbrace 0\\rbrace$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/in_sets/#interactions-between-functions-and-sets",
    "relUrl": "/notes/functions/in_sets/#interactions-between-functions-and-sets"
  },"80": {
    "doc": "Functions and sets",
    "title": "Being in bijection",
    "content": "Saying that we have a bijection $f : A \\to B$ is quite strong. For each element of $a$ there is exactly one element of $b$ and vice-versa. You go back and forth by apply $f$ or its inverse. While particular bijections can be highly non-trivial, we can still abstract them as a “change of labels” for a set. Example. Let $R_m$ be the complex roots of the polynomial $z^m - 1$. The roots are of the form $e^{2 \\pi \\imath j/m}$ for $j = 0,\\ldots,m-1$. Thus, there is a bijection between the set of $R_m$ and the set $[m] := \\lbrace 0, 1, \\ldots, m-1 \\rbrace$. One of this is very simple, $[m]$, while the other carries interesting algebraic information. Definition. We say $A$ and B$ are in bijection if there exists a bijection $f : A \\to B$. We write $A \\cong B$ if $A$ and $B$ are in bijection. Even if $A \\cong B$, there is, in general, not a single bijection nor a canonical choice for one. Let’s look at self-bijections $\\sigma : [m] \\to [m]$. In general, if we have an injective function $f : [m] \\to A$, then we have at least $m$ distinct (up to equality) elements of $A$. Now, if $A = [m]$, then we only have $[m]$ distinct elements to being with. Thus, $\\sigma : [m] \\to [m]$ is bijective if and only if it is injective. Similarly, if $\\sigma : [m] \\to [m]$ is surjective, then we have to have $m$ elements in $\\sigma([m])$. But, for any function with domain $[m]$, the image can have at most $m$ elements since we only have $m$ elements to plug in to $f$. If we have exactly $m$ elements, then $\\sigma$ must be injective. Each time $\\sigma(i) = \\sigma(j)$, with $i \\neq j$, we drop the size of the image of by 1. Thus, $\\sigma$ is bijective if and only if it is surjective. We have established the following result. Theorem. (Pigeonhole Principle) A function $f : X \\to Y$ with $X, Y$ finite and of the same order is a bijection if and only if it is an injection if and only if it is a surjection. Similar logic gives the . Corollary. If $f : X \\to Y$ is a function between finite sets and $|X| &lt; |Y|$, then $f$ is not surjective. If $|X| &gt; |Y|$, then $f$ is not injective. The previous results tell us to recognize bijections between finite sets. We see that for $\\sigma : [m] \\to [m]$ to be a bijection. We have some value $\\sigma(0)$. Then there is some value $\\sigma(1) \\neq \\sigma(0)$. Then $\\sigma(2) \\neq \\sigma(1)$ and $\\neq \\sigma(0)$ . Finally, leaving a unique choice for $\\sigma(m)$. So a self-bijection of $[m]$ is scrambling of the order of the numbers $0,1,2,\\ldots, m-1$. There are $m$ choices for the value of $0$, $m-1$ choices for $1$,., $2$ choices for $m-2$, and a single choice for $m-1$. Thus, we have \\(m! := m(m-1)(m-2) \\cdots 2 \\cdot 1\\) unique self-bijections of $[m]$. Such self-bijections are called permutations. Example. Let’s write down all the permutations of the set $[3]$. We as (possibly) disordered lists: \\(123, 132, 213, 312, 231, 321\\) The first entry of the list is the identity function. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/in_sets/#being-in-bijection",
    "relUrl": "/notes/functions/in_sets/#being-in-bijection"
  },"81": {
    "doc": "Functions and sets",
    "title": "Functions and sets",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/in_sets/",
    "relUrl": "/notes/functions/in_sets/"
  },"82": {
    "doc": "Homework",
    "title": "Homework",
    "content": ". | Homework 12. Due Date: November 14 . | Homework 11. Due Date: November 7 . | Homework 10. Due Date: October 31 . | Homework 9. Due Date: October 24 . | Homework 8. Due Date: October 17 . | Homework 7. Due Date: October 10 . | Homework 6. Due Date: October 3 . | Homework 5. Due Date: September 26 . | Homework 4. Due Date: September 19 . | Homework 3. Due Date: September 6 . | Homework 2. Due Date: September 6 . | Homework 1. Due Date: August 26 . | Homework 0. Due Date: August 22 . | . ",
    "url": "https://300.f22.matthewrobertballard.com/homework/",
    "relUrl": "/homework/"
  },"83": {
    "doc": "Intro to Proofs",
    "title": "HNRS:  Transition to Advanced Mathematics",
    "content": "Thinking and communicating like a mathematician. ",
    "url": "https://300.f22.matthewrobertballard.com/#hnrs--transition-to-advanced-mathematics",
    "relUrl": "/#hnrs--transition-to-advanced-mathematics"
  },"84": {
    "doc": "Intro to Proofs",
    "title": "Week 15 Announcement",
    "content": "Dec 2 &middot; 0 min read For the last week of classes, make sure . | to present at least once (this is a quarter of your grade completely in your control) and | to turn in any revisions by the end of Friday December 2 (all course materials can be found at our GitHub org) | . Each presentation after the first will convert your lowest homework or quiz to a 100%. I’ve sent out an assignment in Teams that just serves to report your current grade. Announcements . ",
    "url": "https://300.f22.matthewrobertballard.com/",
    "relUrl": "/"
  },"85": {
    "doc": "Intro to Proofs",
    "title": "Syllabus",
    "content": "The syllabus can be found at the syllabus tab. ",
    "url": "https://300.f22.matthewrobertballard.com/#syllabus",
    "relUrl": "/#syllabus"
  },"86": {
    "doc": "Intro to Proofs",
    "title": "Calendar",
    "content": "At the calendar tab, you will find our topic schedule for each class along with the pre-reading, worksheets for that class, and due dates for assignments. ",
    "url": "https://300.f22.matthewrobertballard.com/#calendar",
    "relUrl": "/#calendar"
  },"87": {
    "doc": "Intro to Proofs",
    "title": "Notes",
    "content": "The notes tab is where you can find the course reading. ",
    "url": "https://300.f22.matthewrobertballard.com/#notes",
    "relUrl": "/#notes"
  },"88": {
    "doc": "Intro to Proofs",
    "title": "Homework",
    "content": "There are tabs for class homework. Homework is turned in weekly and in groups of 3-4. For more information, see the Syllabus. ",
    "url": "https://300.f22.matthewrobertballard.com/#homework",
    "relUrl": "/#homework"
  },"89": {
    "doc": "Intro to Proofs",
    "title": "Me",
    "content": "If you are interested in a bit about who I am and what I do, check out the me tab or visit my website. ",
    "url": "https://300.f22.matthewrobertballard.com/#me",
    "relUrl": "/#me"
  },"90": {
    "doc": "Intro to Proofs",
    "title": "Intro to Proofs",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/",
    "relUrl": "/"
  },"91": {
    "doc": "Induction",
    "title": "Recursion for proofs",
    "content": "We revert to using $0$ for zero and $n+1$ for $s(n)$. Recursion allows us to build functions with domain $\\mathbb{N}$ by knowing . | $f(0)$ and | $f(n+1)$ given $f(n)$ | . Induction allows us to construct proofs in a similar fashion. Theorem (Principle of Induction). Let $P(n)$ be a predicate on $n \\in \\mathbb{N}$. Assume that . | We have a proof of $P(0)$ and | Given any $n$, we can prove $P(n) \\to P(n+1)$ | . Then we can prove $\\forall n,~ P(n)$. Proof. (Expand to view) Let $$ X = \\lbrace n \\in \\mathbb{N} \\mid P(n) \\rbrace $$ In other words, $X$ is the subset of $\\mathbb{N}$ consisting exactly of the $n \\in \\mathbb{N}$ where we can prove $P(n)$. Then $0 \\in X$ and if $n \\in X$, we have $n+1 \\in X$. From the final axiom for $\\mathbb{N}$, we have $\\mathbb{N} = X$. In other words, we can prove $P(n)$ for all $n$. &#9632; . The base case of induction is the proof of $P(0)$ and the induction step is the proof of $\\forall~ n, P(n) \\to P(n+1)$. Here is a proof in Lean. theorem induction {P : Nat → Prop} (base : P 0) (ind : ∀ n, P n → P (n+1)) (m : Nat) : P m := match m with | 0 =&gt; base | n+1 =&gt; ind n (induction base ind n) . We use recursion to use the proof for n given by induction base ind n to handle the induction step. Example. Let’s prove that \\(\\sum_{i=0}^n i = \\frac{n(n+1)}{2}\\) for all $n$. To apply induction, we need to prove two things: . | Base case: the statement is true for $n=0$ | Induction step: if the statement is true for $n$, then it is also true for $n+1$. | . Once we do this, we can apply to induction and conclude that the statement is true for all $n$. We treat the base case: $n=0$. Then the left-hand side is \\(\\sum_{i=0}^0 i = 0\\) and the right-hand side is \\(\\frac{0 \\cdot 1}{2} = 0\\) which are equal. Next we do the induction step. Assume we know that \\(\\sum_{i=0}^n i = \\frac{n(n+1)}{2}\\) We want to show that \\(\\sum_{i=0}^{n+1} i = \\frac{(n+1)(n+2)}{2}\\) We note that \\(\\sum_{i=0}^{n+1} i = \\sum_{i=0}^n i + (n+1)\\) Using the induction hypothesis, we have \\(\\sum_{i=0}^{n+1} i = \\frac{n(n+1)}{2} + (n+1)\\) Getting a common denominator and simplifyin we get \\(\\frac{n(n+1)}{2} + (n+1) = \\frac{n(n+1) + 2(n + 1)}{2} = \\frac{(n+1)(n+2)}{2}\\) which finishes the induction step. Appealing to induction, we can conclude that \\(\\sum_{i=0}^n i = \\frac{n(n+1)}{2}\\) for all $n$. Let’s see how this looks in Lean. -- We import results on Nat beyond those in Lean core import Std.Data.Nat.Lemmas -- Here is a recursive definition of our sum def LinearSum (n : Nat) : Nat := match n with | 0 =&gt; 0 | n+1 =&gt; n+1 + LinearSum n theorem linear_sum (n : Nat) : LinearSum n = n*(n+1) / 2 := by -- We first show it suffices to prove the result with -- denominators cleared suffices h : 2*(LinearSum n) = n*(n+1) by rw [←h,Nat.mul_comm] -- The simplifier simp can often help where rw doesn't let h : 0 &lt; 2 := by simp exact Eq.symm (Nat.mul_div_cancel (LinearSum n) h) -- Now our goal is 2*(LinearSum n) = n*(n+1) and -- we can use the induction tactic to prove it induction n with -- We handle the base case | zero =&gt; rw [Nat.zero_mul]; rfl -- We then do the induction step where -- hn : 2 * LinearSum n = n * (n + 1) and our -- goal is 2 * LinearSum (Nat.succ n) = -- Nat.succ n * (Nat.succ n + 1) | succ n hn =&gt; conv =&gt; lhs; simp [LinearSum] rw [Nat.mul_add,hn,←Nat.add_mul] conv =&gt; lhs; rw [Nat.mul_comm,Nat.add_comm 2 n] . We have the following variant of induction where the base case does not have to be zero. Corollary. Let $P(n)$ be a predicate on $n \\in \\mathbb{N}$ and $n_0 \\in \\mathbb{N}$. Assume that . | we have a proof of $P(n_0)$ and | for any $n \\geq n_0$, we can prove $P(n) \\to P(n+1)$. | . Then we can prove $\\forall n \\geq n_0, P(n)$. In other words, $P(n)$ is true for all $n \\geq n_0$. Proof. (Expand to view) Set $Q(n) := P(n+n_0)$. Then our conditions translate into $Q(0)$ is true and $Q(n) \\to Q(n+1)$ is true for all $n$. Using induction, we conclude that $Q(n)$ is true for all $n$. But then $P(n+n_0)$ is true for all $n$ or $P(n)$ is true $n \\geq n_0$. &#9632; . Example. For all $n \\geq 3$, we have $3n \\leq n^2$. Note that while the conlusion is true for $n=0$ it is defintely not true to $n = 1,2$. We start with the base case of $n_0 = 3$. The left-hand side is $ 3 \\cdot 3 = 9$ as is the right hand side. Thus the base case is true. Now we assume $n \\geq 3$ and that $3n \\leq n^2$ and try to show that $3(n+1) \\leq (n+1)^2$. We can expand the right-hand side as $(n+1)^2 = n^2 + 2n + 1$ and the left-hand side as $3n + 3$. From the induction hypothesis, we know that $3n \\leq n^2$. Thus, \\(3(n+1) = 3n + 3 \\leq n^2 + 3\\) Now if $3 \\leq 2n + 1$ we get \\(3(n+1) \\leq n^2 + 3 \\leq n^2 + 2n + 1 = (n+1)^2\\) and get our desired conclusion. We need to prove that $3 \\leq 2n + 1$ for all $n \\geq 3$. To do this, we use induction! The base case is $n = 3$ where the right-hand side is $7$ which is greater than $3$. Assume that $3 \\leq 2n + 1$. Then \\(3 \\leq 2n + 1 \\leq 2n + 1 + 2 = 2(n+1) + 1\\) Appealing to induction, we can conclude $3n \\leq n^2$ for all $n \\geq 3$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/induction/#recursion-for-proofs",
    "relUrl": "/notes/induction/induction/#recursion-for-proofs"
  },"92": {
    "doc": "Induction",
    "title": "Induction",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/induction/",
    "relUrl": "/notes/induction/induction/"
  },"93": {
    "doc": "Other inductive types",
    "title": "Behind the curtain",
    "content": "Nat is not alone. Inductive constructions can model a vast amount of mathematics. We can create the propositions True and False using them. inductive False : Prop where inductive True : Prop where | intro . As you can see both False and True are more basic than Nat. With False you have no ways of building it. With True, you have exactly one: intro. When building a function f : Nat → α, recursion told us we needed to specify a value of f for each way we construct a Nat: one for zero and one for each succ n. What does recursion look like here? . theorem False.elim {p : Prop} (no : False) : p := no.rec . False.elim allows us to prove anything from a proof of a False. Why? Because when using recursion on False, there is nothing to recurse over. This is exactly the same reasoning that exhibits a function $\\varnothing \\to X$ for any set. (The match syntax expects terms so the proof uses the recursor rec underlying it.) . We can also build And and Or using inductive types. inductive And (p q : Prop) : Prop where | intro (left : p) (right : q) inductive Or (p q : Prop) : Prop where | inl (h : p) | inr (h : q) . Here are proofs of And.left and And.right. theorem And.left {p q: Prop} (h : And p q) : p := match h with | intro left _ =&gt; left theorem And.right {p q: Prop} (h : And p q) : q := match h with | intro _ right =&gt; right . Or.elim becomes just another name for recursion. theorem Or.elim {p q r : Prop} (h : Or p q) (h₁ : p → r) (h₂ : q → r) : r := match h with | inl h =&gt; h₁ h | inr h =&gt; h₂ h . We can also model existential propositions using inductive types. inductive Exists {α : Type} (P : α → Prop) : Prop where | intro (a : α) (h : P a) theorem Exists.elim {α : Type} {p : Prop} {P : α → Prop} (e : Exists P) (h : ∀ a, P a → p) : p := match e with | intro a h' =&gt; h a h' . Even equality fits into a inductive construction. inductive Eq {α : Type} : α → α → Prop where | refl (a : α) : Eq a a theorem Eq.symm {α : Type} (a a' : α) (h : Eq a a') : Eq a' a := by match h with | refl a =&gt; exact Eq.refl a . As we know from shopping, lists are also built recursively. inductive List (α : Type) where | nil | cons (a : α) (as : List α) . We start with an empty list nil and we build via cons our list by adding one thing, a:α, at a time. def ShoppingList : List String := List.cons \"nuts\" (List.cons \"cottage cheese\" (List.cons \"grapes\" List.nil)) . As this is cumbersome, Lean allows for familiar notation for lists. def ShoppingList : List String := [\"nuts\",\"cottage cheese\",\"grapes\"] . We have the [] for the empty list and a::as to append a to the list as. We can build useful functions on List using recursion . def Length {α : Type} (l : List α) : Nat := match l with | [] =&gt; 0 | _::as =&gt; 1 + Length as def Join {α : Type} (l₁ l₂ : List α) : List α := match l₁ with | [] =&gt; l₂ | a::as =&gt; a :: Join as l₂ . And we can prove results, like the additivity of length, under join. theorem join_add_len {α : Type} {l₁ l₂ : List α} : Length (Join l₁ l₂) = Length l₁ + Length l₂ := by match l₁ with | [] =&gt; simp [Length,Join] | a::as =&gt; simp[Length]; rw [join_add_len,Nat.add_assoc] . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/inductive_types/#behind-the-curtain",
    "relUrl": "/notes/induction/inductive_types/#behind-the-curtain"
  },"94": {
    "doc": "Other inductive types",
    "title": "Other inductive types",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/inductive_types/",
    "relUrl": "/notes/induction/inductive_types/"
  },"95": {
    "doc": "Lean's Int",
    "title": "Two copies of Nat",
    "content": "With our construction of $\\mathbb{Z}$, we (eventually) get two copies of $\\mathbb{N}$ one coming from the function \\(i : \\mathbb{N} \\to \\mathbb{Z}\\) and the other from \\(j : \\mathbb{N} \\to \\mathbb{Z}\\) . We can think of one copy of $\\mathbb{N}$ as the non-negative integers and the other as the non-positive integers – with their overlap being $0$. One can could imagine building an inductive type from this expressing that we have two ways to build an integer from a natural number. Indeed, that is what Lean does but a slight shift. The two copies of Nat in Int are the non-negative integers and the strictly negative integers. inductive Int : Type where | ofNat : Nat → Int | negSucc : Nat → Int . negSucc n should be viewed as -n-1. Lean gives the analog of $j$ above as . def negOfNat : Nat → Int | 0 =&gt; 0 | succ m =&gt; negSucc m . In Grothendieck construction of $\\mathbb{Z}$, we got addition almost immediately since it was natural to add $\\mathbb{N} \\times \\mathbb{N}$. In Lean, it requires a bit more book-keeping using successors when using negSucc. def add (m n : Int) : Int := match m, n with | ofNat m, ofNat n =&gt; ofNat (m + n) | ofNat m, negSucc n =&gt; subNatNat m (succ n) | negSucc m, ofNat n =&gt; subNatNat n (succ m) | negSucc m, negSucc n =&gt; negSucc (succ (m + n)) . This uses subNatNat (read as subtract a natural number from a natural number). def subNatNat (m n : Nat) : Int := match (n - m : Nat) with | 0 =&gt; ofNat (m - n) -- m ≥ n | (succ k) =&gt; negSucc k . Natural number subtraction returns 0 if m ≥ n. On the other hand, perhaps multiplication looks simpler than the formula we had before. def mul (m n : Int) : Int := match m, n with | ofNat m, ofNat n =&gt; ofNat (m * n) | ofNat m, negSucc n =&gt; negOfNat (m * succ n) | negSucc m, ofNat n =&gt; negOfNat (succ m * n) | negSucc m, negSucc n =&gt; ofNat (succ m * succ n) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/int/#two-copies-of-nat",
    "relUrl": "/notes/integers/int/#two-copies-of-nat"
  },"96": {
    "doc": "Lean's Int",
    "title": "Lean's Int",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/int/",
    "relUrl": "/notes/integers/int/"
  },"97": {
    "doc": "Sets",
    "title": "The concept underlying (almost) all math",
    "content": "We have seen concepts like propositions, predicates, function, and formulas and have seen the value in reasoning over them all at once. But how should we make sense of collections of propositions? Or of functions? . There are various ways to approach this but the most common is the notion of a set. For most mathematicians, the objects they work are built up from sets. What are sets? We won’t answer that question precisely. But, we will give you enough examples, properties, and constructions that you should gain some intuition for them. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/intro/#the-concept-underlying-almost-all-math",
    "relUrl": "/notes/sets/intro/#the-concept-underlying-almost-all-math"
  },"98": {
    "doc": "Sets",
    "title": "Sets",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/intro/",
    "relUrl": "/notes/sets/intro/"
  },"99": {
    "doc": "Integers",
    "title": "More numbers",
    "content": "We saw the truth about $\\mathbb{N}$. The next natural evolution in human understanding of numbers are the integers $\\mathbb{Z}$. What are the integers precisely in terms of the natural numbers and how can we working them? . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/intro/#more-numbers",
    "relUrl": "/notes/integers/intro/#more-numbers"
  },"100": {
    "doc": "Integers",
    "title": "Integers",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/intro/",
    "relUrl": "/notes/integers/intro/"
  },"101": {
    "doc": "Predicate logic",
    "title": "The next level of logic",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/intro/#the-next-level-of-logic",
    "relUrl": "/notes/predicate/intro/#the-next-level-of-logic"
  },"102": {
    "doc": "Predicate logic",
    "title": "Predicate logic",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/intro/",
    "relUrl": "/notes/predicate/intro/"
  },"103": {
    "doc": "Functions",
    "title": "The workhorses of mathematics",
    "content": "The basic idea of a function is simple: it takes some input and converts it to some output. Its simplicity results in robustness of applications. We have already seen in Lean how functions are a basic ingredient used to represent implication, universal quantification, predicates,… . Due to our familiarity, we will reverse the previous order of presentation and discuss functions in Lean first. Later we will turn to definition so functions in term of sets. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/intro/#the-workhorses-of-mathematics",
    "relUrl": "/notes/functions/intro/#the-workhorses-of-mathematics"
  },"104": {
    "doc": "Functions",
    "title": "Functions",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/intro/",
    "relUrl": "/notes/functions/intro/"
  },"105": {
    "doc": "Induction",
    "title": "Our first numbers",
    "content": "Since kindergarten, we all have been counting. What do we use to count? The natural numbers, $\\mathbb{N}$. Next we will look at the what the natural numbers really are and how it ties in with notions of induction and recursion. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/intro/#our-first-numbers",
    "relUrl": "/notes/induction/intro/#our-first-numbers"
  },"106": {
    "doc": "Induction",
    "title": "Induction",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/intro/",
    "relUrl": "/notes/induction/intro/"
  },"107": {
    "doc": "Lean",
    "title": "Computers, mathematics, and proof",
    "content": "Each day brings greater involvement of computers in every facet of our day to day life. Mathematics is no different. Use of computers for computation in mathematics is now very well-established. For example, suppose we want to figure out if $2^{15485862}$ is divisible by $15485863$. Computing the power and then long dividing by hand would take a person awhile. (But there is a secret shortcut if you know some abstract algebra). But a well-written computer program can do it in milli-seconds. Another use, relevant to us directly, is the encoding mathematical ideas and proof in computer programs. Proofs become data which the computer can then check for correctness. Mathematicians and computer scientists have worked on this idea for decades but it is only relatively recently that computer checked proofs have reached a threshold of usability to see widespread adoption by mathematicians. We will use a tool called Lean to aid us in our investigations of mathematics and proof in particular. To begin with, we will see how to represent all of proposition logic in Lean. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/intro/#computers-mathematics-and-proof",
    "relUrl": "/notes/lean/intro/#computers-mathematics-and-proof"
  },"108": {
    "doc": "Lean",
    "title": "Lean",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/intro/",
    "relUrl": "/notes/lean/intro/"
  },"109": {
    "doc": "Relations",
    "title": "When things are similar but aren’t equal",
    "content": "Or when we need to order things, relations are a flexible mathematical notion that allows us to compare terms or elements. The most familiar relation is equality. But you have encountered many others at this point: . | $ \\to $ - implication of propositions | $ \\leq $ - less than (or equality) of numbers | $ \\subseteq $ - subset containment | $\\mid$ - divisibility | . Relations unify all these concepts. We will discuss the general concept and then branch off to investigate different common properties of relations. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/intro/#when-things-are-similar-but-arent-equal",
    "relUrl": "/notes/relations/intro/#when-things-are-similar-but-arent-equal"
  },"110": {
    "doc": "Relations",
    "title": "Relations",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/intro/",
    "relUrl": "/notes/relations/intro/"
  },"111": {
    "doc": "Notes",
    "title": "Course Notes",
    "content": "These will serve to provide the background ideas we will discuss in class. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/intro/#course-notes",
    "relUrl": "/notes/intro/#course-notes"
  },"112": {
    "doc": "Notes",
    "title": "Notes",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/intro/",
    "relUrl": "/notes/intro/"
  },"113": {
    "doc": "Propositional logic",
    "title": "Symbolic and semantic",
    "content": "Human reason follows some basic patterns. The truth of one statement is often connected to the truth of another statement. For example, let’s take the following example. Example. If it is cloudy outside, then I don’t need my sunglasses. To understand the content of this course, the first thing we need to do is disentangle our thought a bit. There are two closely related but distinct facets of this example. There is the truth of the statement. Is it actually cloudy outside or not? Do I actually need sunglasses or not? Whether or not someone actually needs their sunglasses probably depends on the person and the level of cloudiness. In focusing on the truth of a statement, we care about the semantics of the proposition. Distinctly, we can also view this statement as built up from basic “atoms” using well-defined rules. In our semantic analysis, we already have broken it down into two separate statements that can either be truth or false in principal: . $A$. It is cloudy outside . $B$. I don’t need my sunglasses . Our example statement is built up from $A$ and $B$ via a if-then construction. It then makes sense to denote it by $A \\Rightarrow B$. The fancy arrow $\\Rightarrow$ stands in for the if-then. Thus, symbolically we have $A$ and $B$ and $\\Rightarrow$ provides a way to connect them to make a new formal symbol \\(A \\Rightarrow B\\) . Symbolically, $A$ and $B$ have no infused meaning so why do we even consider this? . Because symbolic manipulation can be incredibly powerful. It can streamline human thought. It can be mechanized in a computer program. It can be converted in a game. For mathematicians, logical reasoning is especially important. When reasoning about intricate structures, it is incredibly easy to make a mistake. The history of mathematics is rich with such examples. To help minimize errors, mathematicians grounded their arguments in logical deduction and fostered a culture of rigorous proofs. Let’s look at a more mathematical example. Recall that \\(\\mathbb{N} = \\lbrace 0,1,2,\\ldots \\rbrace\\) is the set of natural numbers. A natural number $n$ is even if it can be written as $n = 2m$ for some other natural number $m$. A number is odd if is not even. Example. Let $n$ be a natural number. If $n$ is even, then $n+1$ is odd. t If we denote . $A$. $n$ is even. $B$. $n+1$ is odd. then symbolically we can represent the statement as before \\(A \\Rightarrow B\\) But semantically this if very different than our cloudy/sunglasses example above. We start by introducing the basic structure of logical argument. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/intro/#symbolic-and-semantic",
    "relUrl": "/notes/propositional_logic/intro/#symbolic-and-semantic"
  },"114": {
    "doc": "Propositional logic",
    "title": "Propositional logic",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/intro/",
    "relUrl": "/notes/propositional_logic/intro/"
  },"115": {
    "doc": "Inverses",
    "title": "Hitting the undo button",
    "content": "A natural question to ask about a process is whether it can be undone. We can ask the same about a function. Definition. A left inverse to a function $f: A \\to B$ is a function $g : B \\to A$ such that $g \\circ f = \\operatorname{id}_A$. Here $\\operatorname{id}_A$ is the identity function on $A$ so this can rewritten as $g(f(a)) = a$ for all $a$. To define a left inverse in Lean, we confront an new problem: we really need to pieces of mathematical data: for the function $g : B \\to A$ and then the proof that $g \\circ f = \\operatorname{id}$. We can bundle those two things together into a single structure. structure LeftInverse (f : α → β) where to_fun : β → α invl : to_fun ∘ f = id def TheFun (g : LeftInverse f) : β → α := g.to_fun example : g.to_fun ∘ f = id := g.invl . Given a (g : LeftInverse f), we can access the function β → α as g.to_fun and the proof that g.to_fun ∘ f = id using g.invl. To construct a LeftInverse, we need to supply both pieces of data . def IdInv : LeftInverse (@id α) := ⟨id,by rfl⟩ . It also helpful to define single proposition which is true if $f$ has a left inverse. def HasLeftInv (f : α → β) : Prop := Nonempty (LeftInverse f) . Here Nonempty α is proposition that states there is actually some term of type α. Definition. A right inverse to $f$ is a function $h : B \\to A$ such that $f \\circ h = \\operatorname{id}_B$. Of course, if $h$ is a right inverse for $f$, then $f$ is also a left inverse for $h$. Definition. An inverse to $f$ is a function that is simultaneously a left and right inverse to $f$. Possession of inverses and injectivity/surjective are tied closely together. Theorem. If $f$ has a left inverse, then $f$ is injective. Proof. (Expand to view) Assume we have $a_1,a_2$ with $f(a_1) = f(a_2)$ and let $g$ be a left-inverse of $f$. Then, we can apply $g$ to both sides of the equality $f(a_1) = f(a_2)$ to get $$ a_1 = g(f(a_1)) = g(f(a_2)) = a_2 $$ and see that $f$ is injective. &#9632; . Here is a proof in Lean. theorem has_left_inv_injective (f : α → β) (h : HasLeftInv f) : Injective f := by -- Introduce a pair of arguments and the assumption that -- f evaluates to the same on them intro (a₁:α) (a₂:α) (l₁: f a₁ = f a₂) -- Break up the existence of a left-inverse into a function and a proof it is a -- left inverse have ⟨g,l₂⟩ := h -- A calculation block allows us to more efficiently perform equality manipulations calc a₁ = id a₁ := by rfl -- these reduce to an equality _ = (g ∘ f) a₁ := Eq.symm (congrFun l₂ a₁) -- we apply equal functions _ = (g ∘ f) a₂ := congrArg g l₁ -- we apply a function to equal arguments _ = id a₂ := congrFun l₂ a₂ -- we apply equal functions to same value again _ = a₂ := by rfl -- done . Similarly, if we have right inverse, then we are surjective. As a corollary, we get the following statement. Corollary. If $f$ has both a right and left inverse, then $f$ is a bijection. In fact if $f$ has both a left and right inverse, then they have to be equal. theorem left_inv_right_inv_eq { f : α → β } (g : LeftInverse f) (h : RightInverse f) : g.to_fun = h.to_fun := by apply funext intro (b: β) calc g.to_fun b = g.to_fun (f (h.to_fun b)) := congrArg g.to_fun (Eq.symm (congrFun h.invr b)) _ = h.to_fun b := congrFun g.invl (h.to_fun b) theorem inv_unique (f : α → β) (g : Inverse f) (h : Inverse f) : g.to_fun = h.to_fun := by calc g.to_fun = (InvtoLeftInv g).to_fun := by rfl _ = (InvtoRightInv h).to_fun := left_inv_right_inv_eq (InvtoLeftInv g) (InvtoRightInv h) _ = h.to_fun := by rfl . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/inverses/#hitting-the-undo-button",
    "relUrl": "/notes/functions/inverses/#hitting-the-undo-button"
  },"116": {
    "doc": "Inverses",
    "title": "More nonconstructive tools",
    "content": "We saw about that if $f$ has a left inverse, then it is injective. The converse is also true allowing for new nonconstructive tools. Theorem. Suppose $f: A \\to B$ is injective and $A$ is nonempty. Then $f$ has a left inverse. Proof. (Expand to view) We first make our candidate left inverse function $g: B \\to A$. Pick some $b$ from $B$. The idea is to split the definition of $g(b)$ into two cases depending on whether there exists some $a$ with $f(a) = b$ or not. To do so, we know that $A$ is nonempty so we can pick some junk value $a_0$ for use. Then, we \"define\" $g$ as $$ g(b) = \\begin{cases} a &amp;\\text{where $a$ is \\textit{some} value satisfying $f(a) = b$} \\\\ a_0 &amp;\\text{if there is no such solution to $f(a) = b$} \\end{cases} $$ Nothing so far depended on the assumption that $f$ is injective. But we haven't checked that $g$ is, in fact, a left inverse. From the definition, we know that $g(f(a)) = a'$ where $a'$ is some value satisfying $f(a') = f(a)$. Since $f$ is injective, we can conclude that $a = a'$ and that we indeed have a left inverse. &#9632; . So why the quotes around “define” there. It seems reasonable to assume we can pick a value from a nonempty set for each value $b$ where there is one. But this is not a consequence in set theory and requires additional axiom: the Axiom of Choice. Let’s see what this looks like in Lean where we see the use of choice. -- this definition constructs the g in the proof above. It is marked noncomputable -- because Lean cannot make a computer program out of it noncomputable def Section (f : α → β) (l : Nonempty α) : β → α := by intro (b:β) have a₀ : α := Classical.choice l -- propDecicable tells Lean is ok that that we may not actually be able check -- using a computer program the condition in the following if, then statement have : Decidable (∃ a, f a = b) := Classical.propDecidable (∃ a, f a = b) exact if h : ∃ a, f a = b then Classical.choose h else a₀ theorem inj_has_left_inv (f : α → β) (l : Nonempty α) (h : Injective f) : HasLeftInv f := by -- let is like have except it allows for better computation let g : β → α := Section f l -- suffices changes the goal to u and shows we can close if we have u using ⟨g,u⟩ suffices u : g ∘ f = id from ⟨g,u⟩ apply funext intro (a:α) -- exists is a helper technique for establishing existential statements have (v : ∃ x, f x = f a) := by exists a -- dif_pos is a helper result that says the result of the if, then is what we expect -- when the if condition is true have (w : g (f a) = Classical.choose v) := dif_pos v calc g (f a) = Classical.choose v := w _ = a := h (Classical.choose_spec v) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/inverses/#more-nonconstructive-tools",
    "relUrl": "/notes/functions/inverses/#more-nonconstructive-tools"
  },"117": {
    "doc": "Inverses",
    "title": "Inverses",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/inverses/",
    "relUrl": "/notes/functions/inverses/"
  },"118": {
    "doc": "Sets in Lean",
    "title": "Sets in Lean",
    "content": "Given a universal set $\\mathcal U$, one can go back and forth between predicates on elements of $\\mathcal U$ and subsets of $\\mathcal U$. For $P(x)$, a predicate on $x \\in \\mathcal U$, we define the set \\(X := \\lbrace x \\mid P(x) \\rbrace\\) This is the set of all $x \\in \\mathcal U$ satisfying $P$. For a subset $X \\subset \\mathcal U$, we have \\(P(x) := x \\in X\\) the predicate which checks membership of $x$ in $X$. We use this idea to embed basic set theory in Lean as follows. For our universe of discourse $\\mathcal U$, we use a type U:Type and then we define Set U to simply be predicates . def Set (U : Type) := U → Prop . Here we create a definition, denoted def, to indicate we are constructing some data. Theorems/examples are just special types of definitions in Lean. Membership now becomes satisifcation of the underlying predicate. variable (U : Type) def Mem (x : U) (X : Set U) : Prop := X x . We introduce standard mathematical notation for membership ∈ typed as \\in. To check membership is then equivelent to providing a proof of the predicate. variable (U : Type) variable (X : Set U) -- going from a proof of X x to x ∈ X example (x : U) (h : X x) : x ∈ X := h -- going back example (x : U) (h : x ∈ X) : X x := h . We have containment of sets. variable (U : Type) def Subset {U : Type} (X Y : Set U) : Prop := ∀ x, x ∈ X → x ∈ Y -- given the notation ⊆, typed \\sub . Then, our basic set operations mirror our logical operations. variable (U : Type) def Union (X Y : Set U) : Set U := fun (x:U) =&gt; x ∈ X ∨ x ∈ Y -- given the notation X ∪ Y, typed as \\cup def Inter (X Y : Set U) : Set U := fun (x:U) =&gt; x ∈ X ∧ x ∈ Y -- given the notation X ∩ Y, typed as \\cap def Diff (X Y : Set U) : Set U := fun (x:U) =&gt; x ∈ X ∧ x ∉ Y -- given the notation X \\ Y . We also have the universal set and the empty set . variable (U : Type) def Univ : Set U := fun _ =&gt; True def Empty : Set U := fun _ =&gt; False -- with notation ∅, typed as \\empty . With this, we can define the complement of a set: all elements not in it. variable (U : Type) def Comp (X: Set U) : Set U := Univ \\ X -- given the notation Xᶜ, typed \\^c . Then the remainder of set-theoretic constructs . variable (I U V: Type) def PowerSet (X : Set U) : Set (Set U) := fun (Y : Set U) =&gt; Y ⊆ X -- given notation 𝒫, typed \\powerset def Prod (X : Set U) (Y : Set V) : Set (U × V) := fun z =&gt; z.1 ∈ X ∧ z.2 ∈ Y -- given notation X ×ˢ Y, typed \\times\\^s def BigUnion (X : I → Set U) : Set U := fun x =&gt; ∃ i, x ∈ X i def BigInter (X : I → Set U) : Set U := fun x =&gt; ∀ i, x ∈ X i . Taking both power sets and products naturally land us in sets of a different type than we start. Notice for products we have a product type U × V. Terms of this type are pairs (u,v) where u:U and v:V. Writing z : U × V we can access the each entry using z.1 and z.2. Before we prove anything, we need one essential fact: set extensionality. This is an axiom of set theory but is a consequence (of other extensionality axioms) in Lean. variable (U : Type) variable (X Y : Type) theorem set_ext : X = Y ↔ (∀ (x:U), x ∈ X ↔ x ∈ Y) := sorry . Let’s see some proves using these notions. varible (U : Type) variable (X Y : Set U) theorem sub_left_of_union : X ⊆ X ∪ Y := by intro (x:U) (h: x ∈ X) -- we call the corresponding operation on propositions exact Or.inl h theorem sub_right_of_union : Y ⊆ X ∪ Y := by intro (x:U) (h: x ∈ Y) exact Or.inr h theorem comm_union : X ∪ Y = Y ∪ X := by -- we use set extensionality to get equality from a proof -- of (∀ (x:U), x ∈ X ↔ x ∈ Y) apply set_ext.mpr intro (x:U) apply Iff.intro -- this allows us to split into two proofs for each direction -- of containment. · intro (h: x ∈ X ∪ Y ) apply Or.elim h -- now we supply proofs for each branch of the or · exact fun (g : x ∈ X) =&gt; sub_right_of_union x g · exact fun (g : x ∈ Y) =&gt; exact sub_left_of_union x g · intro (h : x ∈ Y ∪ X) apply Or.elim h · exact fun (g : x ∈ Y) =&gt; sub_right_of_union x g · exact fun (g : x ∈ X) =&gt; exact sub_left_of_union x g . We introduced some new syntax here. Note the dots. They focus your infoview on a single current goal if you have multiple. They are not necessary but might be helpful. Note that you need to indent if you use dots. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/lean/",
    "relUrl": "/notes/sets/lean/"
  },"119": {
    "doc": "Lean",
    "title": "Predicate logic in Lean",
    "content": "Like with propositional logic, Lean has the rules of predicate logic embedded within it. As we discussed, predicates are analogous to functions which output propositions. We can declare predicates in Lean as ‘ . variable (α : Type) variable (A : α → Prop) variable (B : α → α → Prop) . A new subtlety is variable (α : Type). In predicate logic, we have domain of discourse, which is the source of values for the input variables of our predicates. In Lean, we have to declare that we have some source of inputs of our predicates. This notation tells Lean that we have something α whose type is the generic Type. Then A is a predicate on a single variable and B is one on two variables. We can understand $\\forall x~ A(x)$ as saying that no matter what the value of $x$ is we have a proof of $A(x)$. In this way, we can think of a proof of $\\forall x~ A(x)$ as a function whose inputs are $x$’s and whose outputs are proofs of $A(x)$. In Lean, this is how ∀ is understood. For example, if we look at . variable (P Q : Prop) theorem not_true : P \\to Q := sorry #check not_true . we will see . not_true : ∀ (P Q : Prop), P → Q . Given any pair of propositions P and Q, the “theorem” not_true produces a (sorried) proof of P → Q. Lean represents this using a ∀. Since ∀ is implemented via as a function, the introduction and elimination rules are familiar. variable (α : Type) variable (A : α → Prop) example : ∀ (x:α), A x → A x := fun x (h : A x) =&gt; h example (y : α) (h : ∀ x, A x) : A y := h y . Next, let’s look at the existential quantifier ∃. variable (α : Type) #check @Exists α -- @Exists α : (α → Prop) → Prop #check @Exists.intro α -- @Exists.intro α : ∀ {p : α → Prop} (w : α), p w → Exists p #check @Exists.elim α -- @Exists.elim α : ∀ {p : α → Prop} {b : Prop}, -- (∃ x, p x) → (∀ (a : α), p a → b) → b . Given a domain of discourse α and a predicate A : α → Prop, the existential quantification ∃ x, A x is a proposition. This is what Exists models. Then, we have our introduction and elimination rules for ∃ built in to Exists. Existential introduction takes . | a domain of discourse α (which Lean tries to infer from the context), | a predicate p : α → Prop (inferred if possible), | and a value (w : α) | . and yields a function that converts proofs of the proposition to p w to an existentially quantified proposition. Elimination will take . | a domain of discourse α (inferred), | a predicate p (inferred), | a proposition b, | a proof of ∃ x, p x, | a proof of ∀ (a : α), p a → b (ie a function with inputs a and a proof of p a and output a proof of b), | . and will return a proof of b. If we have some value where p is true and for any value p x implies b, then we can conclude b. Here are simple example uses. variable (α : Type) variable (A : α → Prop) example (x:α) (h:P x) : ∃ y, P y := Exists.intro x h example (h : ∃ y, ¬ P y) : ¬ (∀ x, P x) := by intro (g : ∀ x, P x) apply Exists.elim h intro (a : α) intro (l : ¬ P a) exact l (g a) . Next, we have equality, $=$. variable (α : Type) #check @Eq α -- @Eq : α → α → Prop . Equality at its most basic level is a special named predicate on two variables. But, we remember it satisfies some properties. Firstly, reflexivity, symmetry, and transistivity. These becomes ways to build equality. variable (α : Type) #check @Eq.refl α -- @Eq.refl α : ∀ (a : α), a = a #check @Eq.symm α -- @Eq.symm α : ∀ {a b : α}, a = b → b = a #check @Eq.trans α -- @Eq.trans α : ∀ {a b c : α}, a = b → b = c → a = c . There are also substitution rules for equality, one involving function application and one for predicates. variable (α β : Type) #check @Eq.subst α -- @Eq.subst α : ∀ {motive : α → Prop} {a b : α}, a = b → motive a → motive b example (P : α → Prop) (x y : α) (e : x = y) (h : P x) : P y := Eq.subst g h #check @congrArg -- @congrArg α β : ∀ {a₁ a₂ : α} (f : α → β), a₁ = a₂ → f a₁ = f a₂ example (f : α → α) (x y : α) (h : x = y) : f x = f y := congrArg f h . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/lean/#predicate-logic-in-lean",
    "relUrl": "/notes/predicate/lean/#predicate-logic-in-lean"
  },"120": {
    "doc": "Lean",
    "title": "Lean",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/lean/",
    "relUrl": "/notes/predicate/lean/"
  },"121": {
    "doc": "Proofs in Lean",
    "title": "Examples",
    "content": "Let’s do some examples of predicate logic proofs in Lean to get comfortable with the new syntax and also introduce a few more useful tactics. First, we prove that ∀ (x : α), P x → ∃ (y : α), P y. example (α : Type) : ∀ (x : α), P x → ∃ (y : α), P y := by intro (a : α) intro (h : P a) exact ⟨a, h⟩ . From out previous discussion, we would expect the final line to be exact Exists.intro a h. Lean has a shorthard notation for intro rules. We can use French quotes (typed &lt; &gt;) to construct the term. Similarly, if we wanted an And.intro a b, we could ⟨a, b⟩. Like most notation it makes thing easier to write but can also make it harder to read. Let’s look at the proof showing we can exchange quantifiers in one direction. variable (α : Type) variable (C : α → α → Prop) example : Type) : (∃ (x:α), ∀ (y:α), C x y) → ∀ (v:α), ∃ (u:α), C u v := by intro h v -- introduce h : ∃ x, ∀ (y : α), C x y and v : α apply Exists.elim h -- we supply the existential statement and Lean now asks for a proof of -- ⊢ ∀ (a : α), (∀ (y : α), C a y) → ∃ u, C u v intro g f -- we introduce f : ∀ (y : α), C g y and g : α apply Exists.intro -- we have new goals ⊢ C ?w v and ⊢ α exact f v -- this solves the first and Lean then infers the second . Note that we can introduce multiple terms just by including a spaced list of labels for them. Next, if there does not exist a value making the predicate true, we can conclude it is false for all values. variable (α : Type) variable (P : α → Prop) example : (¬ ∃ y, P y) → ∀ x, ¬ P x := by intro h a n exact h ⟨a,n⟩ . Below we have another example of giving proofs using quantifiers. variable (α : Type) variable (P Q : α → Prop) example : (∀ x, P x → ¬ Q x) → ¬ ∃ y, P y ∧ Q y := by intro h n apply Exists.elim n intro a g -- Here g : P x ∧ Q x exact h a g.left g.right -- Lean lets us use the shorthand g.left for And.left g and similarly -- g.right for And.right g . Let’s do a basic example using functions and equality. variable (α : Type) variable (P : α → Prop) example (f : α → α) (x y : α) (h₁ : x = y) (h₂ : P (f x)) : P (f y) := by rw [←h₁] -- the goal is now P (f x) assumption . There a few things to notice in this proof. First, we have rw [←h₁] with the backwards ←. Lean’s convention for rewriting using x=y is to search for occurrences of x and replace them with y. If we tried rw [h₁], then Lean would return an error . tactic 'rewrite' failed, did not find instance of the pattern in the target expression . Lean allows you to rewrite hypotheses in addition to goals but you need to specify the assumption to target. The following proof is also valid. example (f : α → α) (x y : α) (h₁ : x = y) (h₂ : P (f x)) : P (f y) := by rw [h₁] at h₂ -- now h₂ is P (f y) assumption . This tells Lean to look for x’s in h₂ and replace them with y’s. In both cases, the assumption tactic tells Lean: one of the goals is an established fact in the context, figure out which and close the goal. You can also feed Lean multiple terms to use for rewriting as a list. variable (α : Type) variable (x y z : α) variable (P : α → Prop) example (h₁ : x = y) (h₂ : z = x) (f : α → α) : f y = f z := by rw [← h₁, h₂] . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/lean_pfs/#examples",
    "relUrl": "/notes/predicate/lean_pfs/#examples"
  },"122": {
    "doc": "Proofs in Lean",
    "title": "Proofs in Lean",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/lean_pfs/",
    "relUrl": "/notes/predicate/lean_pfs/"
  },"123": {
    "doc": "Mod m",
    "title": "Arithmetic with remainders",
    "content": "We now have $\\mathbb{Z}$ at our disposal. Conceptually, the integers are a wonderful tool. Practically, we can only even consider finitely many things. For example, on your computer now, there is only a finite amount of memory. It is a very large collection of what can be viewed as switches. To store data, these switches can be in the on position or the off position. Suppose we have $b$ switches. Suppose we have a number $n$ that we wish to store in memory. How can we do that with switches? . A question we can ask about $n$ to help pin it down is whether it is even or odd. Since it is a binary choice, it can be captured completely using a single switch. To store this information, we just remember the value $n \\mod 2$. While knowing $0$ versus $1$ (for even vs odd) is useful, we generally want to work with larger numbers. Let $\\epsilon_0$ be the remainder from dividing $m$ by $2$. Then $m \\equiv \\epsilon_0 \\mod 2$ and $ m - \\epsilon_0 = 2m_1$ for some $m_1$. This $m_1$ itself could be even or odd. Let $\\epsilon_1$ be its remainder when divided by $2$. Then \\(m - \\epsilon_0 - 2\\epsilon_1 = 4m_2\\) So \\(m \\equiv \\epsilon_0 + 2 \\epsilon_1 \\mod 4\\) . We can continue this process to write \\(m \\equiv \\sum_{j = 0}^{n-1} \\epsilon_j 2^j \\mod 2^n\\) and each $\\epsilon_j \\in \\lbrace 0,1 \\rbrace$. Since $\\equiv_m$ is an equivalence relation, we can form its quotient. Definition. The integers mod $m$, denoted $\\mathbb{Z}/m\\mathbb{Z}$, are the quotient \\(\\mathbb{Z}/m\\mathbb{Z} := \\mathbb{Z}/\\equiv_m\\) of $\\mathbb{Z}$ by the equivalence relation $\\equiv_m$. Remember that this means that \\(\\mathbb{Z}/m\\mathbb{Z} = \\lbrace [n] \\mid n \\in \\mathbb{Z} \\rbrace\\) where each \\([n] = \\lbrace n' \\mid n' \\equiv n \\mod m \\rbrace\\) are equivalence classes. Recall that the division algorithm on $\\mathbb{Z}$ takes in $n \\in \\mathbb{Z}$ and $m \\in \\mathbb{N}$ and outputs $q_n,r_n \\in \\mathbb{Z}$ with \\(n = q_n m + r_n\\) and \\(0 \\leq r_n &lt; m\\) Moreover, $q_n$ and $r_n$ along with $m$ uniquely determine $m$. Lemma. Let $m \\in \\mathbb{N}$. The function \\(\\begin{aligned} r : \\mathbb{Z} &amp; \\to \\mathbb{N} \\\\ n &amp; \\mapsto r_n \\end{aligned}\\) descends to \\(\\overline{r} : \\mathbb{Z}/m\\mathbb{Z} \\to \\mathbb{N}\\) Moreover, it is a bijection with its image $\\lbrace n \\mid 0 \\leq n &lt; m \\rbrace$. Proof. (Expand to view) To show that a function descends to the quotient by an equivalence relation, we need to show that it is _constant_ on equivalence classes, ie whenever $n \\equiv n' \\mod m$ we have $r_n = r_{n'}$. By definition, we have $n - n' = cm$ for some $c$. Thus, $$ q_n m + r_n - (q_{n'}m + r_{n'}) = cm $$ or $$ r_n - r_{n'} = (c - q_{n'} + q_n)m $$ In other words, $r_n - r_{n'}$ is divisible by $m$. But since $0 \\leq r_n, r_{n'} &lt; m$, we have $$ -m &lt; r_n - r_{n'} &lt; m $$ The only number strictly between $-m$ and $m$ that is divisible by $m$ is $0$. So $$ r_n = r_{n'} $$ So we see that $r$ is constant on equivalence classes. Since $r_j = j$ for $0 \\leq j &lt; m$, we see that the image of $r$ is $\\lbrace n \\mid 0 \\leq n &lt; m \\brace$. To finish, we check that $\\overline{r}$ is injective. Assume that $r_n = r_{n'}$. Then $$ n - n' = q_n m + r_n - (q_{n'}m + r_n) = (q_n - q_{n'})m $$ so $n \\equiv n' \\mod m$. Thus, $\\overline{r}$ is injective and a bijection onto its image. &#9632; . Example. Let’s take $m=5$. The previous lemma says that \\(\\mathbb{Z}/5\\mathbb{Z} = \\lbrace [0], [1], [2], [3], [4] \\rbrace\\) We can figure out which box to place $n \\in \\mathbb{Z}$ into mod $5$ by determining its remainder after division by $5$. So $22 = 4\\cdot 5 + 2$ and $[22] = [2]$. We can also transport arithmetic from $\\mathbb{Z}$ to $\\mathbb{Z}/m\\mathbb{Z}$. Definition/Lemma. We add two elements of $\\mathbb{Z}/m\\mathbb{Z}$ using the rule \\([n] + [n'] := [n+n']\\) and we multiply via \\([n] \\cdot [n'] := [nn']\\) . This is tagged as a lemma because rules we have written down for outputs depend, ostensibly, on the choice of representative for the equivalence class. For example, mod $5$, we have \\([22] + [3] = [25]\\) and \\([2] + [3] = [5]\\) But $[22] = [2]$ so we better have $[25] = [5]$. Indeed we do. Proof. (Expand to view) We need to check that if $n_1 \\equiv n_2 \\mod m$ and $n_1' \\equiv n_2' \\mod m$ then $n_1 + n_1' \\equiv n_2 + n_2' \\mod m$ and $n_1n_1' \\equiv n_2n_2' \\mod m$. Assume that $n_1 \\equiv n_2 \\mod m$ and $n_1' \\equiv n_2' \\mod m$. Then by definition $n_1 - n_2 = c_1m$ and $n_1' - n_2' = c_2 m$. Then $$ n_1 + n_1' - (n_2 + n_2') = c_1 m + c_2 m + (c_1+c_2) m $$ so indeed $n_1 + n_1' \\equiv n_2 + n_2' \\mod m$. Being a little more clever, we have $$ n_1 \\cdot n_1' - n_2 \\cdot n_2' = n_1 \\cdot n_1' - n_1 \\cdot n_2' + n_1 \\cdot n_2' - n_1' \\cdot n_2' = n_1c_2m - n_2'c_1 m= (n_1c_2 - n_2'c_1)m $$ &#9632; . Example. Let’s work out the multiplication table for $\\mathbb{Z}/5\\mathbb{Z}$. We have . |   | $[0]$ | $[1]$ | $[2]$ | $[3]$ | $[4]$ | . | $[0]$ | $[0]$ | $[0]$ | $[0]$ | $[0]$ | $[0]$ | . | $[1]$ | $[0]$ | $[1]$ | $[2]$ | $[3]$ | $[4]$ | . | $[2]$ | $[0]$ | $[2]$ | $[4]$ | $[1]$ | $[3]$ | . | $[3]$ | $[0]$ | $[3]$ | $[1]$ | $[4]$ | $[2]$ | . | $[4]$ | $[0]$ | $[4]$ | $[3]$ | $[2]$ | $[1]$ | . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/mod/#arithmetic-with-remainders",
    "relUrl": "/notes/integers/mod/#arithmetic-with-remainders"
  },"124": {
    "doc": "Mod m",
    "title": "Mod m",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/integers/mod/",
    "relUrl": "/notes/integers/mod/"
  },"125": {
    "doc": "Interactive mode",
    "title": "Game mode",
    "content": "All the proofs we have seen so far have been a little hard for a person to read. As mentioned, Lean can serve as an interactive theorem prover. There is more interactive mode to write proofs called tactic mode. Tactic mode also allows us to structure our proofs in more human-readable form. To enter tactic mode, we add the keyword by after the := like so. example : False := by . In the Infoview pane, you will see something like . ▶ 1 goal ⊢ False . You can sorry this and notice that Goals accomplished 🎉 appears for the goal state; though Lean still gives a warning that we are using sorry. Inside tactic mode, you can use tactics. Each tactic is a built-in helper function for constructing a proof. Let’s look at some in an example step by step. Suppose we wanted to prove the formula (A → B ∧ C) → (A → B) ∧ (A → C). We start with . example : (A → B ∧ C) → (A → B) ∧ (A → C) := by . and the infoview provides the current state . A B C: Prop ⊢ (A → B ∧ C) → (A → B) ∧ (A → C) . We have assumptions A B C which are propositions and our goal is (A → B ∧ C) → (A → B) ∧ (A → C). Next we would normally start with fun (h : A → B ∧ C) =&gt;. In tactic mode, we can use the tactic intro. When our goal is of the for X → Y, intro h will introduce an assumption h : X and change our goal to Y. Here . example : (A → B ∧ C) → (A → B) ∧ (A → C) := by intro h . and the infoview provides the current state . A B C: Prop h : A → B ∧ C ⊢ (A → B) ∧ (A → C) . While Lean can infer the type of h from the goal, it is good practice to provide the type yourself. When you disagree with Lean, then its good chance to check your understanding. Next we want to make proofs of A → B and A → C. Previously, we would jam that into an And.intro making the resulting expression dense. The tactic have allows us to introduce new assumptions into the context if we provide proofs. example (A B C : Prop) : (A → B ∧ C) → (A → B) ∧ (A → C) := by intro (h : A → B ∧ C) have (f : A → B) := fun (a:A) =&gt; And.left (h a) have (g : A → C) := fun (a:A) =&gt; And.right (h a) . and the infoview provides the current state . A B C: Prop h : A → B ∧ C f: A → B g: A → C ⊢ (A → B) ∧ (A → C) . Now just need to combine f and g with And.intro. Since And.intro f g is exactly our goal. We use the exact tactic to tell Lean. example (A B C : Prop) : (A → B ∧ C) → (A → B) ∧ (A → C) := by intro (h : A → B ∧ C) have (f : A → B) := fun (a:A) =&gt; And.left (h a) have (g : A → C) := fun (a:A) =&gt; And.right (h a) exact And.intro f g . The infoview celebrates with us: Goals accomplished 🎉. Another useful tactic is called apply. It applies a function to the goal to get a new goal. For example, . example (a : A) (b : B) : A ∧ B := by apply And.intro . gives . case left a: A b: B ⊢ A case right a: A b: B ⊢ B . in the infoview. We can tackle each case. example (a : A) (b : B) : A ∧ B := by apply And.intro case left =&gt; exact a case right =&gt; exact b . To simplify proofs with or elimination, Lean has the tactic cases. example (h : A ∨ B) : B ∨ A := by cases h with | inl a =&gt; exact Or.inr a | inr b =&gt; exact Or.inl b . Each line labelled with | is a case of or elimination. inl tells Lean you are taking the left branch of the or while inr is the right. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/mode/#game-mode",
    "relUrl": "/notes/lean/mode/#game-mode"
  },"126": {
    "doc": "Interactive mode",
    "title": "Interactive mode",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/mode/",
    "relUrl": "/notes/lean/mode/"
  },"127": {
    "doc": "Truth tables",
    "title": "What is truth anyway?",
    "content": "Previously we have been performing purely symbolic moves to generate our proofs. How does this relate to a given mathematics proof or debate topic? . To motivate our rules we have often replaced our symbols $A,B,C,$… by actual statements, eg “the sun is out”. “The sun is out” can either be true or false – we just look outside. So at a very basic level this provides a way to assign either T or F to a propositional variable. We could of course willy-nilly assign T and F for each our propositional variables. But all of our connectives have familiar interpretation in the context of T/F values. | Not true better be false and vice-versa. So \\(\\neg T \\mapsto F \\ , \\ \\neg F \\mapsto T.\\) We can put this into a table: | . | $A$ | $\\neg A$ | . | $T$ | $F$ | . | $F$ | $T$ | . This expresses the values of $\\neg A$ given the values of $A$. | Suppose I know that $A \\to B$ and we know that is $A$ is $T$. It would make a lot sense to conclude that $B$ should also be assigned $T$. But if we allow ourselves to look at possible assignments it makes sense to assign T/F values to each expression using T/F and $\\to$. We can make another table where we list the values assigned to $A$ along the first column and the values assigned to $B$ in the first row. | . | $A$ | $B$ | $A \\to B$ | . | $T$ | $T$ | $T$ | . | $T$ | $F$ | $F$ | . | $F$ | $T$ | $T$ | . | $F$ | $F$ | $T$ | . One can read this as saying the implication is itself is true if either assumption is false or both the assumption and conclusion are true. | We also have a table for $\\land$ | . | $A$ | $B$ | $A \\land B$ | . | $T$ | $T$ | $T$ | . | $T$ | $F$ | $F$ | . | $F$ | $T$ | $F$ | . | $F$ | $F$ | $F$ | . which says that $A \\land B$ should only be true if both $A$ and $B$ are. | And we have a table for $\\lor$ | . | $A$ | $B$ | $A \\lor B$ | . | $T$ | $T$ | $T$ | . | $T$ | $F$ | $T$ | . | $F$ | $T$ | $T$ | . | $F$ | $F$ | $F$ | . which says $A \\lor B$ is false only when both $A$ and $B$ are. | We also want \\(\\top \\mapsto T \\\\ \\bot \\mapsto F\\) | . Using these rules, once we have a chosse of T/F, we can assign T/F to any propositional formula. Let’s look at a more complicated formula. Example. Let’s take the formula \\(\\neg A \\lor B \\to C \\land \\neg D\\) and the truth assignment \\(A, C \\mapsto T, \\ B, D \\mapsto F\\) . It convenient notation to “plug in” to the formula the values of $T$ and $F$. This gives \\(\\neg T \\lor F \\to T \\land \\neg F\\) Then use our rules above to simplify down to a single value. First the negation \\(F \\lor F \\to T \\land T\\) Then the $\\lor$ and $\\land$ \\(F \\to T\\) Finally for $\\to$ we reduce to $T$. Different assignments for $A,B,C,D$ can yield a different value for our formula. For example, if \\(B, C, D \\mapsto T, \\ A \\mapsto F\\) Then \\(\\neg A \\lor B \\to C \\land \\neg D \\mapsto F\\) . We can think of the possible truth value assignments to our collection of propositional variables as different possible universes. For example, if $A$ is standing for “the sun is out”, then $A \\mapsto T$ is saying we know the sun it out while $A \\mapsto F$ is saying the sun is not out. So any real-world or mathematical possibility can be found by listing out all the possible T/F assignments and the values taken by the formula given that assignment. Below is a table for our example . The truth table for our example. (Expand to view) | $A$ | $B$ | $C$ | $D$ | $\\neg A \\lor B \\to C \\land \\neg D$ | . | $T$ | $T$ | $T$ | $T$ | $F$ | . | $T$ | $T$ | $T$ | $F$ | $T$ | . | $T$ | $T$ | $F$ | $T$ | $F$ | . | $T$ | $F$ | $T$ | $T$ | $T$ | . | $F$ | $T$ | $T$ | $T$ | $F$ | . | $T$ | $T$ | $F$ | $F$ | $F$ | . | $T$ | $F$ | $T$ | $F$ | $T$ | . | $F$ | $T$ | $T$ | $F$ | $T$ | . | $T$ | $F$ | $F$ | $T$ | $T$ | . | $F$ | $T$ | $F$ | $T$ | $F$ | . | $F$ | $F$ | $T$ | $T$ | $F$ | . | $T$ | $F$ | $F$ | $F$ | $T$ | . | $F$ | $T$ | $F$ | $F$ | $F$ | . | $F$ | $F$ | $T$ | $F$ | $T$ | . | $F$ | $F$ | $F$ | $T$ | $F$ | . | $F$ | $F$ | $F$ | $F$ | $F$ | . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/models/#what-is-truth-anyway",
    "relUrl": "/notes/propositional_logic/models/#what-is-truth-anyway"
  },"128": {
    "doc": "Truth tables",
    "title": "Truth tables",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/models/",
    "relUrl": "/notes/propositional_logic/models/"
  },"129": {
    "doc": "Soundness and completeness",
    "title": "Models for predicate logic",
    "content": "Before we dive into proving statements in predicate logic, we equip ourselves with a useful tool to decide if a formula is not provable. For propositional logic, we used truth assignments and truth tables as a quick tool to establish the lack of a proof. This was only possible because we established soundness of truth assignments: if we could establish $X \\vdash Y$, then we know that $X \\models Y$, ie every truth assignment that makes $X$ true will also make $Y$ true. Propositions are simpler than predicates though. For predicate logic, the interpretations have more moving parts. Our domain of discourse, or source for inputs of the variables, needs to be assigned a concrete set of values. For example, we could consider $\\mathbb{N}$ as our concrete set. Then, each function $f(x)$ should get assigned to a function whose inputs are from $\\mathbb{N}$ and whose outputs lie in $\\mathbb{N}$, like $f(x) = x+1$. Each predicate $A(x)$ may be true for some numbers $x$ and false for others. Thus, we need to assign a set of values for which $A(x)$ is true and assign false for the others. For example, we could assign $A(x)$ to the set of even natural numbers. Meaning, $A(x)$ is true for $x$ even and false $x$ odd. Remember that predicate logic is purely about symbolic manipulation respecting a set of rules. Through models, we imbue some meaning and familiarity to the symbols. Our rules for propogating truth and falsity through our familiar connectives $\\to, \\land, \\lor, \\neg, \\leftrightarrow$. We need ways to assign values to $\\forall$ and $\\exists$. These are built into the motivations for these symbols. We declare that $\\forall x~ A(x)$ evaluates to true if $A(x)$ is true for all values of $x$ in our model. It is false otherwise. For example, we if use $\\mathbb{N}$ and interpret $A(x)$ to be $x &gt; 5$. Then, $\\forall x~ A(x)$ would evaluate to false. But if we interpret $A(x)$ to be $x^2-x \\geq 0$ then we would get true. Similarly, $\\exists x~ A(x)$ evaluates to true if there at least one value in our model making $A(x)$ true and is otherwise false. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/models/#models-for-predicate-logic",
    "relUrl": "/notes/predicate/models/#models-for-predicate-logic"
  },"130": {
    "doc": "Soundness and completeness",
    "title": "Soundness",
    "content": "With our more complex models, we can extend $X \\models Y$ to predicate logic. Definition. We say that a formula $Y$ is a logical consequence of a formula $X$ if, in any model, whenever $X$ is true, then $Y$ is true. So to show that $X \\not \\models Y$ we just need to locate one model where $X$ evaluates to true while $Y$ to value for some value. Predicate logic is sound similar to propositional logic. Theorem. If $X \\vdash Y$, then $X \\models Y$. Like with propositional logic, this gives a powerful means to check that $X \\not \\vdash Y$: just find one model demonstrating $X \\not \\models Y$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/models/#soundness",
    "relUrl": "/notes/predicate/models/#soundness"
  },"131": {
    "doc": "Soundness and completeness",
    "title": "Completeness",
    "content": "Amazingly, the converse of the previous theorem continues to hold. Theorem. If $X \\models Y$, then $X \\vdash Y$. Completeness of predicate logic is more involved than that for propositional logic. It was first proven by Kurt Gödel in his 1929 thesis. We won’t go into any details and will not use completeness in any way moving forward. But, hopefully, you are well equiped to appreciate the statement. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/models/#completeness",
    "relUrl": "/notes/predicate/models/#completeness"
  },"132": {
    "doc": "Soundness and completeness",
    "title": "Soundness and completeness",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/models/",
    "relUrl": "/notes/predicate/models/"
  },"133": {
    "doc": "Proofs in Lean",
    "title": "More set theoretic proofs in Lean",
    "content": "We’ve seen an example where the goal is to give a proof of an equality of sets. Both in Lean and with pen-and-paper, to show two sets are equal X=Y we use set extensionality to reduce to establishing ∀ x, x ∈ X ↔ x ∈ Y. We then take some x ∈ U, prove one direction x ∈ X → x ∈ Y, and then the other x ∈ Y → x ∈ X. While for pen-and-paper everyone can just do this conversion “in their head”, in Lean we need to step the computer through each time. This can be tedious so we automate it. For that, we can use a tactic called set_extensionality. variable (U : Type) variable (X Y : Set U) example : X = Y := set_extensionality x -- we now have x:U -- and two goals x ∈ X → x ∈ Y and x ∈ X → x ∈ Y -- we sorry these goals because we cannot prove two sets are -- equal in general . sorry . sorry . set_extensionality helps us when proving a goal of the form X=Y. What if we have a hypothesis of set equality? . variable (x:U) variable (X Y Z : Set U) example (h: X = Y) : X ∪ Z = Y ∪ Z := by rewrite [h] rfl . Rewriting the goal with the assumption X=Y produces a new goal X ∪ Z = X ∪ Z. Recall the tactic rfl solves goals of the form t = t. We can also use rw in place of rewrite and rfl as rw does a rewrite and then calls rfl. Let’s see another one. variable (U : Type) variable (X Y : Set U) example (h : X ⊆ Y) : Z \\ Y ⊆ Z \\ X := by intro (x:U) (g : x ∈ Z \\ Y) have : x ∉ X := sorry exact ⟨g.left,this⟩ . The only thing left is to fill in the sorry. Knowing that if X ⊆ Y and x ∉ Y, then x ∉ X seems like a useful result itself. We give it a name and then use it. (Remember that given h : A ∧ B we can access a proof of A using h.left and a proof of B using h.right.) . variable (U : Type) variable (X Y : Set U) theorem sub_comp_super (h : X ⊆ Y) : Yᶜ ⊆ Xᶜ := by intro (x : U) (g : x ∈ Yᶜ) (n : l ∈ X) exact g (h x l) example (h : X ⊆ Y) : Z \\ Y ⊆ Z \\ X := by intro (x:U) (g : x ∈ Z \\ Y) have : x ∉ X := sub_comp_super h x g.right exact ⟨g.left,this⟩ . Next we look at the distributivity of intersection over unions. variable (U : Type) variable (X Y Z : Set U) theorem dist_inter_union : X ∩ (Y ∪ Z) = (X ∩ Y) ∪ (X ∩ Z) := by set_extensionality x · intro (h : x ∈ X ∩ (Y ∪ Z)) cases h.right with | inl (g : x ∈ Y) =&gt; exact Or.inl ⟨h.left,g⟩ | inr (g : x ∈ Z) =&gt; exact Or.inr ⟨h.left,g⟩ · intro (h : x ∈ (X ∪ Y) ∩ (X ∩ Z)) cases h with | inl (g : X ∩ Y) =&gt; exact ⟨g.left,Or.inl g.right⟩ | inr (g : X ∩ Z) =&gt; exact ⟨g.left,Or.inr g.right⟩ . In place of an apply Or.elim, we have used the cases tactic. This tactic creates different proof goals for each way there is to build the term. In our case, h.right : x ∈ Y ∪ Z which is definitionally equivalent to x ∈ Y ∨ x ∈ Z. There are two ways to make a proof of an or-statement: either you have a proof of the left and use .inl or you have a proof the right and use .inr. These constructors are the labels for the two branches of the cases. Note that cases comes with additional syntax: with and the | to label the branches. Here is an example with the use of cases for the existential quantifer. variable (I U : Type) variable (X Y : I → Set U) example (h : ∃ (i:I), X i ∩ Y i = ∅) : BigInter X ∩ BigInter Y = ∅ := by set_extensionality x · intro (g : x ∈ BigInter X ∩ BigInter Y) cases h with | intro (i : I) (g₁ : X i ∩ Y i = ∅) =&gt; have g₂ : x ∈ X i := g.left i have g₃ : x ∈ Y i := g.right i have g₄ : x ∉ X i ∩ Y i := by rw [g₁] exact fun h =&gt; False.elim h exact g₄ ⟨g₂,g₃⟩ · exact fun h =&gt; False.elim h . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/more_lean/#more-set-theoretic-proofs-in-lean",
    "relUrl": "/notes/sets/more_lean/#more-set-theoretic-proofs-in-lean"
  },"134": {
    "doc": "Proofs in Lean",
    "title": "Proofs in Lean",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/more_lean/",
    "relUrl": "/notes/sets/more_lean/"
  },"135": {
    "doc": "Negation and RAA",
    "title": "Negation",
    "content": "Let’s see how Lean understands negation. variable (A : Prop) #reduce ¬ A -- A → False . The command #reduce tells Lean to try to peel away notation and write things in a more basic form. So Lean-speak for not of a formula are functions that take proofs of A to proofs of False. With this in mind, $\\neg$-elimination is another instance of function application. example (A : Prop) (a : A) (n : ¬ A) : False := n a . If ¬ A means A → False, then negation introduction looks very similar to implication introduction. variable {A : Prop} theorem totallyProvenTheorem (a : A) : False := sorry example : ¬ A := totallyProvenTheorem a . Example. Let’s prove the formula (A → B) → (¬ B → ¬ A). variable (A B : Prop) example : (A → B) → (¬ B → ¬ A) := fun (f : A → B) =&gt; fun (h : ¬ B) =&gt; fun(a : A) =&gt; h (f a) . Tilting our heads to the side, we can read this as constructing a function which inputs . | A function f taking proofs of A to proofs of B | A function h taking proofs of B to proofs of False | A proof a of A | . From f a we get a proof of B. Applying h gives us a proof of False. Thus, our output is a proof of False. Since Lean views ¬ A as A → False, it accepts this construction. Repeatedly writing the fun =&gt; is a little tedious. Thankfully, Lean accepts notation more closely adhering to our sense of multivariate functions. variable (A B : Prop) example : (A → B) → (¬ B → ¬ A) := fun (f : A → B) (h : ¬ B) (a : A) =&gt; h (f a) . Recall that we can prove anything from False. In Lean, this is . variable (A : Prop) #check @False.elim -- False.elim : False → A . Appending @ forces Lean to make explicit some arguments it usually infers from the context. (And makes nicer messages to copy.) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/negation/#negation",
    "relUrl": "/notes/lean/negation/#negation"
  },"136": {
    "doc": "Negation and RAA",
    "title": "Proof by contradiction",
    "content": "Recall that proof by contradiction (or reducito ad absurdum) allows us to conclude $A$ from $\\neg A \\vdash \\bot$. In Lean this is called Classical.byContradiction. variable (A : Prop) #check @Classical.byContradiction A -- Classical.byContradiction : (¬A → False) → A . We can eliminate double negation using this in Lean. variable (A : Prop) example : ¬ ¬ A → A := fun (h : ¬ ¬ A) =&gt; Classical.byContradiction (fun (n : ¬ A) =&gt; h n) . Note that fun (n : ¬ A) =&gt; h n is function that takes proofs of ¬ A to proofs of False. Applying byContradiction to this yields a proof of A as we want. We also have access to the law of the excluded middle built in. #check Classical.em -- Classical.em : ∀ (p : Prop), p ∨ ¬p . Example. Let’s prove the converse of the previous example (¬ B → ¬ A) → (A → B). example : (¬ B → ¬ A) → (A → B) := Or.elim (Classical.em B) (fun (b : B) (_ : A) =&gt; b) (fun (n : ¬ B) (a : A) =&gt; False.elim (h n a)) . Notice how Lean just “figured out” that we wanted to eliminate False into B. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/negation/#proof-by-contradiction",
    "relUrl": "/notes/lean/negation/#proof-by-contradiction"
  },"137": {
    "doc": "Negation and RAA",
    "title": "Negation and RAA",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/negation/",
    "relUrl": "/notes/lean/negation/"
  },"138": {
    "doc": "Not",
    "title": "Negation",
    "content": "In a debate or a courtroom, there are usually two opposing sides. One is arguing for $A$ and the other is arguing for not $A$. In propositional logic, we introduce a symbol in the place of not: negation. It is denoted by $\\neg$. Given a formula $A$, then we can make a new one $\\neg A$. But what should be the rules of inference that mimic our arguments involving not? When have I established not of a statement? What does knowing the negation of a statement allow me to conclude? . One common pattern is to start an argument with $A$ and reason until you reach something that is clearly not true. This leads us to also introduce a symbol $\\bot$ which plays the role of false or “this is crazy”. Then we can formalize our pattern of argument via the following introduction rule for $\\neg$ . Given an argument assuming $A$ that leads to an absurdity, then we can conclude $\\neg A$. To eliminate $\\neg$ we have . If both $\\neg A$ and $A$ hold, then this is absurd. What are the rules for introducing and eliminating $\\bot$? We actually just saw the $\\bot$-introduction above – it doubles as the $\\neg$-elimination rule. The elimination rule is very general. Once we have established $\\bot$, then we are free to reach any conclusion. Let’s do another example to see how our rules of deduction interact. Example. Let’s establish \\(\\neg A \\land \\neg B \\to \\neg (A \\lor B)\\) . Recall this is shorthand for $ \\vdash (\\neg A \\land \\neg B \\to \\neg(A \\lor B))$. In words, this says we can establish $ \\neg A \\land \\neg B \\to \\neg (A \\lor B)$ with no assumptions. Proof. (Expand to view) If we want to establish a conclusion of the form $X \\to Y$ then we will want to introduce $\\to$. To do that we need to provide a deduction of the form $$ X \\vdash Y $$ In our case, we want to fill in the details for $$ \\neg A \\land \\neg B \\vdash \\neg(A \\lor B) $$ Now our goal is of the form $\\neg Z$ so we want to introduce $\\neg$. To do that, we need to supply a proof of $\\bot$ from $Z$. We have reduced to establishing $$ \\neg A \\land \\neg B, A \\lor B \\vdash \\bot $$ We could combine $A$ and $\\neg A$, if we had them, to got $\\bot$. The same holds for $B$ and $\\neg B$. ee can eliminate $\\neg A \\land \\neg B$ into either $\\neg A$ or $\\neg B$. For $A \\lor B$ elimination, we need proofs of desired conclusion, here $\\bot$, one with $A$ $$ \\neg A \\land \\neg B, A \\vdash \\bot $$ and one with $B$ $$ \\neg A \\land \\neg B, B \\vdash \\bot $$ The proofs of these are quicker. Putting everything together, we get the following natural deduction proof. In step${}^0$, we cancel the assumption $\\neg A \\land \\neg B$ to introduce $\\to$. In step${}^1$, we cancel the assumption $A \\lor B$ to introduce $\\neg (A \\lor B)$ since our conclusion is $\\bot$. Finally the steps${}^2$, we cancel $A$ and $B$ using or elimination. The numerical labels are convenient to keep track of the cancellations. Note that all assumptions are cancelled. &#9632; . Ok so what is the value of this result? It gives a method of proof that holds no matter how we interpret $A$ and $B$. For example, if we say $A$ is “it is hot out” and $B$ is “it is raining”, then we can interpret the above as saying “if I know that the either it is not hot out or it is not raining, then I can conclude that it is not both hot and sunny”. Each of formula that we can prove symbolically is an argument pattern that can be applied in any context. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/negation/#negation",
    "relUrl": "/notes/propositional_logic/negation/#negation"
  },"139": {
    "doc": "Not",
    "title": "Some conventions",
    "content": "Expressions like $\\neg \\neg A$ are pretty un-ambiguous and we declare that $\\neg$ binds most closely. So for example \\(\\neg A \\to B := (\\neg A) \\to B \\\\ \\neg C \\lor D:= (\\neg C) \\lor D\\) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/negation/#some-conventions",
    "relUrl": "/notes/propositional_logic/negation/#some-conventions"
  },"140": {
    "doc": "Not",
    "title": "Not",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/negation/",
    "relUrl": "/notes/propositional_logic/negation/"
  },"141": {
    "doc": "Operations on sets",
    "title": "Making new sets from old",
    "content": "The empty set. A special role is played by the set with no elements. The empty set, denote $\\varnothing$, satisfies \\(\\forall x~ x \\not \\in \\varnothing\\) . It enjoys nice properties with respect to unions and intersections: \\(X \\cup \\varnothing = X \\\\ X \\cap \\varnothing = \\varnothing\\) . Unions. Given two sets $X$ and $Y$ we can make a new one whose elements are those which come from $X$ or from $Y$ \\(X \\cup Y := \\lbrace z \\mid z \\in X \\text{ or } z \\in Y \\rbrace\\) . For example, if $X = \\lbrace 0,2,4\\rbrace$ and $Y = \\lbrace 0,1,3\\rbrace$ then \\(X \\cup Y = \\{0,1,2,3,4\\}\\) . Note that $X,Y \\subseteq X \\cup Y$. Intersections. We can instead ask for the elements that are in both $X$ and $Y$. \\(X \\cap Y := \\lbrace z \\mid z \\in X \\text{ and } z \\in Y \\rbrace\\) . For example, if $X = \\lbrace 0,2,4\\rbrace$ and $Y = \\lbrace 0,1,3\\rbrace$ then \\(X \\cap Y = \\{0\\}\\) . Note that $X \\cap Y \\subseteq X,Y$. Complements. Another sensible thing to ask is that $z \\in X$ but $z \\not \\in Y$ or vice versa. \\(X \\setminus Y := \\lbrace z \\in X \\mid z \\not \\in Y \\rbrace\\) . For example, if $X = \\lbrace 0,2,4\\rbrace$ and $Y = \\lbrace 0,1,3\\rbrace$ then \\(X \\setminus Y = \\{2,4\\}\\) . A special case is when $X = \\mathcal U$. Then we write \\(X^c := \\mathcal U \\setminus X\\) Note that $X \\setminus Y \\subseteq X$. Unions, intersections, and complements can be understood with Venn diagrams. Products. The Cartesian product of sets $X$ and $Y$, denote $X \\times Y$ is \\(X \\times Y := \\lbrace (x,y) \\mid x \\in X \\text{ and } y \\in Y \\rbrace\\) Its elements consists of ordered pairs $(x,y)$ whose first entry is an element of $X$ and whose second is an element of $Y$. Two ordered pairs $(x_1,y_1)$ and $(x_2,y_2)$ are equal if and only if their components are equal $x_1=x_2$ and $y_1=y_2$. For example, if $X = \\lbrace 0,2,4\\rbrace$ and $Y = \\lbrace 0,1,3\\rbrace$ then \\(X \\times Y = \\{(0,0),(0,1),(0,3),(2,0),(2,1),(2,3),(4,0),(4,1),(4,3)\\}\\) . We often use a line to represent $\\mathbb{R}$. The plane represents $\\mathbb{R}^2 = \\mathbb{R} \\times \\mathbb{R}$. Power sets. Given a set $X$ we can form the set whose elements are all subsets of $X$. This called the power set of $X$ and is denoted by $\\mathcal P(X)$. For example if $X = \\lbrace 0,2,4 \\rbrace$, then \\(\\mathcal P(X) = \\lbrace \\varnothing, \\lbrace 0 \\rbrace, \\lbrace 2 \\rbrace, \\lbrace 4 \\rbrace, \\lbrace 0,2 \\rbrace, \\lbrace 0,4 \\rbrace, \\lbrace 2,4 \\rbrace, \\lbrace 0,2,4 \\rbrace \\rbrace\\) . Families of sets. Unions, intersections, and products are binary operations on sets: they take two sets and make new one. We can upgrade these a bit. A family of sets is a set of sets indexed by a set. We used set a lot there. More precisely, we have a indexing set $I$ and for each element $i \\in I$, we have a set $X_i$. Then \\(\\bigcup_{i \\in I} X_i := \\lbrace x \\mid x \\in X_i \\text{ for some } i \\in I \\rbrace \\\\ \\bigcap_{i \\in I} X_i := \\lbrace x \\mid x \\in X_i \\text{ for all } i \\in I \\rbrace\\) . We can also for the infinite product $\\prod_{i \\in I} X_i$ whose elements are functions $f : I \\to \\mathcal U$ with $f(i) \\in X_i$ for each $i$. For example, let’s take $X_n = [0,1/(n+1)) \\subset \\mathbb{R}$ where $n \\in \\mathbb{N}$ is our indexing set. Then, \\(\\bigcup_{n \\in \\mathbb{N}} X_n = [0,1) \\\\ \\bigcap_{n \\in \\mathbb{N}} X_n = \\lbrace 0 \\rbrace\\) One can understand $\\prod_{n \\in \\mathbb{N}} [0,1/(n+1))$ as half-infinite sequences of real numbers \\(x_0,x_1,x_2,x_3,\\ldots,x_m,\\ldots\\) where $0 \\leq x_n &lt; 1/(n+1)$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/operations/#making-new-sets-from-old",
    "relUrl": "/notes/sets/operations/#making-new-sets-from-old"
  },"142": {
    "doc": "Operations on sets",
    "title": "Identities",
    "content": "These operations satisfy many identities relating them. Let’s take the following as an example. Theorem. Let $X$ and $Y$ be sets. Then \\((X \\cap Y) \\cup (X \\setminus Y) = X\\) . Proof. (Expand to view) To show that two sets are equal we show that every element of one is an element of the other and vice-versa. Assume that $x \\in (X \\cap Y) \\cup (X \\setminus Y)$. Then either $x \\in X \\cap Y$ or $x \\in X \\setminus Y$. We argue in each case. If $x \\in X \\cap Y$, then $x \\in X$ and $x \\in Y$ by definition. Thus, $x \\in X$. If $x \\in X \\setminus Y$, then $x \\in X$ and $x \\not \\in X$. So $x \\in X$. In both cases, we conclude that $x \\in X$ overall. Now we argue in the other direction. Assume that $x \\in X$. Then either $x \\in Y$ or $x \\not \\in Y$. In the case that $x \\in Y$, we have $x \\in X \\cap Y$. In the case that $x \\not \\in Y$, we have $X \\setminus Y$. In both cases, we can conclude that $x \\in (X \\cap Y) \\cup (X \\setminus Y)$. &#9632; . Here is another one. Theorem. Let $X, Y$, and $Z$ be sets. Assume that $X \\cap Y = \\varnothing$. Then, \\((X \\times Z) \\cap (Y \\times Z) = \\varnothing\\) . Proof. (Expand to view) Let's show that $(X \\times Z) \\cap (Y \\times Z)$ has no elements. Assume that $(u,v) \\in (X \\times Z) \\cap (Y \\times Z)$. Then, since $(u,v) \\in X \\times Z$, we have by definition $u \\in X$ and $v \\in Z$. Since $(u,v) \\in Y \\times Z$, we have $u \\in Y$ and $v \\in Z$. Thus, $u \\in X \\cap Y = \\varnothing$. We have element of the empty set which is a contradiction. Thus, one of our assumptions must be false. Here there must be no such element $(u,v)$. In other words, $(X \\times Z) \\cap (Y \\times Z)$ has no elements. From extensionality of sets, since it has the same elements as the empty set it must be $\\varnothing$ itself. &#9632; . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/operations/#identities",
    "relUrl": "/notes/sets/operations/#identities"
  },"143": {
    "doc": "Operations on sets",
    "title": "Operations on sets",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/sets/operations/",
    "relUrl": "/notes/sets/operations/"
  },"144": {
    "doc": "Partial and total orders",
    "title": "Using relations to order",
    "content": "We have seen some relations that convey a notion of size. On $\\mathbb{R}$ (and its subsets), we have $&lt;,\\leq$. If $x &lt; y$, then we think of $y$ as a bigger number than $x$. For sets, subset containment $X \\subseteq Y$ is similar. If $X \\subseteq Y$, then every $x \\in X$ is also an element of $Y$. Thus, $Y$ has more elements than $X$. Such ordering relations can be quite useful. As such, we make two definitions. Definition. Let $\\prec$ be a relation on $X$. We say that $\\prec$ is a partial order if it is . | reflexive | antisymmetric | and transitive. If $X$ has a partial order, we call it a poset. | . It is a total order if it is . | total | antisymmetric | and transistive. | . In the context of partial and total orders, we will use the symbol $\\prec$. As we saw, total implies reflexive. Thus, . Lemma. | Any total order is a partial order. | A partial order that is total is a total order. | . We can define partial and total orders in Lean using a structure that bundles up the three defining properties. structure PartialOrder (R : α → α → Prop) where refl : Reflexive R antisymm : AntiSymmetric R trans : Transitive R structure TotalOrder (R : α → α → Prop) where total : Total R antisymm : AntiSymmetric R trans : Transitive R . Our work previously lets us prove that $a \\mid b$ is a partial order on $\\mathbb{N}$. theorem div_partial_order : PartialOrder Divides := ⟨div_refl, div_antisym, div_trans⟩ . It is not a total order however because | is not a total relation. For example, $2 \\nmid 3$ and $3 \\nmid 2$. Other familiar examples of partial orders are: . | Sets with $\\subseteq$ | $\\mathbb{R}$ (or $\\mathbb{Z}$ or $\\mathbb{N}$) with $\\leq$ | Any set with $=$ is a partial order. | . Of these, only $\\leq$ on $\\mathbb{R}$ is a total order. A partial order allows to ask about largest and smallest elements. Definition. Let $(X, \\prec)$ be a poset. A least element $\\bot$ is an element of $X$ such that \\(\\forall~ x, \\bot \\prec x\\) A greatest element $\\top$ is an element of $X$ such that \\(\\forall~ x, x \\prec \\top\\) . Examples. | Let $X$ be a set. Then the poset $(\\mathcal P(X),\\subseteq)$ has $\\varnothing$ as a least element and $X$ as a greatest element. | The poset $(\\mathbb{N},\\mid)$ has $1$ as a least element and $0$ as a greatest element. | . Example. The totally ordered set $(\\mathbb{Z},\\leq)$ has neither a least or a greatest element. In general, $\\bot$ and $\\top$ need not exist for a poset. Lemma. Least elements are unique as are greatest elements. Proof. (Expand to view) Assume we have two least elements $\\bot, \\bot^\\prime$. Then since $\\bot$ is least, we have $\\bot \\prec \\bot^\\prime$. Since $\\bot'$ is least, we have $\\bot^\\prime \\prec \\bot$. From antisymmetry, we get $\\bot = \\bot^\\prime$. An analogous argument works for uniqueness of greatest elements. &#9632; . Lemma. Let $(X, \\prec)$ be a poset with least element $\\bot$ and greatest element $\\top$. If $\\bot = \\top$, then $X = \\lbrace \\bot \\rbrace$. Proof. (Expand to view) Let $x \\in X$. Then $\\bot \\prec x$ and $x \\prec \\top = \\bot$. Using antisymmetry, we have $x = \\bot$. &#9632; . Suppose we have a poset $(X,\\prec)$. Then we can make a new set $X_b := X \\cup \\lbrace -\\infty \\rbrace$ with a relation $\\prec_b$ where \\(R_{\\prec_b} = R_\\prec \\cup \\lbrace -\\infty \\rbrace \\times X_b \\subset X_b \\times X_b\\) is the subset of related pairs of $\\prec_b$. In other words, we all the previous relations of $\\prec$ hold and the new element $-\\infty$ satisfies $-\\infty \\prec_b x$ for all $x$ (including $x = -\\infty$). Similarly, we can adjoin a greatest element $\\infty$. We denate that as $X^t$. Lemma. Let $(X,\\prec)$ be a poset. Then $(X_b,\\prec_b)$ is a poset with least element $-\\infty$. Similarly, $(X^t,\\prec^t)$ is a poset with greatest element $\\infty$. Proof. (Expand to view) Let's check that $(X_b,\\prec_b)$ is a poset. The proof for $(X^t,\\prec^t)$ is analogous so we omit it. We check reflexivity. If $x \\in X$, then $x \\prec_b x = x \\prec x$ and we have $x \\prec x$ since $\\prec$ is reflexive. If $x = -\\infty$, then by definition $-\\infty \\prec -\\infty$. We check antisymmetry. Assume that $x \\prec_b y$ and $y \\prec_b x$. Either $x \\in X$ or $x = -\\infty$. If $x = \\bot$, then we contradict the definition of $\\prec_b$ unless $y = -\\infty$ also. In the case $x,y \\in X$, we know that $x = y$ from the assumed antisymmetry of $\\prec$. Finally, we check transitivity. Assume that $x \\prec_b y$ and $y \\prec_b z$. If $z = -\\infty$, then $y = -\\infty$ by definition of $\\prec_b$. But then $x = -\\infty$ from the definition again. Thus, $x = -\\infty \\prec_b -\\infty = z$. If $y = -\\infty$, then $x = -\\infty$ by definition of $\\prec_b$. So $x=y \\prec_b z$. If $x = -\\infty$, then $x = -\\infty \\prec_b z$ by definition. The remaining case is where $x,y,z \\in X$. But we have assumed that $\\prec$ is transitive so $x = z$ in this case also. &#9632; . Example. If we take $(\\mathbb{R},\\leq)$ as our poset then $\\mathbb{R}^b_t$ is often written as $[-\\infty,\\infty]$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/orders/#using-relations-to-order",
    "relUrl": "/notes/relations/orders/#using-relations-to-order"
  },"145": {
    "doc": "Partial and total orders",
    "title": "Partial and total orders",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/orders/",
    "relUrl": "/notes/relations/orders/"
  },"146": {
    "doc": "Peano's axioms",
    "title": "Axiomatic $~\\mathbb{N}$",
    "content": "We all feel pretty comfortable with the natural numbers but how would you explain to a computer? In Lean, Nat is the type of the natural numbers. It looks like . inductive Nat where | zero : Nat | succ (n : Nat) : Nat . The basic building blocks for Nat are a particular term, zero, and function succ : Nat → Nat. The keyword inductive tells Lean to make all possible expressions using just these two pieces. How does that work? . Well, to use succ, we need something plug in. We have zero. We can make a new term succ zero. With a new term, we can apply succ again to get succ (succ zero). Now, we can apply succ again, etc… . Thus, from the two pieces, zero and succ, we get a list of terms . zero, succ zero, succ (succ zero), succ (succ (succ zero)),... We would usually denote these as \\(0, 1, 2, 3,\\ldots\\) The term zero is of course $0$ and succ is $n \\mapsto n+1$ and is short for “successor”. This makes plain the principle of childhood counting that we understand one natural number from all the ones that come before it. Giuseppe Peano provided an axiomatic characterization of the natural numbers in the last 1800s. It was based on this idea that everything is built from an initial element by applying a successor function. Definition. The natural numbers are a set $\\mathbb{N}$ possessing a specified elements $0 \\in \\mathbb{N}$ called zero and a function $s : \\mathbb{N} \\to \\mathbb{N}$ called the successor function and which satisfy the following conditions . | For any $n \\in \\mathbb{N}$, $0 \\neq s(n)$. | The successor function is injective: if $s(n) = s(m)$ then $n=m$. | The set $\\mathbb{N}$ is generated by $0$ and $s$: suppose we have a set $X$ which satisfies . | $0 \\in X$ and | For any $n \\in \\mathbb{N}$, if $n \\in X$, then $s(n) \\in X$ | . Then $\\mathbb{N} \\subseteq X$. In other words, if any set contains $0$ and contains a successor of any natural number it already contains, then it has to have all of $\\mathbb{N}$ inside it. | . Another way to state the final condition: $\\mathbb{N}$ is the smallest set to have $0$ and be closed under application of $s$. In Lean, the injectivity ($0 \\neq s(n)$ and $s(n) = s(m) \\to n = m$) is built into the notion of an inductive type. It is important to note that, as defined above, $\\mathbb{N}$ are a specification and not a construction. Lean’s Nat is a construction that meets this specification. Below is another one. Example. We can build the natural numbers starting from nothing! More precisely, the empty set $\\varnothing$. We set $0 := \\varnothing$ and $s(X) = X \\cup \\lbrace X \\rbrace$. Then, \\(0 = \\varnothing \\\\ s(0) = \\lbrace \\varnothing \\rbrace \\\\ s(s(0)) = \\lbrace \\varnothing, \\lbrace \\varnothing \\rbrace \\rbrace \\\\ s(s(s(0))) =\\lbrace \\varnothing, \\lbrace \\varnothing, \\lbrace \\varnothing \\rbrace \\rbrace \\rbrace \\\\ \\vdots\\) Then the Von Neumann naturals is the set containing all these sets as elements. (The axioms of set theory guarantee such a set.) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/peano/#axiomatic-mathbbn",
    "relUrl": "/notes/induction/peano/#axiomatic-mathbbn"
  },"147": {
    "doc": "Peano's axioms",
    "title": "Peano's axioms",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/peano/",
    "relUrl": "/notes/induction/peano/"
  },"148": {
    "doc": "Proof vs truth",
    "title": "Proof vs truth",
    "content": "There are now two distinct categories of validity of a logical statement. | Can we find a (natural deduction) proof $X \\vdash Y$? | For any truth assignment that makes $X \\mapsto T$, must $Y \\mapsto T$? | . Finding a proof is an explicit set of moves to go from $X$ to $Y$ while truth assignments are somewhat external to $X$ and $Y$ but it turns out that the these two notion are closely related. As such we will given the second notion some notation, we will write $X \\models Y$ if for any truth assignment whenever $X \\mapsto T$ then $Y \\mapsto T$ also. We can check this via a truth table. Example. Let’s take \\(X = (A \\to B) \\land A \\ , \\ Y = B\\) . Then we have . | $A$ | $B$ | $(A \\to B) \\land A$ | . | $T$ | $T$ | $T$ | . | $T$ | $F$ | $F$ | . | $F$ | $T$ | $T$ | . | $F$ | $F$ | $F$ | . and can see that when $B$ is true so is $(A \\to B) \\land A$. So \\((A \\to B) \\land A \\models B\\) . But, we also know that \\((A \\to B) \\land A \\vdash B\\) from the proof . The proof above is very close to $\\to$ elimination. Indeed, that is the last set. It is easy to see that \\((A \\to B), A \\models B\\) . This means that whenever we apply $\\to$ elimination, we also have $\\models$ at that step in the proof. We come to our first real mathematical theorem. Theorem. Let $X_1,\\ldots,X_r$ and $Y_1,\\ldots,Y_s$ be collections of formulas in proposition logic. If we know that \\(X_1, \\ldots, X_r \\vdash Y_1, \\ldots, Y_s\\) then \\(X_1, \\ldots, X_r \\models Y_1, \\ldots, Y_s\\) . With the example above and the accompanying discussion, this might not be so surprising. A natural deduction proof is built from the elimination and introduction rules listed in the previous sections. One just needs to check that all of these rules don’t break $\\models$. At the moment, we content ourselves with this sketch of a proof. It should be enough to leaving your favoring the validity of the theorem but it falls short of a full mathematical proof. This theorem goes by the name of soundness of propositional logic. But, wait, there is more. Theorem. Let $X_1,\\ldots,X_r$ and $Y_1,\\ldots,Y_s$ be collections of formulas in proposition logic. If we know that \\(X_1, \\ldots, X_r \\models Y_1, \\ldots, Y_s\\) then \\(X_1, \\ldots, X_r \\vdash Y_1, \\ldots, Y_s\\) . In fact, you can somehow conjure a proof from the aether just from knowing whenever $X_1,\\ldots,X_r$ get assigned $T$, then so does $Y_1,\\ldots,Y_s$. This is usually called the completeness of propositional logic. A proof this result is beyond the scope of the course but it depends on using the law of the excluded middle (or reductio ad absurdum as they are equivalent. One approach is to break it into a giant collection of cases coming from $A \\lor \\neg A$ for each variable $A$.) . Theorems in mathematics ideally should provide deeper understanding and new tools to address old questions. One question we haven’t really broached but it immediate: how do I know when it is impossible to prove $Y$ with assumptions $X$? . Going straight from the defintion of a natural deduction proof, we would have to test all possible combinations of introduction/elimination rules. Not great. However, from soundness, if we can find a single truth assignment with $X \\mapsto T$ but $Y \\mapsto F$, then we can immediately conclude that $X \\not \\vdash Y$, ie that it is impossible to prove $Y$ from $X$. Example. Let’s show that we cannot prove $\\neg A \\land B \\to C$ from $A \\to B, \\neg C$. Let’s take $A \\mapsto F, B \\to T$, and $C \\to F$. Then \\(A \\to B, \\neg C \\mapsto T\\) while \\(\\neg A \\land B \\to C \\mapsto F\\) If we had $A \\to B, C \\vdash \\neg A \\land B \\to C$, then from the theorem above we could conclude that $A \\to B, C \\vdash \\neg A \\land B \\to C$. We have arrived now at an absurdity. Our calculation shows that $X \\not \\models Y$ but our argument shows that $X \\models Y$. We might be worried for second but then we remember the argument started out with an assumption: that we had a proof! The only way to avoid the absurdity for there not be a proof. In this example, you can see the basic moves in propositional logic being employed in a real-life mathematical example. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/pf_v_truth/",
    "relUrl": "/notes/propositional_logic/pf_v_truth/"
  },"149": {
    "doc": "Predicates, quantifiers, and equality",
    "title": "Families of propositions",
    "content": "In propositional logic, we start with variables, like $A,B,$ or $C$ as have been our defaults. These are meant to represent statements which can either be true or false. But, it is very common for a statement to depend on additional data before we can check its truth or falsity. For example, “the dog has four feet”. Is this true or false? . Well, it depends on which dog we are talking about. We can think of “dog” as a variable which when filled with a concrete dog makes the statement a proposition. A common, more mathematical, class of examples are statements of about numbers. Recall that the natural numbers $\\mathbb{N}$ are $0,1,2,3,\\ldots$. Definition. Given two natural numbers $n$ and $m$, we say $n$ divides $m$ if there is some other natural number $c$ such that \\(m = cn\\) If $n$ divides $m$, we write $n \\mid m$. If $n$ does not divide $m$, we write $n \\nmid m$. For example, $2$ divides $4$ but $3$ does not divide $4$. The statement $m$ divides $n$ can be true or false depending on the values we have for $m$ and $n$. Another important possible property of a (natural) number. Definition. A natural number $p$ is prime if . | $p \\neq 1$, i.e. $p$ is not $1$, and | whenever there is another natural number $d$ with $d \\mid n$, then we must have $d = 1$ or $d = p$. | . So $13$ is prime but $15 = 3 \\cdot 5$ is not because it is divisible by $3$ and $5$. The truth of the statement, $n$ is prime, depends on the value of $n$ itself. In each of these examples, we have collection of variables, dogs or numbers, and statements whose truth are predicated on value of the variable. Predicate, or first order, logic is an extention of propositional logic meant to model these examples. The basic building blocks are called predicates and usually denoted like $A(x), B(x,z)$, or $C(x_1,\\ldots,x_n)$. Here $x$ and $A$ play different roles. The symbol $x$ is a stand in for our variables and $A$ is like a proposition but it depends on $x$ in general. One way to understand this semantically is as a function $A : \\alpha \\to \\text{Prop}$ where $x \\in \\alpha$ is our collection of variables and $A$ is a function which hands back a proposition whenever an choice from $\\alpha$ is inputed. If we have a regular old proposition, we can think of it a predicate that does not change as we vary the input. In this way, we can start to embed propositional logic in predicate logic. Continuing, we add it the familiar connectives. If $A(x,y)$ and $B(z)$ are predicates, then we make new formulas using . | implication: $A(x,y) \\to B(z)$ | negation: $\\neg B(z)$ | conjunction: $A(x,y) \\land B(z)$ | disjunction: $A(x,y) \\lor B(z)$ | bi-implication: $A(x,y) \\leftrightarrow B(z)$. | . Like with propositional logic, we can keep joining up formulas using these connectives to make bigger and bigger new formulas. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/predicate/#families-of-propositions",
    "relUrl": "/notes/predicate/predicate/#families-of-propositions"
  },"150": {
    "doc": "Predicates, quantifiers, and equality",
    "title": "Functions",
    "content": "We already saw that predicates can be viewed as functions taking values in propositions. But, predicate logic also allows actual (multi-variant) functions $f(x,y,z)$ whose inputes comes from domain of discourse and whose output is also in our domain discourse. For example, if we are talking about $\\mathbb{N}$, we might want to consider the addition function \\(\\operatorname{Add} (n,m) = n + m\\) or multiplication \\(\\operatorname{Mult}(n,m) = n\\cdot m\\) . Given a function $f(x)$, we can make new predicates from an old ones $A(y)$ via substitution $A(f(x))$. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/predicate/#functions",
    "relUrl": "/notes/predicate/predicate/#functions"
  },"151": {
    "doc": "Predicates, quantifiers, and equality",
    "title": "Quantifiers",
    "content": "If we stopped here, our resulting logic would look like propositional logic with just a bigger set of propositions coming from varying the inputs. The richness of allowing propositions to depend on variables is that we can naturally ask about which values make a predicate true. Which dogs have four legs? All of them? Some of them? None of them? . To capture these sentiments, we introduce two new symbols into the game: . | the universal quantifier: $\\forall$ | the existential quantifier : $\\exists$ | . The universal quantifier is commonly called a “for all” and the existential quantifier a “there exists”. Before we gives the symbolic rules for writing our formulas in predicate logic using $\\forall$ and $\\exists$. Let’s look at quantifying statements in the realm of numbers. Definition. A number $n$ is even if $2 \\mid n$ and is odd if $2 \\nmid n$. Clearly any number is either divisible by $2$ or not. So the following is a true statement: for all $n$, $n$ is even or $n$ is odd. We could look at the statement: for all $n$, $n$ is prime. This would be false as we have seen there are values of $n$, like $15$, that are not prime numbers. The following is true: there exists some $n$ such that $n$ is prime. Since $n=2$ is prime, we have at least one $n$ which is prime. Using for all, there exists, and their negations, we can capture our questions about the quantity of values making the predicate formula true. Given a predicate of the form $B(y,z)$ we say that $y$ and $z$ are free variables. We can attach to each free variable at most one quantifier. For example, $\\exists y ~ \\forall z~ B(y,z)$ is a valid new formula as are $\\exists z~ B(y,z)$ or $\\forall y~ \\forall z~ B(y,z)$. Note that each quantifier comes with a variable label identifying the variable we are quantifying over. Once we quantify over a free variable, it becomes a bound variable. In general, given a formula in predicate logic with a free variable $x$ we can form a new formula by quantifying, using either $\\forall$ or $\\exists$, over it. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/predicate/#quantifiers",
    "relUrl": "/notes/predicate/predicate/#quantifiers"
  },"152": {
    "doc": "Predicates, quantifiers, and equality",
    "title": "Equality",
    "content": "Using different inputs vs the same can lead to very different statements. For example, $n$ is odd or $n$ is even vs $n$ is odd or $m$ is even. We can universally quantify over $n$ in the first one and get a true statement but not so with the second. We see being able to reason about inputs being the same or different is desired when our truth statement depend on those inputs. We therefore introduce one more new symbol: $=$, equality. We can use $=$ to make new predicates like $x = y$ or $\\neg(x = y)$. Taking everything together we can make formula like: . | $\\forall x~ \\exists ~y (A(x,y) \\to (x = y))$ | $\\exists x~ \\exists y~ \\exists z~ (\\neg(x = y) \\land \\neg(y=z) \\land \\neg(x=z) \\land B(x,y,z))$ or | $\\forall x~ (A(x,y) \\to \\exists z~ B(z))$ | . For convenience of write, we often bundle together multiple variables bound under the same quantifer. For example, we write $\\exists x~ y$ when we mean $\\exists x~ \\exists y$. And we adopt standard conventions for implicit parentheses where $\\exists$ and $\\forall$ bind more closely that the previous binary quantifiers. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/predicate/#equality",
    "relUrl": "/notes/predicate/predicate/#equality"
  },"153": {
    "doc": "Predicates, quantifiers, and equality",
    "title": "Predicates, quantifiers, and equality",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/predicate/",
    "relUrl": "/notes/predicate/predicate/"
  },"154": {
    "doc": "More rules and proofs",
    "title": "Conjunction",
    "content": "To build a proof of $A \\land B$, we needs proofs of $A$ and $B$. In Lean, this is accomplished by And.intro. example : (a : A) (b : B) : A ∧ B := And.intro a b . For elimination, we use And.left and And.right to extract proofs from A ∧ B. example : (h : A ∧ B) : A := And.left h example : (h : A ∧ B) : B := And.right h . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/proofs/#conjunction",
    "relUrl": "/notes/lean/proofs/#conjunction"
  },"155": {
    "doc": "More rules and proofs",
    "title": "Disjunction",
    "content": "For the or-introduction rules, we have . example : (a : A) : A ∨ B := Or.inl h example : (b : B) : A ∨ B := Or.inr h . For $\\lor$-elimination we need three things : . | $A \\lor B$ | A proof $A \\vdash C$ | A proof $B \\vdash C$ Let’s see what it looks like in Lean. | . #check Or.elim -- ∀ {a b c : Prop}, a ∨ b → (a → c) → (b → c) → c . So to use Or.elim we need three proofs: . | r : A ∨ B | p : A → C | q : B → C | . Let’s see a one direction of a commutativity of ∨ in Lean and at the same time get some sense of how to build up a proof in steps. Often Lean can “fill in” arguments from the context. You can ask it by placing a _. Let’s see what happens here. example (h : A ∨ B) : B ∨ A := Or.elim h _ _ . The infoview might look something like . don't know how to synthesize placeholder for argument 'right' context: A B : Prop h : A ∨ B ⊢ B → B ∨ A don't know how to synthesize placeholder for argument 'left' context: A B : Prop h : A ∨ B ⊢ A → B ∨ A . Lean is asking for our proofs of B → B ∨ A and A → B ∨ A. Remember that the are functions that turn any proof of B into a proof of B ∨ A and the same with A to B ∨ A. We can fill in the proof by providing such functions using or eliminations. example (h : A ∨ B) : B ∨ A := Or.elim h (fun (a:A) =&gt; Or.inr a) (fun (b:B) =&gt; Or.inl b) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/proofs/#disjunction",
    "relUrl": "/notes/lean/proofs/#disjunction"
  },"156": {
    "doc": "More rules and proofs",
    "title": "Bi-implication",
    "content": "We can eliminate a bi-implication into two implications. example (h : A ↔ B) : A → B := Iff.mp example (h : A ↔ B) : B → A := Iff.mpr . Here mp stands for “Modus ponens” and mpr for the “reverse”. To introduce a bi-implication, we need proofs of A → B and B → A. #check Iff.intro -- ∀ {a b : Prop}, (a → b) → (b → a) → (a ↔ b) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/proofs/#bi-implication",
    "relUrl": "/notes/lean/proofs/#bi-implication"
  },"157": {
    "doc": "More rules and proofs",
    "title": "Some examples",
    "content": "example (h : A → B ∧ C) : A → C := fun (a : A) =&gt; And.right (h a) . example : A ∧ B → A ∨ B := fun (p : A ∧ B) =&gt; Or.inl (And.left p) . example (h : A ∧ B) : B ∧ B := And.intro (And.right h) (And.right h) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/proofs/#some-examples",
    "relUrl": "/notes/lean/proofs/#some-examples"
  },"158": {
    "doc": "More rules and proofs",
    "title": "More rules and proofs",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/proofs/",
    "relUrl": "/notes/lean/proofs/"
  },"159": {
    "doc": "Useful properties",
    "title": "Properties of relations",
    "content": "Looking at the examples from before, we can identify some useful properties can satisfy. Definition. Let $\\sim$ be a relation. We say that $\\sim$ is reflexive if \\(\\forall~ x, x \\sim x\\) In other words, every $x$ is related to itself. If $R_\\sim$ is the subset corresponding to $\\sim$, then reflexivity is equivalent to \\(\\Delta_U \\subseteq R_\\sim\\) We say that $\\sim$ is irreflexive \\(\\forall~ x, x \\not \\sim x\\) . Equality is reflexive as is divisibility. But $ &lt; $ is irreflexive. Definition. Let $\\sim$ be a relation. We say that $\\sim$ is symmetric if \\(\\forall~ x,y, x \\sim y \\to y \\sim x\\) In other words, if $x$ is related to $y$, then $y$ is also related to $x$. We say that $\\sim$ is antisymmetric if \\(\\forall~ x,y, x \\sim y \\to y \\sim x \\to x=y\\) So if both $x$ is related $y$ and $y$ is related to $x$, then in fact they have to be equal. We say that $\\sim$ is asymmetric if \\(\\forall~ x,y, x \\sim y \\to x \\not \\sim y\\) . Again equality is symmetric but divisibility. Both $ \\leq $ and $\\subseteq$ are examples of antisymmetric relations. Strict less than $ &lt; $ is asymmetric. Note that any relation that is symmetric and antisymmetric is very close to equality. In particular if $x \\sim y$ then we must have $x = y$. Definition. Let $\\sim$ be a relation. We say that $\\sim$ is transitive if \\(\\forall~ x,y,z, x \\sim y \\to y \\sim z \\to x \\sim z\\) In other words, if $x$ is related to $y$ and $y$ is related to $z$, then we know that $x$ is related to $z$. Equality, divisibility, and $ &lt; $ are all transitive. Definition. We say that $\\sim$ is total if \\(\\forall~ x,y, x \\sim y \\lor y \\sim x\\) Total relations are ones where we can compare every pair, one way or another. So $=$ and $\\subseteq$ are rarely total but $\\leq$ is total. These notions are interrelate. Assuming some can imply others or their negations. For example, . Lemma. If a relation is total, then it is reflexive. Proof. (Expand to view) Assume $\\sim$ is a total relation. Since $\\sim$ is total, we know that either $x \\sim x$ or $x \\sim x$ for any $x$. But either branch is exactly what we want. &#9632; . This looks like . theorem total_refl { R : α → α → Prop } (h : Total R) : Reflexive R := fun a =&gt; eq_or (h a a) where eq_or {P : Prop} (h : P ∨ P) : P := by cases h; repeat assumption . in Lean. A where keyword allows you to introduce unknown results and use them if you provide their definition and proof after the where statement. Let’s look at some specific properties of division. Recall that, for two natural numbers (or integers) $n$ and $m$, $n \\mid m$ means there exists some $c \\in \\mathbb{N}$ (or $\\mathbb{Z}$) with $m = cn$. Let’s show that this is reflexive, anti-symmetric, and transitive. def Divides (a b : Nat) : Prop := ∃ c, b = c*a infix:60 \" | \" =&gt; Divides theorem div_refl : Reflexive Divides := by -- take some number a intro a -- we know that a = 1*a have : a = 1*a := Eq.symm (Nat.one_mul a) -- exists takes the witness and looks for the proof in -- the context to close the goal exists 1 theorem div_antisym : AntiSymmetric Divides := by -- take two numbers a and b and assume that a | b and b | a intro a b h₁ h₂ -- extract the multiples and proofs of equality have ⟨c₁,h₁⟩ := h₁ have ⟨c₂,h₂⟩ := h₂ -- we break it into the case where a = 0 and a ≠ 0 by_cases h : a = 0 -- we can write h₁ : b = c₁ * a using a = 0 to get b = 0 · rw [h,Nat.mul_zero,←h] at h₁ exact Eq.symm h₁ -- we use basic facts about natural numbers to show that -- c₁ and c₂ are both 1 · rw [h₁,←Nat.mul_assoc,Nat.mul_comm] at h₂ conv at h₂ =&gt; lhs ; rw [←Nat.mul_one a] have : 1 = c₂ * c₁ := Nat.mul_nonzero_cancel h h₂ have : c₁ = 1 := (Nat.prod_eq_one (Eq.symm this)).right rw [this,Nat.one_mul a] at h₁ exact Eq.symm h₁ theorem div_trans : Transitive Divides := by -- we have a,b,c with a | b and b | c intro a b c h₁ h₂ -- we extract the witnesses have ⟨d₁,h₁⟩ := h₁ have ⟨d₂,h₂⟩ := h₂ -- we get c = (d₂*d₁)*a rw [h₁,←Nat.mul_assoc] at h₂ exists d₂*d₁ . We can find facts about $\\mathbb{N}$ in the namespace Nat and we will see how $\\mathbb{N}$ is defined and how facts like these are proven soon. (In fact, some of these results don’t exist at the moment 🫢.) . Example. Let’s take the set $\\lbrace 0,1,2 \\rbrace$ and construct relations satisfying some, and not other, properties above. | $R = \\varnothing$ is irreflexive, symmetric, antisymmetric, asymmetric, and transitive. It is not reflexive or total. | $R = \\lbrace (0,0) \\rbrace$. This is symmetric, antisymmetric, and transitive. It is not reflexive, irreflexive, asymmetric, or total. | $R = \\lbrace (0,1), (1,0) \\rbrace$. This is irreflexive and symmetric. It is not reflexive, irreflexive, antisymmetric, asymmetric, transitive, or total. | $R = \\lbrace (0,1), (1,2) \\rbrace$. This is irreflexive, antisymmetric, and asymmetric. It is not reflexive, symmetric, transitive, or total. | $R = \\lbrace (0,1), (1,2), (2,0) \\rbrace$ is irreflexive, antisymmetric, asymmetric, and total. It is not reflexive, symmetric, or transitive. | $R = \\lbrace (0,0), (0,1), (1,2), (2,0) \\rbrace$ is antisymmetric but is not reflexive, irreflexive, symmetric, asymmetric, transitive, or total. | $R = \\lbrace (0,0), (0,1), (1,0), (1,1) \\rbrace$ is symmetric and transitive but is not reflexive, irreflexive, antisymmetric, asymmetric, or total. | $R = \\lbrace (0,0), (0,1), (1,0), (1,1), (1,2), (2,0), (2,2) \\rbrace$ is reflexive and total. It is not irreflexive, symmetric, antisymmetric, asymmetric, or transitive. | . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/properties/#properties-of-relations",
    "relUrl": "/notes/relations/properties/#properties-of-relations"
  },"160": {
    "doc": "Useful properties",
    "title": "Useful properties",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/relations/properties/",
    "relUrl": "/notes/relations/properties/"
  },"161": {
    "doc": "Properties of functions",
    "title": "Important properties of functions",
    "content": "Here are two import properties a function can have. Definition. We say a function $f: A \\to B$ is injective if for all $a_1,a_2$ with $a_1 \\neq a_2$ we have $f(a_1) \\neq f(a_2)$. So formally, a function is injective if it satisfies \\(\\forall a_1, a_2, a_1 \\neq a_2 \\to f(a_1) \\neq f(a_2)\\) . Example. The function \\(f : \\mathbb{Z} \\to \\mathbb{Z} \\\\ n \\mapsto n + 1\\) is injective. For, if $f(n_1) = f(n_2)$, we have $n_1 + 1 = n_2 + 1$. Adding $-1$ to both sides, gives $n_1 = n_2$. In checking injectivity of the previous example, we encountered the contrapositive $f(a_1) = f(a_2) \\to a_1 = a_2$ which is also often taken as the definition of injectivity. Here is a definition of injectivity and a proof of this example in Lean the natural numbers. def Injective (f : α → β) : Prop := ∀ ⦃a₁ a₂⦄, f a₁ = f a₂ → a₁ = a₂ def f (n : Nat) : Nat := n + 1 example : Injective f := by -- assume we have two natural numbers and their images are equal intro (n₁ : Nat) (n₂ : Nat) (h : f n₁ = f n₂) -- in the library defining the natural numbers we find the useful -- fact that if n + k = m + k we know can conclude n = m. This -- exactly what we want exact Nat.add_right_cancel h . Example. The function \\(g : \\mathbb{Z} \\to \\mathbb{Z} \\\\ n \\mapsto n^2 - 3n + 2\\) is not injective since $g(1) = g(2) = 0$. We can show that $g$ is also not injective in the natural numbers in Lean. example : ¬ Injective g := by -- we assume that g is actually and try to reach an absurdity intro (n : Injective g) -- we use rfl to compute and check equality have : g 1 = g 2 := by rfl -- applying the have : 1 = 2 := n this -- someone has already told Lean that n &lt; n + 1 for all n have o : 1 &lt; 2 := Nat.lt_succ_self 1 -- and they have also told Lean that n &lt; m → ¬ (n = m) exact Nat.ne_of_lt o this . Injectivity can be viewed as saying $f: A \\to B$ injects a copy of $A$ into $B$. Definition. A function $f: A \\to B$ is surjective if, for any $b$ in $B$, there is some $a$ with $f(a) = b$. Formally, \\(\\forall b, \\exists a, f(a) = b\\) . Returning to our two examples above, we see $n \\mapsto n+1$ is also surjective. Given $m \\in \\mathbb{Z}$, since $f(m-1) = m$, we have an element mapping to $m$. Thus, $f$ is surjective. If we change the domain and codomain to $\\mathbb{N}$, $n \\mapsto n + 1$ is no longer surjective . def Surjective (f : α → β) : Prop := ∀ b, ∃ a, f a = b example : ¬ Surjective f := by intro (h : Surjective f) have ⟨m,g⟩ : ∃ n, n + 1 = 0 := h 0 -- we use that 0 is never equal to n + 1 for n : Nat exact Nat.succ_ne_zero m g . The function $n \\mapsto n^2$ is not surjective since there is no integer that solves $n^2 = -1$. Often one wants to understand the totality of $b$’s for which there is some $a$ such that $f(a) = b$. This is called the range (or image) of $f$. Note the range and codomain are distinct in general. Indeed, \\(f : \\mathbb{Z} \\to \\mathbb{Z} \\\\ n \\mapsto n + 1\\) is surjective to the range equals the codomain. But each integer is also a real number so the function \\(f : \\mathbb{Z} \\to \\mathbb{R} \\\\ n \\mapsto n + 1\\) is also well-defined. Even though, as is common, we used the same notation for the two functions, they are not equal as function because they have two different codomains. We can think of a surjective function $f: A \\to B$ as way of covering $B$ with $A$ using the rule $f$. We can combine the two notions in a single one. Definition. A function $f: A \\to B$ is bijective if it is both injective and surjective. In Lean, . def Bijective (f : α → β) : Prop := Injective f ∧ Surjective f . Our first example, $n \\mapsto n+1$, is bijective. Bijectivity can be rephrased as \\(\\forall b, \\exists ! a, f(a) = b\\) For any $b$, there is exactly one value $a$ satisfying $f(a) = b$. Injectivity, surjectivity, and bijectivity are preserved under composition in the following sense. Theorem. Let $f : A \\to B$ and $g : B \\to C$ be functions. | Suppose $f$ and $g$ are injective, Then $g \\circ f$ is also injective. | Suppose $f$ and $g$ are surjective. Then $g \\circ f$ is also surjective. | Suppose $f$ and $g$ are bijective. Then $g \\circ f$ is also bijective. | . Proof. (Expand to view) Assume that $f$ and $g$ are injective. If $g(f(a_1)) = g(f(a_2))$, then since $g$ is injective we know that $f(a_1) = f(a_2)$. But since $f$ is injective, we have $a_1 = a_2$. Thus, $g \\circ f$ is injective. Assume that $f$ and $g$ are surjective. Then for a $c$ there is some $b$ with $g(b) = c$ since $g$ is sujective. There is also some $a$ with $f(a) = b$ since $f$ is surjective. Thus, we have $a$ with $g(f(a)) = c$ and $g \\circ f$ is surjective. Finally if both $f$ and $g$ are bijections, then, by definition, they are both injective and surjective. We have just shown that $g \\circ f$ is then injective and surjective or is a bijection. &#9632; . We can also detect injectivity or surjectivity using a composition. Theorem. Let $f : A \\to B$ and $g : B \\to C$ be functions. | If $g \\circ f$ is injective, then $f$ is injective. | If $g \\circ f$ is surjective, then $g$ is surjective. | . Let’s give a proof of this in Lean. theorem comp_inj (f : α → β) (g : β → γ) (h : Injective (g ∘ f)) : Injective f := by -- assume we have two values with equal image intro (a₁ : α) (a₂ : α) (h₁ : f a₁ = f a₂) -- apply g to equal arguments yields equal outputs have : g (f a₁) = g (f a₂) := congrArg g h₁ exact h this theorem comp_surj (f : α → β) (g : β → γ) (h : Surjective (g ∘ f)) : Surjective g := by -- take some and try to solve g b = c for some b intro (c : γ) -- take the a satisfying g (f a) = c and the proof of equality have ⟨a,h₁⟩ : ∃ a, g (f a) = c := h c -- the b we want is f a and the same proof of equality works exact ⟨f a, h₁⟩ . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/properties/#important-properties-of-functions",
    "relUrl": "/notes/functions/properties/#important-properties-of-functions"
  },"162": {
    "doc": "Properties of functions",
    "title": "Properties of functions",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/functions/properties/",
    "relUrl": "/notes/functions/properties/"
  },"163": {
    "doc": "Reductio ad absurdum",
    "title": "Proof by contradiction",
    "content": "Suppose I can establish an absurdity by assuming the negation of something. What does this give us? Well, given $\\neg A \\vdash \\bot$, we can prove $\\neg \\neg A$. If we that the sun is not not up, that usually means that it is actually up, right? . More formally, we want to know about jutisfying \\(\\neg \\neg A \\vdash A\\) Can this be done using the rules so far? . Unfortunately, nothing in our rules so far will allow us establish this. Adding this rule to our existing system yields some very useful conclusions. For example, given $\\neg A \\vdash \\bot$, we already knew we could establish $\\vdash \\neg \\neg A$ but now we also have $\\vdash A$. The process of establishing $A$ by assuming $A$ doesn’t hold and arguing to a contradiction goes by the Reductio ad absurdum (RAA) or proof by contradiction. Another well-known conclusion is the Law of the Excluded Middle which is just \\(A \\lor \\neg A\\) In other words, no matter what $A$ is either $A$ holds or it is doesn’t. You might take a moment and think this an immutable law of reality. Our day-to-day experience definitely leads us to think this. But reality in general is more complicated. Think of Schrodinger’s cat. Is the cat alive or not alive in the box? What is the state of the unobserved wave function? . But in an idealized world proof by contradiction is a perfectly reasonable assumption. And mathematicians, for the most part, tend to idealize our world. Below is a proof the Law of Excluded Middle using proof by contradiction. Given an formula of the form $A \\to B$, the contrapositive is the formula \\(\\neg B \\to \\neg A\\) . Let’s justify \\(A \\to B \\vdash \\neg B \\to \\neg A\\) . Below is a natural deduction proof . If we substitute $\\neg B$ for $A$ and $\\neg A$ for $B$, we immediately have \\(\\neg B \\to \\neg A \\vdash (\\neg \\neg A) \\to (\\neg \\neg B)\\) With proof by contradiction, we get \\(\\neg B \\to \\neg A \\vdash A \\to B\\) . Establishing the contrapositive and deducing the original statement is uncommonly common pattern in mathematical argument. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/raa/#proof-by-contradiction",
    "relUrl": "/notes/propositional_logic/raa/#proof-by-contradiction"
  },"164": {
    "doc": "Reductio ad absurdum",
    "title": "Reductio ad absurdum",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/raa/",
    "relUrl": "/notes/propositional_logic/raa/"
  },"165": {
    "doc": "Recursion",
    "title": "Working with Peano $~\\mathbb{N}$",
    "content": "We already know a good deal about the natural numbers from life but how do we work with Peano natural numbers. The answer is recursion. Theorem. Let $Y$ be a set. For all $y \\in Y$ and $h : \\mathbb{N} \\times Y \\to Y$, there is a unique function $f : \\mathbb{N} \\to Y$ such that $f(0) = y$ and $f(s(n)) = h(s(n),f(n))$ for all $n \\in \\mathbb{N}$. Proof. (Expand to view) For an natural number of the form $0$ or $s(n)$ for some other natural number where we know $f(n)$, we can define $f$ directly. $$ \\begin{aligned} f(0) &amp; := y \\\\ f(s(n)) &amp; := h(s(n),f(n)) \\text{ whenever $f(n)$ is defined } \\end{aligned} $$ Is this a definition for every $n \\in \\mathbb{N}$? Let $$ X := \\lbrace n \\in \\mathbb{N} \\mid f(n) \\text{ is defined} \\rbrace $$ Then $0 \\in X$. And, if $n \\in X$, then $s(n) \\in X$ from the definition of $f$. Peano's last axiom says that $\\mathbb{N} \\subseteq X$. Of course, in this case, $X \\subseteq \\mathbb{N}$. So $X = \\mathbb{N}$ and $f(n)$ is defined for all $n$. Now we turn to uniqueness of $f$. Assume we have two different functions $f,g : \\mathbb{N} \\to Y$ satisfying the conditions of the theorem and set $$ X := \\lbrace n \\in \\mathbb{N} \\mid f(n) = g(n) $$ Then $0 \\in X$ since $f(0) = y = g(0)$. Assume that $n \\in X$, so $f(n) = g(n)$. Then, $$ f(s(n)) = h(s(n),f(n)) = h(s(n),g(n)) = g(s(n)) $$ so $s(n) \\in X$. Thus, $\\mathbb{N} = X$ as before and $f = g$. &#9632; . Now, let’s see what this means and how to use it. The function $h$ allows for any way to combine the natural number $s(n)$ and value, we already know, for $f(n)$. Example. Suppose $Y = \\mathbb{N}$. Let’s take our initial value to $1$. And let $h(n,m) = nm$, the product of $n$ and $m$. Then we want a function $f: \\mathbb{N} \\to \\mathbb{N}$ which satisfies . | $f(0) = 1$ and | $f(n+1) = (n+1)f(n)$ | . The function that satisfies this is the factorial $n \\mapsto n!$. We write the value $n!$ purely in terms of $n$ alone: \\(n! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\cdots 2 \\cdot 1\\) Writing function defined via recursion this way is called its closed form. In Lean, we can build factorial as . def Factorial (n : Nat) : Nat := match n with | 0 =&gt; 1 | m+1 =&gt; (m+1)*(Factorial m) . The match n with tells Lean consider the different ways we can get a natural number from its constructors. Either we have 0 or the number is a successor n = m+1. In each case, we have provided a value output by Factorial. We see also that Lean knows that 0 really means zero and n+1 is succ n. We might also overlook that we used multiplication of natural numbers. Lean knows multiplication already but what did someone tell it. def Mult (n m : Nat) : Nat := match n, m with | _, 0 =&gt; 0 | _, m+1 =&gt; Mult n m + n . We use $n(m+1) = nm + n$ to define multiplication recursively. But now you might have noticed that we added terms of Nat. What is addition? . def Plus : Nat → Nat → Nat | n, Nat.zero =&gt; n | n, Nat.succ m =&gt; Nat.succ (Plus n m) . where we explicitly used Nat.zero and Nat.succ. You can find the actual definitions of addition and multiplication in Nat under Nat.add and Nat.mul. We can check that with our definition Plus n 1 = Nat.succ n for all n. theorem plus_one_eq_succ (n : Nat) : Plus n 1 = Nat.succ n := by rfl . If we try the other order for adding one, you get the following error. theorem one_plus_eq_succ (n : Nat) : Plus 1 n = Nat.succ n := by rfl tactic 'rfl' failed, equality lhs Plus 1 n is not definitionally equal to rhs Nat.succ n . Why is this? As a hint, we try to break it into the cases for constructing n. theorem one_plus_eq_succ (n : Nat) : Plus 1 n = Nat.succ n := match n with | 0 =&gt; by rfl -- ok | Nat.succ m =&gt; by rfl tactic 'rfl' failed, equality lhs Plus 1 (Nat.succ m) is not definitionally equal to rhs Nat.succ (Nat.succ m) . If we look at the definition we have . Plus 1 (Nat.succ m) = Nat.Succ (Plus 1 m) . These are not the same! But we can use the proof for case of m to finish. We rewrite the right-hand side of the goal using Plus 1 m = Nat.succ m. Then Lean sees defintional equality. theorem one_plus_eq_succ (n : Nat) : Plus 1 n = Nat.succ n := match n with | 0 =&gt; by rfl | Nat.succ m =&gt; by conv =&gt; rhs rw[←one_plus_eq_succ m] . This is the our first encounter with induction. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/recursion/#working-with-peano-mathbbn",
    "relUrl": "/notes/induction/recursion/#working-with-peano-mathbbn"
  },"166": {
    "doc": "Recursion",
    "title": "Recursion",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/recursion/",
    "relUrl": "/notes/induction/recursion/"
  },"167": {
    "doc": "New rules of inference",
    "title": "Introduction and elimination for $~\\forall$",
    "content": "With a richer language of symbols comes more rules that mimic how we argue about truth. Here we extend the rules of inference from propositonal logic to include rules for quantifiers and equality. Introduction and elimination rules model how we use formulas as assumptions or conclude then as goals in arguments. How would we conclude that something is true for all values of a variable? Let’s call our formula $A(x).$ Well, if we can establish $A(x)$ without imposing any “conditions” on $x$, we should be free to conclude $\\forall x~ A(x)$. In particular, we should not have any hypotheses floating around that depend on $x$ themselves. For example, if we assumed that $4 \\mid n$, then we could conclude that $n$ is even. But it would make no sense to conclude that $n$ is even for all $n$. Our standing assumption placed conditions on $n$. Following this idea, we use the following introduction rule: . but only if $x$ is not free in any uncancelled hypotheses at this step. Elimination works very much in the reverse. Given a proof of $\\forall x~ A(x)$, we get a proof of $A(x)$ itself. A proof of a formula $A(x)$ with free variable behaves like a proof the formula of the universal quantification over it $\\forall x~ A(x)$. We can be a more general . where $t$ is any other term available to us. You can think of this as a useful change of variables. However, we need to be careful about collisions of names – we need to make sure that $t$ is itself does not involve any variables bound elsewhere in $A(x)$. For example, if we have the formula $\\forall x~ \\exists~y \\neg(x = y)$ and we try to eliminate to $\\exists y~ \\neg(y = y)$ by taking $t=y$ we quickly run into problems. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/rules/#introduction-and-elimination-for-forall",
    "relUrl": "/notes/predicate/rules/#introduction-and-elimination-for-forall"
  },"168": {
    "doc": "New rules of inference",
    "title": "Introduction and elimination for $~\\exists$",
    "content": "Now let’s think about the existential quantifier. If we can provide a proof of $A(t)$, now regardless of the extra assumptions, we can conclude $\\exists x~ A(x)$. Again our switch from $t$ to $x$ allows for convenient change of variables. We next come to the existential elimination. It is a good point to stop and make a useful analogy between the pair $\\forall$ and $\\exists$ and the pair $\\land$ and $\\lor$. Suppose we our variable could only take a finite set of values $x_1,\\ldots,x_n$. Then saying $\\forall x~ A(x)$ is true is equivalent to saying that the big conjunction \\(A(x_1) \\land A(x_2) \\land \\cdots \\land A(x_n)\\) is true. Similarly, saying that $\\exists x~ A(x)$ is true is equivalent to the big disjunction \\(A(x_1) \\lor A(x_2) \\lor \\cdots \\lor A(x_n)\\) being true. Via this analogy, in the general setting, $\\forall$ can be viewed as akin to an “infinite and” and $\\exists$ can be viewed as an “infinite or”. From within this interpretation, the elimination rule for $\\exists looks familiar. To use $\\exists x~ A(x)$ in a proof and reach a conclusion $C$, we need to provide a proof that, in any case, we can prove $C$. Formally, we have . Like with $\\lor$, we need to provide an argument in any case, $A(y)$, concluding $C$ to use the fact we know there is some $x$ such that $A(x)$ holds. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/rules/#introduction-and-elimination-for-exists",
    "relUrl": "/notes/predicate/rules/#introduction-and-elimination-for-exists"
  },"169": {
    "doc": "New rules of inference",
    "title": "Rules for \\(~=\\)",
    "content": "Finally, we have a set of rules for $=$. While these do not look like our previous rules, they should seem familiar from experience. Equality allows us to build new formula, namely $x = y$. First, we should know that $x=x$ always. Next, we have that $=$ is symmetric. And that $=$ is transitive. Finally, we have two rules regarding subsitution into functions and predicates. Equal inputs produce equal outputs of functions. If we have equal terms and a proof a predicate depending on the first term, then we can conclude we have a proof of the same predicate after substitution. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/rules/#rules-for-",
    "relUrl": "/notes/predicate/rules/#rules-for-"
  },"170": {
    "doc": "New rules of inference",
    "title": "New rules of inference",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/predicate/rules/",
    "relUrl": "/notes/predicate/rules/"
  },"171": {
    "doc": "Proofs and our first rules",
    "title": "Proofs",
    "content": "I said everything in Lean has a type. What is the type of a proof of a formula X : Prop? Let’s call the proof h. Well, its type is X itself. In addition to being a term in the (big) type of Prop, X is itself a type whose terms are proofs of X. We can of course declare we have a proof (without providing one) by saying . variable (A : Prop) variable (h : A) . But far more important for us is producing proofs! . Before we look at some basic examples, let’s introduce two new keywords for Lean: example and theorem. Both of these tell Lean that we want to produce a proof for a particular proposition. Here are some examples: . variable (A : Prop) example : A := sorry theorem bigOne : A := sorry . The main difference between example and theorem is that theorem expects a name whereas example does not. Each of these is telling Lean that I am going to provide a proof of A. This is why we end the statement with : A. It is informing Lean the type of the coming proof. The proof goes after :=. sorry is a special command that decreases the volume of the complaints from Lean that we did not actually provide a proof. If we remove sorry, we notice that the message is in red now: unexpected end of input. Messages like these from the infoview pane are meant to be helpful in constructing our proofs but they can be cryptic. A good rule is to step back a little and meditate on the error message in the context of the question. In general, we cannot produce a proof out of nothing except for situations. Even so, they are instructive to investigate. Suppose I want to establish $A \\vdash A$. This is trivial in propositional logic: I have $A$ so I have $A$. How does this look in Lean? . For examples/theorems, we can put the assumptions on the left-hand side of the semi-colon. example (h : A) : A := sorry . This reads as: “assume I have a proof h of A and I want to prove A”. A completed proof is: . example (h : A) : A := h . You are providing the assumed proof of A as the desired proof of A. A formula we can always prove is $\\top$. In Lean, this proposition is called True and $\\bot$ goes by False. The introduction rule for True comes in the form of a canonical proof called true of type True. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/rules/#proofs",
    "relUrl": "/notes/lean/rules/#proofs"
  },"172": {
    "doc": "Proofs and our first rules",
    "title": "Implication elimination and introduction",
    "content": "Our rules of inference allowed us to build more complicated proofs from some basic steps. Each rule is encoded in Lean. Let’s start by looking at the introduction and elimination rules for implication. Say we have A B : Prop and we want to prove B from A → B and A. This is done as . variable (A B : Prop) example (f : A → B) (h : A) : B := f h . What is going on here? h is a proof of A as before and f is a proof of A → B. What is a proof of A → B? Well, one way to understand it is as a way to turn a proof of A into a proof B. We generally call such things functions. By placing f h, we are saying “feed h into f and use the output”. A more common way to say it is that we applied f to h. Application of f of h is how $\\to$-elimination is implemented in Lean. Next we look at $\\to$-introduction. For example, how would we finish the following? . variable (A : Prop) example : A → A := sorry . This difference between this example and . example (h : A) : A := h . is the exactly the elimination rule for implication. We want to make a function f : A → A which mimics our intitution that given a proof h : A that we can output that given proof to get a proof of A. The syntax for doing so is seen below in the completed example. variable (A : Prop) example : A → A := fun (h:A) =&gt; h . fun tells Lean that a function is coming (h : A) specifies the input (and its type). The arrow =&gt; separates the input from the output. Strictly speaking this is not the implication introduction rule but it plays an important part. variable {A B : Prop} theorem superProof (h : A) : B := sorry example : A → B := fun (h : A) =&gt; superProof h . We can treat the (nonexistent) proof of our theorem as a function. But you may have noticed the braces { A B : Prop }. When we declare (A : Prop), Lean adds it as an assumption to all examples/theorems in our file. So really superProof has the form . theorem {A B : Prop} superProof (h : A) : B := sorry . Using the parentheses (A B : Prop) tells Lean that I want A and B to also be (explicit) inputs to superProof. (When we saying variable to Lean, it really goes all out.) . Using the braces {A B : Prop} tells Lean “you figure out A and B” from the other information. Which is can do in the case of our example from the desired type is A → B. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/rules/#implication-elimination-and-introduction",
    "relUrl": "/notes/lean/rules/#implication-elimination-and-introduction"
  },"173": {
    "doc": "Proofs and our first rules",
    "title": "Proofs and our first rules",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/lean/rules/",
    "relUrl": "/notes/lean/rules/"
  },"174": {
    "doc": "Me",
    "title": "Staff",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/staff/#staff",
    "relUrl": "/staff/#staff"
  },"175": {
    "doc": "Me",
    "title": "Instructor",
    "content": "Schedule an appointment . I am a Professor in the Department of Mathematics at the University of South Carolina. I have been teaching mathematics for almost two decades and have guided nearly 1000 students from all levels through math courses. A mindset focused on growth is essential for learning mathematics. Each day is a small step forward. When we turn around at the end of the course, only then, do we see how far we have truly traveled. For more of my pedagogical philosophy and experience, take a look at the teaching page. As an extension of teaching, I take pride in mentoring researchers at any stage. In my research, I study algebraic geometry and am particularly interested in questions arising from Homological Mirror Symmetry. Much of my current work focuses on derived categories and their relation to more classical questions. My research has been partially supported by the Simons Foundation and the National Science Foundation. It has also benefited from a membership at the Institute for Advanced Study, funding from UofSC, and the Southeastern Conference. For more information about me, see my CV. For a research summary and a list of my papers, take a look at my research page. ",
    "url": "https://300.f22.matthewrobertballard.com/staff/#instructor",
    "relUrl": "/staff/#instructor"
  },"176": {
    "doc": "Me",
    "title": "Me",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/staff/",
    "relUrl": "/staff/"
  },"177": {
    "doc": "Strong induction",
    "title": "Another variant of induction",
    "content": "Sometimes, the previous version is called weak induction compared to the following version where the you have a stronger assumption available for use in the induction step. Theorem (Strong induction). Let $P$ be a predicate on $n \\in \\mathbb{N}$. Assume we have some $n_0 \\in \\mathbb{N}$ with . | a proof of $P(n_0)$ and | a proof, for all $n \\geq n_0$, that \\((\\forall~ n_0 \\leq k \\leq n, P(k)) \\to P(n+1)\\) | . Then, we have a proof of $\\forall~ n \\geq n_0, P(n)$. Proof. (Expand to view) We make a new predicate $$ Q(n) = \\forall~ n_0 \\leq k \\leq n, P(n) $$ So a proof of $Q(n)$ is the same as proofs of each $P(k)$ for all $k$ between $n_0$ and $n$. Note that, for any $n \\geq n_0$, we have $Q(n) \\to P(n)$. We use the usual version of induction to prove $Q(n)$ for all $n$. For the base case, we note that $Q(n_0) = P(n_0)$ which we have assumed we can prove. For the induction step, we have assumed that we can prove $$ Q(n) \\to P(n+1) $$ But $$ Q(n+1) = Q(n) \\land P(n+1) $$ so we can prove $Q(n) \\to Q(n+1)$. Appealing to (weak) induction, we can prove $Q(n)$ for all $n \\geq n_0$. Since $Q(n)$ implies $P(n)$, we prove $P(n)$ for all $n \\geq n_0$. &#9632; . A Lean-version of the proof is below. -- We will use this but will not prove it theorem based_induction {P : Nat → Prop} {n₀ : Nat} (base : P n₀) (ind : ∀ n, n₀ ≤ n → P n → P (n+1)) (m : Nat) : n₀ ≤ m → P m := sorry -- This is the definition of Q(n) in the proof above def StrongPred (P : Nat → Prop) (n₀ : Nat) : Nat → Prop := fun n =&gt; ∀ k, n₀ ≤ k → k ≤ n → P k -- Another two results we will use but not prove. You should -- recognize them from the above proof. -- To prove Q(n+1) it suffices to prove Q(n) and P(n+1) theorem sp_succ { P : Nat → Prop } { n₀ : Nat } (m : Nat) : StrongPred P n₀ m ∧ P (m+1) → StrongPred P n₀ (m+1) := sorry -- Q(n) implies P(n) for all n theorem strong_pred_imp {P : Nat → Prop} {n₀ : Nat} (h : n₀ ≤ n) : StrongPred P n₀ n → P n := sorry theorem strong_induction {P : Nat → Prop} {n₀ : Nat} (base : P n₀) (ind : ∀ n, StrongPred P n₀ n → P (n+1)) (m : Nat) : n₀ ≤ m → P m := by -- We will want to apply based_induction to StrongPred -- The base case is n₀ have base' : StrongPred P n₀ n₀ := by intro k h₁ h₂ have : k = n₀ := Nat.le_antisymm h₂ h₁ rwa [this] -- The induction step have ind' : ∀ n, n₀ ≤ n → StrongPred P n₀ n → StrongPred P n₀ (n+1) := by intro n _ h' apply sp_succ n have p : P (n+1) := ind n h' exact ⟨h',p⟩ -- We appeal to based induction for StrongPred have SP : ∀ n, n₀ ≤ n → StrongPred P n₀ n := based_induction base' ind' -- Finally StrongPred P n₀ n → P n exact fun h =&gt; strong_pred_imp h (SP m h) . Why do we have this version? In general, $P(n) \\to P(n+1)$ might be false where $(\\forall k \\leq n, P(k)) \\to P(n+1)$ is true. We cannot use (weak) induction in this case but we can use strong induction. Example. The Tribonacci sequence is a sequence defined recursively by \\(a_0 = 0, a_1 = 0, a_2 = 1, a_n = a_{n-1} + a_{n-2} + a_{n-3} \\text{ if } n \\geq 3\\) Let’s show that $a_n \\leq 2^{n-3}$ for all $n \\geq 3$ using strong induction. Our base case is $n=3$. Then $a_3 = 1$ and $2^{3-3} = 1$. Now assume that we know that $a_k \\leq 2^{k-3}$ for $3 \\leq k \\leq n$. We have \\(a_{n+1} = a_n + a_{n-1} + a_{n-2} \\leq 2^{n-3} + 2^{n-4} + 2^{n-5}\\) as long as $n \\geq 5$. We will need to cover the cases of $n=3,4$ separately. We will circle back to this but for right now assume that $n \\geq 5$. Then, we can use the inequality above. We have \\(2^{n-3} + 2^{n-4} + 2^{n-5} = 2^{n-5}(4 + 2 + 1) = 7 \\cdot 2^{n-5} &lt; 2^3 \\cdot 2^{n-5} = 2^{n-2}.\\) Thus $a_{n+1} \\leq 2^{n-2}$ as long as $n \\geq 5$. Assume that $n = 4$. Then we prove directly that $a_4 \\leq 2$. We have $a_4 = a_3 + a_2 = 1 + 1 = 2 = 2^1$. Assume that $n = 5$. Then $a_5 = a_4 + a_3 + a_2 = 2 + 1 + 1 = 4 = 2^2$. These cover the missing cases above in the induction step. We can now appeal strong induction to get our conclusion. In examples like the previous one, it makes sense to introduce another variant of induction: strong induction with multiple base cases. Here we cover some extra base cases before the induction step takes over. Corollary. Let $P$ be a predicate on $n \\in \\mathbb{N}$. Assume we have $n_0, n_1 \\in \\mathbb{N}$ with $n_0 \\leq n_1$ with . | proofs of each $P(n_0),\\ldots,P(n_1)$ and | a proof that, for each $n \\geq n_1$, \\((\\forall~ n_0 \\leq k \\leq n, P(k)) \\to P(n+1)\\) | . Then we have a proof of $\\forall~ n \\geq n_0, P(n)$. Let’s do one more example of induction and recursion combined. Definition. For $n, k \\in \\mathbb{N}$, the binomial coefficient $ \\binom{n}{k}$ is defined recursively by \\(\\binom{n}{0}= 1, \\binom{0}{k+1} = 0, \\binom{n+1}{k+1} = \\binom{n}{k} + \\binom{n}{k+1}\\) . Lemma. If $k &gt; n$, then $\\binom{n}{k} = 0$. Proof. (Expand to view) We prove this via induction on $n$. The base case is $n = 0$. Since $k &gt; 0$, we know that $k = k^\\prime + 1$ for some $k^\\prime \\in \\mathbb{N}$. Then by definition $\\binom{0}{k^\\prime + 1} = 0$. Assume we know that $\\binom{n}{k} = 0$ whenever $k &gt; n$. Assume that $k &gt; n+1$. We can again rewrite $k^\\prime + 1 = k$. Then $$ \\binom{n+1}{k^\\prime+1} = \\binom{n}{k^{\\prime}} + \\binom{n}{k^\\prime +1} $$ Since $k^\\prime &gt; n^\\prime$ and $k^\\prime + 1 &gt; n$, both these terms are $0$ by definition. &#9632; . As an example, we compute \\(\\binom{5}{2} = \\binom{4}{1} + \\binom{4}{2} = \\binom{3}{0} + 2\\binom{3}{1} + \\binom{3}{2} = 3 \\binom{3}{0} + 3\\binom{2}{1} + \\binom{2}{2} \\\\ = 3 \\binom{3}{0} + 3 \\binom{2}{0} + 4 \\binom{1}{1} + \\binom{1}{2} = 3 \\binom{3}{0} + 3 \\binom{2}{0} + 4 \\binom{1}{0} + 4 \\binom{0}{1} = 10\\) . Where do these numbers come from and why the name? . Theorem (Binomial formula). For any indeterminants $x$ and $y$ and any $n \\in \\mathbb{N}$ we have \\((x+y)^n = \\sum_{k=0}^n \\binom{n}{k}x^{n-k}y^k\\) . Proof. (Expand to view) We prove this using induction $n$. For the base case of $n=0$, we have $(x+y)^0 = 1$ and $$ \\sum_{k=0}^0 \\binom{n}{k} x^{-k} y^k = \\binom{0}{0} = 1 $$ Assume that $$ (x+y)^n = \\sum_{k=0}^n \\binom{n}{k} x^{n-k} y^k $$ Then $$ (x+y)^{n+1} = (x+y)(x+y)^n = (x+y) \\sum_{k=0}^n \\binom{n}{k} x^{n-k}y^k = \\\\ x \\sum_{k=0}^n \\binom{n}{k} x^{n-k}y^k + y \\sum_{k=0}^n \\binom{n}{k} x^{n-k}y^k = \\\\ \\sum_{k=0}^n \\binom{n}{k} x^{n+1-k}y^k + \\sum_{k=0}^n \\binom{n}{k} x^{n-k}y^{k+1} $$ Now we combine terms into a single sum. For $0 \\leq j \\leq n+1$, we get two contributions: $\\binom{n}{j} x^{n+1-j}y^j$ from the first and $\\binom{n}{j-1} x^{n+1-j} y^j$ from the second. Thus $$ (x+y)^{n+1} = \\sum_{j=0}^{n+1} \\left( \\binom{n}{j} + \\binom{n}{j-1} \\right) x^{n+1-j}y^j \\\\ = \\sum_{j=0}^{n+1} \\binom{n+1}{j} x^{n+1-j}y^j $$ Appealing to induction, we get our desired conclusion. &#9632; . Example. The Binomial Theorem allows access to many interseting formula about binomial coefficients. For example, if we take $x=y=1$, we get \\(2^n = \\sum_{k=0}^n \\binom{n}{k}\\) If we take $x = 1, y = -1$, then we get \\(0 = \\sum_{k=0}^n (-1)^k \\binom{n}{k}\\) . ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/strong_induction/#another-variant-of-induction",
    "relUrl": "/notes/induction/strong_induction/#another-variant-of-induction"
  },"178": {
    "doc": "Strong induction",
    "title": "Strong induction",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/notes/induction/strong_induction/",
    "relUrl": "/notes/induction/strong_induction/"
  },"179": {
    "doc": "Syllabus",
    "title": "Syllabus",
    "content": ". | Course Information . | Course Name and Number | Term | Meeting Time and Location | Instructor Information | Office Hours | Academic Bulletin Description | Full Course Description | Prerequisites | Learning Outcomes | Course Materials | . | Course Requirements . | Course Format | Course Communication | Technology | Minimal Technical Skills Needed | Technical Support | . | Course Assignments and Grading . | Homework | Quizzes | Presentations | Project | Evaluation and Grading Scale . | Assignment Weights | Grading Scale | . | Assignment Submission | Revisions | . | Academic Success . | Accessibility | Student Success Center | Writing Center | University Library Resources | Teams and Technology | Counseling Services | . | Course Policies and Procedures . | Attendance Policy and COVID Reporting | COVID Policies . | Questions You May Have | . | Academic Integrity | Plagiarism | Group Work | Class Conduct | Late Work/Make-up Policy | Incomplete Grades | Diversity and Inclusion | Title IX and Gendered Identity | Expectations of the Instructor | Copyright/Fair Use Statement | . | Tentative Schedule . | Week 1 | Week 2 | Week 3 | Week 4 | Week 5 | Week 6 | Week 7 | Week 8 | Week 9 | Week 10 | Week 11 | Week 12 | Week 13 | Week 14 | Week 15 | Week 16 | . | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/",
    "relUrl": "/syllabus/"
  },"180": {
    "doc": "Syllabus",
    "title": "Course Information",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-information",
    "relUrl": "/syllabus/#course-information"
  },"181": {
    "doc": "Syllabus",
    "title": "Course Name and Number",
    "content": "HNRS: Transition to Advanced Mathematics – Math 300 . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-name-and-number",
    "relUrl": "/syllabus/#course-name-and-number"
  },"182": {
    "doc": "Syllabus",
    "title": "Term",
    "content": "Fall 2022 . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#term",
    "relUrl": "/syllabus/#term"
  },"183": {
    "doc": "Syllabus",
    "title": "Meeting Time and Location",
    "content": "Mondays, Wednesdays, and Fridays 8:30-9:20 AM in LeConte College Room 348 . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#meeting-time-and-location",
    "relUrl": "/syllabus/#meeting-time-and-location"
  },"184": {
    "doc": "Syllabus",
    "title": "Instructor Information",
    "content": ". | Instructor Name and Preferred Title: Prof. Matthew (Matt) Ballard | Preferred pronouns: He/Him/His | Office : LeConte College Room 341 | E-mail: ballard@math.sc.edu | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#instructor-information",
    "relUrl": "/syllabus/#instructor-information"
  },"185": {
    "doc": "Syllabus",
    "title": "Office Hours",
    "content": "Mondays 1-4 or by appointment . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#office-hours",
    "relUrl": "/syllabus/#office-hours"
  },"186": {
    "doc": "Syllabus",
    "title": "Academic Bulletin Description",
    "content": "Rigor of mathematical thinking and proof writing via logic, sets, and functions. Intended to bridge the gap between lower-level (computational-based) and upper-level (proof-based) mathematics courses. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#academic-bulletin-description",
    "relUrl": "/syllabus/#academic-bulletin-description"
  },"187": {
    "doc": "Syllabus",
    "title": "Full Course Description",
    "content": "Logical verification of a statement is a skill broadly employed, from Plato to Alexa. It is also the central framework of communication in mathematics. In this course, we train this skill in three distinct but complementary ways: . | Oral and written communication in the natural language of mathematical ideas and proofs. | Formal deduction in symbolic logic. | Interactive theorem proving in the proof assistant Lean. | . Using this language, we explore the fundamental mathematical concepts of . | sets | functions | relations | the natural numbers and induction. | . Finally, with our new skills, we tackle a more advanced mathematical topic. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#full-course-description",
    "relUrl": "/syllabus/#full-course-description"
  },"188": {
    "doc": "Syllabus",
    "title": "Prerequisites",
    "content": "C or better in MATH 142, or consent of the Undergraduate Director . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#prerequisites",
    "relUrl": "/syllabus/#prerequisites"
  },"189": {
    "doc": "Syllabus",
    "title": "Learning Outcomes",
    "content": "After successful completion of this course, you will be able to: . | Write clear, correct, and readable mathematical proofs. | Achieve facility with symbolic logic and formal deduction. | Use an interactive proof assistant. | Appreciate new mathematics ideas. | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#learning-outcomes",
    "relUrl": "/syllabus/#learning-outcomes"
  },"190": {
    "doc": "Syllabus",
    "title": "Course Materials",
    "content": "The main resources for materials are the course website and the Microsoft Team for the course. Some supplemental resources: . | C. Newstead. An infinite descent into pure mathematics | J. Avigad, L. de Moura, S. Kong, and S. Ullrich. Theorem proving in Lean | A. Stefanowicz. Proofs and Mathematical Reasoning | . All course materials comply with copyright/fair use policies. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-materials",
    "relUrl": "/syllabus/#course-materials"
  },"191": {
    "doc": "Syllabus",
    "title": "Course Requirements",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-requirements",
    "relUrl": "/syllabus/#course-requirements"
  },"192": {
    "doc": "Syllabus",
    "title": "Course Format",
    "content": "To wholly and successfully engage with the course, you will need to be need to attend class, attempt lots of problems, and engage both with me and your fellow classmates. All course materials are will be made available online so regular Internet access is essential for successful completion of the course. Due to construction delays for the renovation of LeConte College, we will plan to meet virtually until September 7, at least. We will use Microsoft Teams. Links to the meeting will be provided in advance. We will return to face-to-face instruction when possible. It is expected that much of this material will be unfamiliar to you. (If not, more power to you.) The course is structured to guide every student to mastery in terms of conceptual understanding and computational fidelity by the end of the semester. Class time will be spent working in small groups and presenting solutions to problems. It is expected you will have consumed the relevant material ahead of each course. It is not expected you will be comfortable with the material. Class time is for learning through doing and working through your misunderstandings. There will be weekly quizzes to diagnose any problems. At the end of the class, a project will be due in place of a final exam. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-format",
    "relUrl": "/syllabus/#course-format"
  },"193": {
    "doc": "Syllabus",
    "title": "Course Communication",
    "content": "I will be communicating with you regarding grades and assignments. If you need to get in touch with me, the best method is via Microsoft Team chat or email. Generally, I will reply within 24 hours and will provide feedback on assignments within one week. You may also post questions pertaining to the course in the Questions channel in the course team. These questions will be answered within 24 hours. I encourage all students to take a stab at answering any question. If you are having trouble with this course or its material, you should contact me via Microsoft Team chat or email to discuss the issues. Announcements will be posted to this course whenever necessary. If there is any other information I think is important, I will send it to your preferred university email address. It is your responsibility to ensure that your email account works properly in order to receive email. If you are unsure of your preferred email, check your account at myaccount.sc.edu. For more information on setting your preferred university email, please see the Knowledge Base Article How To Change Your Primary University Email Address. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-communication",
    "relUrl": "/syllabus/#course-communication"
  },"194": {
    "doc": "Syllabus",
    "title": "Technology",
    "content": "To participate in learning activities and complete assignments, you will need: . | Access to a working computer that has a current operating system with updates installed with a modern web browser installed; . | Reliable Internet access and a USC email account; . | If you plan to submit handwritten assignments, a scanning device such as a smartphone with the Microsoft Office Lens app. | The main hub for this course is the Microsoft Teams team COTEAM-BALLARMR-MATH-300-H01-FALL-2022 run through UofSC’s Microsoft Teams account. To access the team for the first time on your desktop/laptop, you can use the join link including in your welcome email. | We will be using a interactive theorem prover called Lean as part of our learning. | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#technology",
    "relUrl": "/syllabus/#technology"
  },"195": {
    "doc": "Syllabus",
    "title": "Minimal Technical Skills Needed",
    "content": "Minimal technical skills are needed in this course. All work in this course must be completed and submitted online. Therefore, you must have consistent and reliable access to a computer and the Internet. The minimal technical skills you have include the ability to: . | Organize and save electronic files; . | Check and use the Microsoft Teams site daily; . | Download and upload documents; . | Locate and enter information with a browser. | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#minimal-technical-skills-needed",
    "relUrl": "/syllabus/#minimal-technical-skills-needed"
  },"196": {
    "doc": "Syllabus",
    "title": "Technical Support",
    "content": "If you have problems with your computer, technology, IT-related questions, support, including Microsoft Teams, please contact the Division of Information Technology (DoIT) Service Desk at (803) 777-1800 or submit an online request through the Self-Service Portal or visit the Carolina Tech Zone. The Service Desk is open Monday – Friday from 8:00 AM – 6:00 PM (Eastern Daylight Time). The Thomas Cooper Library at USC has computers for you to use in case you encounter computer issues/problems. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#technical-support",
    "relUrl": "/syllabus/#technical-support"
  },"197": {
    "doc": "Syllabus",
    "title": "Course Assignments and Grading",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-assignments-and-grading",
    "relUrl": "/syllabus/#course-assignments-and-grading"
  },"198": {
    "doc": "Syllabus",
    "title": "Homework",
    "content": "Homework will need to be completed in groups of 3-4 that will be randomly assigned each week. The assignments will be available in and must be returned through GitHub Classroom. All homework assignments are due by 11:59 pm (Eastern Time) on the day indicated on the course schedule. Homework will be graded for correctness. You will be allowed up to two revisions on each homework assignment. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#homework",
    "relUrl": "/syllabus/#homework"
  },"199": {
    "doc": "Syllabus",
    "title": "Quizzes",
    "content": "Each course will end with a short quiz. The goal of the quiz is to diagnose any gaps in the understanding and make sure we all stay on the same page. Quizzes are graded for correctness. You will be allowed up to two revisions on each quiz. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#quizzes",
    "relUrl": "/syllabus/#quizzes"
  },"200": {
    "doc": "Syllabus",
    "title": "Presentations",
    "content": "All students are expected to regularly present solutions to in-class work group problems. Your target should be to present one solution every two weeks. Presentations are graded simply for completion. If you attempt it, it counts. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#presentations",
    "relUrl": "/syllabus/#presentations"
  },"201": {
    "doc": "Syllabus",
    "title": "Project",
    "content": "A list of project topics will be released on October 3. These can be done in groups of 1-4 of your own choosing. Projects are due by December 9 at 9:00 am (EST). ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#project",
    "relUrl": "/syllabus/#project"
  },"202": {
    "doc": "Syllabus",
    "title": "Evaluation and Grading Scale",
    "content": "All grades will be posted on Teams. You are strongly encouraged to check you scores in Teams regularly. A final letter grade will be assigned based on the weighting below. Assignment Weights . | Component | Percent of total | . | Homework | 25% | . | Quizzes | 25% | . | Presentations | 25% | . | Project | 25% | . Grading Scale . | Final total intervals | Letter Grade | . | [90,100] | A | . | [85,90) | B+ | . | [80,85) | B | . | [75,80) | C+ | . | [70,75) | C | . | [65,70) | D+ | . | [60,65) | D | . | [0,60) | F | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#evaluation-and-grading-scale",
    "relUrl": "/syllabus/#evaluation-and-grading-scale"
  },"203": {
    "doc": "Syllabus",
    "title": "Assignment Submission",
    "content": "All written assignments are required to be submitted through Teams. Unless otherwise specified in the problem, you will be able to enter text directly through Teams or upload a scan of handwritten work. If you choose to upload a scan, then . | the handwriting must be clear and legible – otherwise you will receive no credit . | you will need to use the Office 365 Lens app to scan and upload you work to your university OneDrive account before attaching to the assignment. No HEIC extensions are allowed. | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#assignment-submission",
    "relUrl": "/syllabus/#assignment-submission"
  },"204": {
    "doc": "Syllabus",
    "title": "Revisions",
    "content": "All homework turned in on-time is eligible for revision at full credit. All quizzes taken on-time are eligible for revision at full credit. Each assignment can undergo at most two revisions. Revisions must be resubmitted within one week of receiving a marked assignment or revision. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#revisions",
    "relUrl": "/syllabus/#revisions"
  },"205": {
    "doc": "Syllabus",
    "title": "Academic Success",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#academic-success",
    "relUrl": "/syllabus/#academic-success"
  },"206": {
    "doc": "Syllabus",
    "title": "Accessibility",
    "content": "The Student Disability Resource Center (SDRC) empowers students to manage challenges and limitations imposed by disabilities. Students with disabilities are encouraged to contact me to discuss the logistics of any accommodations needed to fulfill course requirements (within the first week of the semester). In order to receive reasonable accommodations from me, you must be registered with the Student Disability Resource Center (1705 College Street Close-Hipp, Suite 102 Columbia, SC 29208, 803-777-6142). Any student with a documented disability should contact the SDRC to make arrangements for appropriate accommodations. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#accessibility",
    "relUrl": "/syllabus/#accessibility"
  },"207": {
    "doc": "Syllabus",
    "title": "Student Success Center",
    "content": "In partnership with USC faculty, the Student Success Center (SSC) offers a number of programs to assist you in better understanding your course material and to aid you on your path to success. SSC programs are facilitated by professional staff, graduate students, and trained undergraduate peer leaders who have previously excelled in their courses. Resources available to you in this and other courses may include: . Peer Tutoring: You can make a one-on-one appointment with a Peer Tutor. Drop-in Tutoring and Online Tutoring may also be available for this course. Visit their website for a full schedule of times, locations, and courses. Peer Writing: Improve your college-level writing skills by bringing writing assignments from any of your classes to a Peer Writing Tutor. Similar to Tutoring, you can visit the website to make an appointment, and to view the full schedule of available drop-in hours and locations. Success Consultations: In Success Consultations, SSC staff assist you in developing study skills, setting goals, and connecting to a variety of campus resources. Throughout the semester, I may communicate with the SSC via Success Connect, an online referral system, regarding your progress in the course. If contacted by the SSC, please schedule a Success Consultation. Success Connect referrals are not punitive and any information shared by me is confidential and subject to FERPA regulations. SSC services are offered to all USC undergraduates at no additional cost. You are invited to call the Student Success Hotline at (803) 777-1000, visit SSC website, or stop by the SSC in the Thomas Cooper Library on the Mezzanine Level to check schedules and make appointments. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#student-success-center",
    "relUrl": "/syllabus/#student-success-center"
  },"208": {
    "doc": "Syllabus",
    "title": "Writing Center",
    "content": "This course has many writing assignments. The University Writing Center is an important resource you should use! It’s open to help any USC student needing assistance with a writing project at any stage of development. The main Writing Center is in Byrnes 703. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#writing-center",
    "relUrl": "/syllabus/#writing-center"
  },"209": {
    "doc": "Syllabus",
    "title": "University Library Resources",
    "content": "University Libraries has access to books, articles, subject specific resources, citation help, and more. If you are not sure where to start, please Ask a Librarian! Assistance is available at sc.edu/libraries/ask.  . Remember that if you use anything that is not your own writing or media (quotes from books, articles, interviews, websites, movies – everything) you must cite the source in MLA (or other appropriate and approved) format. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#university-library-resources",
    "relUrl": "/syllabus/#university-library-resources"
  },"210": {
    "doc": "Syllabus",
    "title": "Teams and Technology",
    "content": "Teams and Technology. As a student in this course, you have access to support from the Division of Information Technology (DoIT) for Teams and computer issues. The service desk can be reached at 803-777-1800. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#teams-and-technology",
    "relUrl": "/syllabus/#teams-and-technology"
  },"211": {
    "doc": "Syllabus",
    "title": "Counseling Services",
    "content": "The University offers counseling and crisis services as well as outreach services and self-help. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#counseling-services",
    "relUrl": "/syllabus/#counseling-services"
  },"212": {
    "doc": "Syllabus",
    "title": "Course Policies and Procedures",
    "content": " ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#course-policies-and-procedures",
    "relUrl": "/syllabus/#course-policies-and-procedures"
  },"213": {
    "doc": "Syllabus",
    "title": "Attendance Policy and COVID Reporting",
    "content": "You are expected to participate actively in each course. If you anticipate an excused absence, you need to contact me in advance. You should submit a request in writing (email is acceptable) stating the dates of the anticipated absence, explaining the reason for absence, providing supporting documentation as required above, and including any request for make-up work. You should submit this request no later than the end of the second week of regularly scheduled classes in a full fall or spring semester term and within twice the length of the drop/add period for any other term. If regularly attending class becomes difficult for any reason, please contact me to discuss the issue. In accordance with university policy, a grade penalty of 10% may be imposed if a student has unexcused absensces exceeding 5% of the total number of courses. For this course, that means missing TWO courses without excuse. All absences due to documented illness or quarantine will be excused, and no grade penalty will be assessed for missing classes for this reason. If you experience COVID-19 symptoms, please stay home, contact the COVID-19 Student Health Services (SHS) nurse line (803-576-8511), complete the COVID-19 Student Report Form and select the option allowing the Student Ombuds to contact your professors. When talking with the SHS nurse, be sure to ask for documentation of the consult as you will need this to document why you missed class. You will also use the COVID-19 Student Report Form if you have tested positive for COVID-19 or if you have been ordered to quarantine because of close contact with a person who was COVID-19 positive. In each of these situations you will be provided appropriate documentation that can be shared through the Student Report Form. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#attendance-policy-and-covid-reporting",
    "relUrl": "/syllabus/#attendance-policy-and-covid-reporting"
  },"214": {
    "doc": "Syllabus",
    "title": "COVID Policies",
    "content": "UofSC no longer requires face coverings, including in the class. For more information on this semester’s COVID policies see the guidance from the Provost. I strongly encourage getting vaccinated. I encourage physical distancing. While not always possible, I will strive to keep everyone at least three feet apart, even when working in groups, which we will do regularly. If you feel uncomfortable with group work in my class, please come talk with me and I don’t mind letting you work independently at all. Questions You May Have . What if I get sick with COVID? Two things have to occur: Isolation: Students who have been diagnosed with COVID-19 are released from isolation when a medical professional has determined, based on the current CDC and DHEC guidelines, that they have recovered. Currently, these guidelines include being fever-free for at least 24 hours and at least 5 days from their first symptom or positive test if they are asymptomatic. If symptoms persist on the fifth day, then the isolation must be extended to 10 days. What is the attendance policy if I get COVID? In brief, I must provide make-up course work including content and assignments when students have excused absences which include (but are not limited to) being in quarantine or isolation, religious holidays, medical conditions related to pregnancy, and military duty. However, recorded classes and hybrid/online options are not required and should not be expected. All excused absences must have documentation. See syllabus for further attendance policies. How will the Dr. Ballard know if I am absent due to quarantine or isolation? COVID-19 related absences must be document through the Student Ombudsman.  Students who have been diagnosed with COVID-19 or have been exposed and require quarantining should complete the COVID-19 Student Report Form and instructors should request this form in order to excuse the absence.  . Can I inquire about classmates condition with COVID? Sadly, not with me. These are health issues and the information is protected by state and federal law. If an individual student has questions about whether they should quarantine or believe that they have been in close contact, have them reach out to the COVID Phone Bank (803-576-8511). Would we ever change to go online if too many people are sick? Only in the rare instance that 30% or more of students have documented excused absences may I take the course online. This is not to be expected and very complicated according to the current policies. What if Dr. Ballard gets sick with COVID? I have been fully vaccinated and breakthrough infection symptoms most often resemble the common cold. In the event of a breakthrough infection, I will enter the self-isolation period and the course will switch modality to synchronous online temporarily. In the rare circumstance I am unable to teach remotely, a substitute instructor will take over the course. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#covid-policies",
    "relUrl": "/syllabus/#covid-policies"
  },"215": {
    "doc": "Syllabus",
    "title": "Academic Integrity",
    "content": "You are expected to practice the highest possible standards of academic integrity. Any deviation from this expectation will result in a minimum academic penalty of your failing the assignment, and will result in additional disciplinary measures. This includes improper citation of sources, using another student’s work, and any other form of academic misrepresentation. The first tenet of the Carolinian Creed is, “I will practice personal and academic integrity.” . Below are some websites for you to visit to learn more about University policies: . | Carolinian Creed . | Academic Responsibility . | Office of Student Conduct and Academic Integrity . | Information Security Policy and Standards . | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#academic-integrity",
    "relUrl": "/syllabus/#academic-integrity"
  },"216": {
    "doc": "Syllabus",
    "title": "Plagiarism",
    "content": "Using the words or ideas of another as if they were one’s own is a serious form of academic dishonesty. If another person’s complete sentence, syntax, key words, or the specific or unique ideas and information are used, one must give that person credit through proper citation. You should in particular cite any resources, person, text, or otherwise, you used to assist in preparation of your work. Copying proofs or problem solutions is strictly forbidden. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#plagiarism",
    "relUrl": "/syllabus/#plagiarism"
  },"217": {
    "doc": "Syllabus",
    "title": "Group Work",
    "content": "Group work should be performed in safe manner. Remote work will certainly form a larger component of a career going forward. You are encouraged to take advantage of Microsoft Teams video and chat abilities to aid in collaboration. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#group-work",
    "relUrl": "/syllabus/#group-work"
  },"218": {
    "doc": "Syllabus",
    "title": "Class Conduct",
    "content": "Professionalism will be expected at all times, but most especially with your interactions online and in person. Because the university classroom is a place designed for the free exchange of ideas, we must show respect for one another in all circumstances. We will show respect for one another by exhibiting patience and courtesy in our exchanges. Appropriate language and restraint from verbal attacks upon those whose perspectives differ from your own is a minimum requirement. Courtesy and kindness is the norm for those who participate in the class. Mistakes are expected and natural. Mistakes are how learning happens. All students should recognize and respect the bravery of a student presenting a proof or solution. If you ever feel uncomfortable beyond the intellectual challenge of the course, please contact me. Teams is a way for you to share your ideas and learning with your colleagues in this class. We do this as colleagues in learning, and the online space is meant to be a safe and respectful environment for us to conduct these discussions. Some general netiquette rules: . | Treat one another with respect. It will be expected that we will not attack one another personally for holding different opinions. | Do not use all CAPITAL LETTERS in emails or discussion board postings. This is considered “shouting” and is seen as impolite or aggressive. | Begin emails with a proper salutation (Examples: Dr. Name; Ms. Name; Hello Professor Name; Good afternoon Mr. Name). Starting an email without a salutation or a simple “Hey” is not appropriate. | When sending an email, please include a detailed subject line. Additionally, make sure you reference the course number (Ex. ENGL 287) in the message and sign the mail with your name. | Use proper grammar, spelling, punctuation, and capitalization. Text messaging language is not acceptable. | Use good taste when communicating. Profanity should be avoided. | Re-Read, think, and edit your message before you click “Send/Submit/Post.” . | Please remember when posting to be respectful and courteous to your colleagues, and limit your communication to topics of this course and the assignments. | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#class-conduct",
    "relUrl": "/syllabus/#class-conduct"
  },"219": {
    "doc": "Syllabus",
    "title": "Late Work/Make-up Policy",
    "content": "All assignments due by the deadline as posted on the course schedule. Late work is not accepted and not eligible for revision. Please plan accordingly, and complete these assignments in advance of their deadlines to ensure any unanticipated circumstances do not result in a missed assignment. User error does not qualify you for any kind of makeup or retake opportunity. Completing and submitting the assignments by the due date is the sole responsibility of you. If you fail to submit the assignment or test by the due date, then your score for that assignment will be recorded as “zero.” . You will be allowed to access the assignments an unlimited number of times until the due date/time. If you are concerned about missing a deadline, post your assignment the day before the deadline. Be Careful: The clock on your computer may be different than the clock in Teams. If the clock is different by one second, you will be locked out of the assignment. Plan accordingly. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#late-workmake-up-policy",
    "relUrl": "/syllabus/#late-workmake-up-policy"
  },"220": {
    "doc": "Syllabus",
    "title": "Incomplete Grades",
    "content": "The grade of Incomplete will be granted only in accordance with university policy. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#incomplete-grades",
    "relUrl": "/syllabus/#incomplete-grades"
  },"221": {
    "doc": "Syllabus",
    "title": "Diversity and Inclusion",
    "content": "The university is committed to a campus environment that is inclusive, safe, and respectful for all persons, and one that fully embraces the Carolinian Creed: “I will discourage bigotry, while striving to learn from differences in people, ideas and opinions.” Likewise, the Student Code of Conduct stresses, “The University of South Carolina strives to maintain an educational community that fosters the development of students who are ethical, civil and responsible persons.” . To that end, all course activities will be conducted in an atmosphere of friendly participation and interaction among colleagues, recognizing and appreciating the unique experiences, background, and point of view each student brings. You are expected at all times to apply the highest academic standards to this course and to treat others with dignity and respect. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#diversity-and-inclusion",
    "relUrl": "/syllabus/#diversity-and-inclusion"
  },"222": {
    "doc": "Syllabus",
    "title": "Title IX and Gendered Identity",
    "content": "This course affirms equality and respect for all gendered identities and expressions. Please don’t hesitate to correct me regarding your preferred gender pronoun and/or name if different from what is indicated on the official class roster. Likewise, I am committed to nurturing an environment free from discrimination and harassment. Consistent with Title IX policy, please be aware that I as a responsible employee am obligated to report information that you provide to me about a situation involving sexual harassment or assault. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#title-ix-and-gendered-identity",
    "relUrl": "/syllabus/#title-ix-and-gendered-identity"
  },"223": {
    "doc": "Syllabus",
    "title": "Expectations of the Instructor",
    "content": "I am expected to facilitate learning, answer questions appropriately, be fair and objective in grading, provide timely and useful feedback on assignments and treat you as I would like to be treated. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#expectations-of-the-instructor",
    "relUrl": "/syllabus/#expectations-of-the-instructor"
  },"224": {
    "doc": "Syllabus",
    "title": "Copyright/Fair Use Statement",
    "content": "I will cite and/or reference any materials that I use in this course that I do not create. Anything that appears on this website is copyright © 2022 Matthew Ballard and is distributed by an MIT license. Course materials that do not appear on this website are copyright © 2022 Matthew Ballard and all rights are reserved. In particular, you may not distribute any of these course materials in any fashion without express permission. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#copyrightfair-use-statement",
    "relUrl": "/syllabus/#copyrightfair-use-statement"
  },"225": {
    "doc": "Syllabus",
    "title": "Tentative Schedule",
    "content": "This is the plan for the semester. But it is only a plan. The successful progression of each student is the most important guide to through the material. As such, you should expect revisions as we go. ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#tentative-schedule",
    "relUrl": "/syllabus/#tentative-schedule"
  },"226": {
    "doc": "Syllabus",
    "title": "Week 1",
    "content": ". | 8/19 welcome and orientation | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-1",
    "relUrl": "/syllabus/#week-1"
  },"227": {
    "doc": "Syllabus",
    "title": "Week 2",
    "content": ". | 8/22 a logical puzzle and a video game | 8/24 conjuction, disjunction, and implication | 8/26 false and proof by contradiction | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-2",
    "relUrl": "/syllabus/#week-2"
  },"228": {
    "doc": "Syllabus",
    "title": "Week 3",
    "content": ". | 8/29 introduction to Lean | 8/31 propositional logic in Lean | 9/2 propositional logic in Lean 2 | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-3",
    "relUrl": "/syllabus/#week-3"
  },"229": {
    "doc": "Syllabus",
    "title": "Week 4",
    "content": ". | 9/5 reductio ad absurdum | 9/7 truth and falsity | 9/9 the universal quantifier | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-4",
    "relUrl": "/syllabus/#week-4"
  },"230": {
    "doc": "Syllabus",
    "title": "Week 5",
    "content": ". | 9/12 the existential quantfier | 9/14 equality | 9/16 semantics of first order logic | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-5",
    "relUrl": "/syllabus/#week-5"
  },"231": {
    "doc": "Syllabus",
    "title": "Week 6",
    "content": ". | 9/19 predicates in Lean | 9/21 quantifiers in Lean | 9/23 quantifiers in Lean 2 | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-6",
    "relUrl": "/syllabus/#week-6"
  },"232": {
    "doc": "Syllabus",
    "title": "Week 7",
    "content": ". | 9/26 sets | 9/28 operations on sets | 9/30 sets in Lean | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-7",
    "relUrl": "/syllabus/#week-7"
  },"233": {
    "doc": "Syllabus",
    "title": "Week 8",
    "content": ". | 10/3 functions | 10/5 injections, surjections and bijections | 10/7 functions in Lean | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-8",
    "relUrl": "/syllabus/#week-8"
  },"234": {
    "doc": "Syllabus",
    "title": "Week 9",
    "content": ". | 10/10 relations | 10/12 equivalence relation and partials orders | 10/14 fall break. | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-9",
    "relUrl": "/syllabus/#week-9"
  },"235": {
    "doc": "Syllabus",
    "title": "Week 10",
    "content": ". | 10/17 relations in Lean | 10/19 Peano’s axioms | 10/21 weak induction | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-10",
    "relUrl": "/syllabus/#week-10"
  },"236": {
    "doc": "Syllabus",
    "title": "Week 11",
    "content": ". | 10/24 strong induction | 10/26 the natural numbers in Lean | 10/28 induction in Lean | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-11",
    "relUrl": "/syllabus/#week-11"
  },"237": {
    "doc": "Syllabus",
    "title": "Week 12",
    "content": ". | 10/31 induction in Lean 2 | 11/2 groups and multiplication tables | 11/4 the integers | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-12",
    "relUrl": "/syllabus/#week-12"
  },"238": {
    "doc": "Syllabus",
    "title": "Week 13",
    "content": ". | 11/7 cyclic groups | 11/9 symmetric/permutation groups | 11/11 cycles and cycle notations | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-13",
    "relUrl": "/syllabus/#week-13"
  },"239": {
    "doc": "Syllabus",
    "title": "Week 14",
    "content": ". | 11/14 abelian groups | 11/16 dihedral groups | 11/18 permutation representation of dihedrals groups | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-14",
    "relUrl": "/syllabus/#week-14"
  },"240": {
    "doc": "Syllabus",
    "title": "Week 15",
    "content": ". | 11/21 presentations of dihedral groups | 11/23 thanksgiving break. | 11/25 thanksgiving break. | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-15",
    "relUrl": "/syllabus/#week-15"
  },"241": {
    "doc": "Syllabus",
    "title": "Week 16",
    "content": ". | 11/28 monoids and free groups | 11/30 more on free groups | 12/2 the universal property of free groups | . ",
    "url": "https://300.f22.matthewrobertballard.com/syllabus/#week-16",
    "relUrl": "/syllabus/#week-16"
  },"242": {
    "doc": "Useful formula",
    "title": "Useful formula",
    "content": "We delve much deeper into propositional (and other kinds of) logic. While we will talk about one more form of logic (first order or predicate logic), we want to get to using our new logical skills on mathematical questions. As such, let’s end the module on propositional logic with a list of useful and/or well-known provable formulas. Below $A,B,C$ are general formula. | \\(A \\land B \\leftrightarrow B \\land A\\) When we can exchange the placement of an operation taking two inputs (binary operation), then we say it is commutative. This is saying that $\\land$ is commutative (up to bi-implication). | $\\lor$ is commutative : \\(A \\lor B \\leftrightarrow B \\lor A\\) | \\((A \\land B) \\land C \\leftrightarrow A \\land (B \\land C)\\) When we have three arguments for a binary and consume them in different orders (apply it to 1 and 2 then the result to 3 vs apply it to 2 and 3 first then the result to 1 while keeping the order of the placements) without affecting the final output, then we say the operation is associative. So here $\\land$ is asssociative. | You can distribute $\\land$ over $\\lor$: \\(A \\land (B \\lor C) \\leftrightarrow (A \\land B) \\lor (A \\land C)\\) | You can also distribute $\\lor$ over $\\land$: \\(A \\lor (B \\land C) \\leftrightarrow (A \\lor B) \\land (A \\lor C)\\) | \\[(A \\to (B \\to C)) \\leftrightarrow (A \\land B \\to C)\\] | Transitivity of implication: \\((A \\to B) \\to ((B \\to C) \\to (A \\to C))\\) | \\[((A \\lor B) \\to C) \\leftrightarrow (A \\to C) \\lor (B \\to C)\\] | \\[\\neg (A \\lor B) \\leftrightarrow \\neg A \\land \\neg B\\] | \\(\\neg (A \\land B) \\leftrightarrow \\neg A \\lor \\neg B\\) | \\[\\neg (A \\to B) \\leftrightarrow A \\land \\neg B\\] | \\[\\neg A \\to (A \\to B)\\] | \\((\\neg A \\lor B) \\leftrightarrow (A \\to B)\\) | \\[\\neg(A \\leftrightarrow \\neg A)\\] | \\[(A \\to B) \\leftrightarrow (\\neg B \\to \\neg A)\\] | \\((A \\to (B \\lor C)) \\to ((A \\to B) \\lor (A \\to C))\\) | If $B \\leftrightarrow C$, then for any $A$ we have . | \\[A \\lor B \\leftrightarrow A \\lor C\\] | \\[A \\land B \\leftrightarrow A \\land C\\] | \\[A \\to B \\leftrightarrow A \\to C\\] | . | . Each of the above can provide a useful logical shortcut when in the midst of a mathematical argument. ",
    "url": "https://300.f22.matthewrobertballard.com/notes/propositional_logic/useful_facts/",
    "relUrl": "/notes/propositional_logic/useful_facts/"
  }
}
